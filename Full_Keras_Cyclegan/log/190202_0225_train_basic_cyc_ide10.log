_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_A_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_B_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
ivec_b (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
ivec_a (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
model_4 (Model)                 (None, 1, 600, 1)    653345      ivec_b[0][0]                     
                                                                 model_3[1][0]                    
                                                                 ivec_a[0][0]                     
__________________________________________________________________________________________________
model_3 (Model)                 (None, 1, 600, 1)    653345      ivec_a[0][0]                     
                                                                 model_4[1][0]                    
                                                                 ivec_b[0][0]                     
__________________________________________________________________________________________________
model_2 (Model)                 (None, 1)            39610241    model_4[1][0]                    
__________________________________________________________________________________________________
model_1 (Model)                 (None, 1)            39610241    model_3[1][0]                    
==================================================================================================
Total params: 80,527,172
Trainable params: 1,306,690
Non-trainable params: 79,220,482
__________________________________________________________________________________________________
Start CycleGAN training.
[Epoch 1/50] [Batch 0/516] [D loss: 19.302315, acc:   0%] [G loss: 37.413490, adv: 0.354179, cyc: 0.924378, id: 0.953104] time: 0:01:59.664773 
[Epoch 1/50] [Batch 100/516] [D loss: 0.091974, acc:  92%] [G loss: 21.899178, adv: 1.150599, cyc: 0.545277, id: 0.464680] time: 0:03:08.376120 
[Epoch 1/50] [Batch 200/516] [D loss: 0.037790, acc:  98%] [G loss: 19.854509, adv: 0.969845, cyc: 0.496212, id: 0.441515] time: 0:04:17.066952 
[Epoch 1/50] [Batch 300/516] [D loss: 0.010793, acc:  99%] [G loss: 18.440477, adv: 0.856446, cyc: 0.463523, id: 0.416041] time: 0:05:25.729326 
[Epoch 1/50] [Batch 400/516] [D loss: 0.022313, acc:  99%] [G loss: 17.032009, adv: 0.754315, cyc: 0.428988, id: 0.380622] time: 0:06:34.368619 
[Epoch 1/50] [Batch 500/516] [D loss: 0.030594, acc:  97%] [G loss: 17.097342, adv: 0.939390, cyc: 0.417858, id: 0.374821] time: 0:07:43.004764 
[Epoch 2/50] [Batch 0/516] [D loss: 0.007026, acc: 100%] [G loss: 16.242348, adv: 0.796957, cyc: 0.403586, id: 0.355006] time: 0:07:53.982234 
[Epoch 2/50] [Batch 100/516] [D loss: 0.008286, acc: 100%] [G loss: 15.950606, adv: 0.814286, cyc: 0.393477, id: 0.352769] time: 0:09:02.615694 
[Epoch 2/50] [Batch 200/516] [D loss: 0.014100, acc: 100%] [G loss: 16.273138, adv: 0.981646, cyc: 0.391332, id: 0.371802] time: 0:10:11.241861 
[Epoch 2/50] [Batch 300/516] [D loss: 0.004741, acc: 100%] [G loss: 15.826181, adv: 0.899840, cyc: 0.383002, id: 0.360493] time: 0:11:19.864824 
[Epoch 2/50] [Batch 400/516] [D loss: 0.002559, acc: 100%] [G loss: 15.115353, adv: 0.828712, cyc: 0.366143, id: 0.342900] time: 0:12:28.497071 
[Epoch 2/50] [Batch 500/516] [D loss: 0.003157, acc: 100%] [G loss: 15.432016, adv: 1.004554, cyc: 0.365785, id: 0.336298] time: 0:13:37.115196 
[Epoch 3/50] [Batch 0/516] [D loss: 0.005792, acc: 100%] [G loss: 14.905740, adv: 1.013935, cyc: 0.353601, id: 0.317666] time: 0:13:48.094718 
[Epoch 3/50] [Batch 100/516] [D loss: 0.003608, acc: 100%] [G loss: 14.793152, adv: 0.951603, cyc: 0.352321, id: 0.321202] time: 0:14:56.715717 
[Epoch 3/50] [Batch 200/516] [D loss: 0.004689, acc: 100%] [G loss: 14.823766, adv: 0.915111, cyc: 0.353259, id: 0.339458] time: 0:16:05.329943 
[Epoch 3/50] [Batch 300/516] [D loss: 0.018758, acc:  99%] [G loss: 14.819943, adv: 0.996042, cyc: 0.350486, id: 0.328628] time: 0:17:13.947284 
[Epoch 3/50] [Batch 400/516] [D loss: 0.003333, acc: 100%] [G loss: 14.220582, adv: 0.874356, cyc: 0.339937, id: 0.318848] time: 0:18:22.554133 
[Epoch 3/50] [Batch 500/516] [D loss: 0.002685, acc: 100%] [G loss: 14.479927, adv: 0.988079, cyc: 0.339921, id: 0.316800] time: 0:19:31.167488 
[Epoch 4/50] [Batch 0/516] [D loss: 0.002350, acc: 100%] [G loss: 13.901140, adv: 0.938012, cyc: 0.329755, id: 0.296078] time: 0:19:42.143961 
[Epoch 4/50] [Batch 100/516] [D loss: 0.005855, acc: 100%] [G loss: 13.853501, adv: 0.882885, cyc: 0.329942, id: 0.301784] time: 0:20:50.751028 
[Epoch 4/50] [Batch 200/516] [D loss: 0.003087, acc: 100%] [G loss: 14.080515, adv: 0.915167, cyc: 0.332810, id: 0.320693] time: 0:21:59.364114 
[Epoch 4/50] [Batch 300/516] [D loss: 0.002018, acc: 100%] [G loss: 14.080265, adv: 0.946754, cyc: 0.332188, id: 0.313284] time: 0:23:07.972621 
[Epoch 4/50] [Batch 400/516] [D loss: 0.003449, acc: 100%] [G loss: 13.631888, adv: 0.915719, cyc: 0.321707, id: 0.299638] time: 0:24:16.600822 
[Epoch 4/50] [Batch 500/516] [D loss: 0.001276, acc: 100%] [G loss: 13.788198, adv: 0.927292, cyc: 0.323617, id: 0.302218] time: 0:25:25.229846 
[Epoch 5/50] [Batch 0/516] [D loss: 0.002853, acc: 100%] [G loss: 13.307908, adv: 0.926553, cyc: 0.313087, id: 0.284591] time: 0:25:36.206491 
[Epoch 5/50] [Batch 100/516] [D loss: 0.002170, acc: 100%] [G loss: 13.505171, adv: 0.971133, cyc: 0.314728, id: 0.288586] time: 0:26:44.812329 
[Epoch 5/50] [Batch 200/516] [D loss: 0.002330, acc: 100%] [G loss: 13.784681, adv: 0.980095, cyc: 0.321164, id: 0.311132] time: 0:27:53.420834 
[Epoch 5/50] [Batch 300/516] [D loss: 0.002371, acc: 100%] [G loss: 13.741018, adv: 0.976194, cyc: 0.320839, id: 0.304105] time: 0:29:02.027261 
[Epoch 5/50] [Batch 400/516] [D loss: 0.001032, acc: 100%] [G loss: 13.221203, adv: 0.938033, cyc: 0.311186, id: 0.287658] time: 0:30:10.626449 
[Epoch 5/50] [Batch 500/516] [D loss: 0.001780, acc: 100%] [G loss: 13.427244, adv: 0.971552, cyc: 0.312479, id: 0.291938] time: 0:31:19.226308 
[Epoch 6/50] [Batch 0/516] [D loss: 0.002013, acc: 100%] [G loss: 13.103090, adv: 0.979398, cyc: 0.305078, id: 0.275711] time: 0:31:35.903651 
[Epoch 6/50] [Batch 100/516] [D loss: 0.002550, acc: 100%] [G loss: 13.041571, adv: 0.939061, cyc: 0.305087, id: 0.279726] time: 0:32:44.512836 
[Epoch 6/50] [Batch 200/516] [D loss: 0.001291, acc: 100%] [G loss: 13.457569, adv: 0.990059, cyc: 0.311954, id: 0.301852] time: 0:33:53.134524 
[Epoch 6/50] [Batch 300/516] [D loss: 0.002446, acc: 100%] [G loss: 13.388596, adv: 0.996131, cyc: 0.310209, id: 0.295028] time: 0:35:01.754692 
[Epoch 6/50] [Batch 400/516] [D loss: 0.001496, acc: 100%] [G loss: 12.957178, adv: 0.962949, cyc: 0.300522, id: 0.282419] time: 0:36:10.376458 
[Epoch 6/50] [Batch 500/516] [D loss: 0.001012, acc: 100%] [G loss: 13.108398, adv: 0.930097, cyc: 0.306283, id: 0.286643] time: 0:37:18.996502 
[Epoch 7/50] [Batch 0/516] [D loss: 0.002818, acc: 100%] [G loss: 12.655085, adv: 0.916384, cyc: 0.294501, id: 0.269622] time: 0:37:29.973032 
[Epoch 7/50] [Batch 100/516] [D loss: 0.001907, acc: 100%] [G loss: 12.809178, adv: 0.985644, cyc: 0.296509, id: 0.271282] time: 0:38:38.584700 
[Epoch 7/50] [Batch 200/516] [D loss: 0.003994, acc: 100%] [G loss: 12.971780, adv: 0.903288, cyc: 0.302961, id: 0.295110] time: 0:39:47.198553 
[Epoch 7/50] [Batch 300/516] [D loss: 0.001896, acc: 100%] [G loss: 13.080018, adv: 0.952317, cyc: 0.303057, id: 0.292457] time: 0:40:55.814534 
[Epoch 7/50] [Batch 400/516] [D loss: 0.001680, acc: 100%] [G loss: 12.657424, adv: 0.943566, cyc: 0.293152, id: 0.276286] time: 0:42:04.418817 
[Epoch 7/50] [Batch 500/516] [D loss: 0.007055, acc: 100%] [G loss: 13.095066, adv: 1.019866, cyc: 0.300108, id: 0.281570] time: 0:43:13.021871 
[Epoch 8/50] [Batch 0/516] [D loss: 0.000409, acc: 100%] [G loss: 12.533689, adv: 0.976465, cyc: 0.289008, id: 0.263490] time: 0:43:23.998249 
[Epoch 8/50] [Batch 100/516] [D loss: 0.001545, acc: 100%] [G loss: 12.619243, adv: 0.994354, cyc: 0.288412, id: 0.269980] time: 0:44:32.606924 
[Epoch 8/50] [Batch 200/516] [D loss: 0.000898, acc: 100%] [G loss: 12.812391, adv: 0.956335, cyc: 0.297006, id: 0.286383] time: 0:45:41.226276 
[Epoch 8/50] [Batch 300/516] [D loss: 0.000954, acc: 100%] [G loss: 12.792420, adv: 0.935939, cyc: 0.296423, id: 0.284916] time: 0:46:49.827486 
[Epoch 8/50] [Batch 400/516] [D loss: 0.012296, acc: 100%] [G loss: 12.580589, adv: 0.982441, cyc: 0.288272, id: 0.271663] time: 0:47:58.412524 
[Epoch 8/50] [Batch 500/516] [D loss: 0.000424, acc: 100%] [G loss: 12.680291, adv: 0.927941, cyc: 0.294300, id: 0.277395] time: 0:49:07.005833 
[Epoch 9/50] [Batch 0/516] [D loss: 0.000539, acc: 100%] [G loss: 12.294653, adv: 0.934705, cyc: 0.284177, id: 0.261407] time: 0:49:17.977755 
[Epoch 9/50] [Batch 100/516] [D loss: 0.001657, acc: 100%] [G loss: 12.435730, adv: 0.974387, cyc: 0.286274, id: 0.264279] time: 0:50:26.525148 
[Epoch 9/50] [Batch 200/516] [D loss: 0.000616, acc: 100%] [G loss: 12.675657, adv: 0.978430, cyc: 0.290286, id: 0.284465] time: 0:51:35.064001 
[Epoch 9/50] [Batch 300/516] [D loss: 0.002940, acc: 100%] [G loss: 12.729580, adv: 0.980716, cyc: 0.292807, id: 0.281305] time: 0:52:43.604223 
[Epoch 9/50] [Batch 400/516] [D loss: 0.000260, acc: 100%] [G loss: 12.407790, adv: 0.976904, cyc: 0.284845, id: 0.268767] time: 0:53:52.159338 
[Epoch 9/50] [Batch 500/516] [D loss: 0.001274, acc: 100%] [G loss: 12.571412, adv: 0.975957, cyc: 0.288162, id: 0.273213] time: 0:55:00.711834 
[Epoch 10/50] [Batch 0/516] [D loss: 0.001089, acc: 100%] [G loss: 12.088882, adv: 0.905883, cyc: 0.280171, id: 0.257575] time: 0:55:11.678777 
[Epoch 10/50] [Batch 100/516] [D loss: 0.000221, acc: 100%] [G loss: 12.291562, adv: 0.965834, cyc: 0.281288, id: 0.263069] time: 0:56:20.225544 
[Epoch 10/50] [Batch 200/516] [D loss: 0.001404, acc: 100%] [G loss: 12.436946, adv: 0.889803, cyc: 0.289881, id: 0.282322] time: 0:57:28.763351 
[Epoch 10/50] [Batch 300/516] [D loss: 0.000616, acc: 100%] [G loss: 12.557452, adv: 0.983448, cyc: 0.286696, id: 0.278208] time: 0:58:37.294727 
[Epoch 10/50] [Batch 400/516] [D loss: 0.003742, acc: 100%] [G loss: 12.371223, adv: 1.047772, cyc: 0.278711, id: 0.265646] time: 0:59:45.837781 
[Epoch 10/50] [Batch 500/516] [D loss: 0.001234, acc: 100%] [G loss: 12.429733, adv: 0.974137, cyc: 0.284296, id: 0.270335] time: 1:00:54.382734 
[Epoch 11/50] [Batch 0/516] [D loss: 0.000984, acc: 100%] [G loss: 12.036545, adv: 0.999100, cyc: 0.272961, id: 0.252716] time: 1:01:06.474970 
[Epoch 11/50] [Batch 100/516] [D loss: 0.001418, acc: 100%] [G loss: 12.083042, adv: 0.944945, cyc: 0.277096, id: 0.258884] time: 1:02:15.021694 
[Epoch 11/50] [Batch 200/516] [D loss: 0.001264, acc: 100%] [G loss: 12.366343, adv: 0.950178, cyc: 0.283589, id: 0.278806] time: 1:03:23.563086 
[Epoch 11/50] [Batch 300/516] [D loss: 0.000545, acc: 100%] [G loss: 12.468814, adv: 0.998764, cyc: 0.282859, id: 0.275691] time: 1:04:32.119348 
[Epoch 11/50] [Batch 400/516] [D loss: 0.000361, acc: 100%] [G loss: 12.021157, adv: 0.954391, cyc: 0.274138, id: 0.262313] time: 1:05:40.670492 
[Epoch 11/50] [Batch 500/516] [D loss: 0.000874, acc: 100%] [G loss: 12.288605, adv: 0.956438, cyc: 0.281414, id: 0.268797] time: 1:06:49.219704 
[Epoch 12/50] [Batch 0/516] [D loss: 0.000660, acc: 100%] [G loss: 11.943540, adv: 0.996479, cyc: 0.269301, id: 0.253005] time: 1:07:00.186819 
[Epoch 12/50] [Batch 100/516] [D loss: 0.000700, acc: 100%] [G loss: 12.201983, adv: 1.027472, cyc: 0.275565, id: 0.257055] time: 1:08:08.729320 
[Epoch 12/50] [Batch 200/516] [D loss: 0.001344, acc: 100%] [G loss: 12.355791, adv: 1.004552, cyc: 0.279177, id: 0.277524] time: 1:09:17.289771 
[Epoch 12/50] [Batch 300/516] [D loss: 0.000483, acc: 100%] [G loss: 12.263569, adv: 0.953432, cyc: 0.280185, id: 0.273097] time: 1:10:25.839214 
[Epoch 12/50] [Batch 400/516] [D loss: 0.001103, acc: 100%] [G loss: 11.952433, adv: 0.969789, cyc: 0.271713, id: 0.259790] time: 1:11:34.377981 
[Epoch 12/50] [Batch 500/516] [D loss: 0.004621, acc: 100%] [G loss: 12.329055, adv: 1.057254, cyc: 0.276344, id: 0.264658] time: 1:12:42.921792 
[Epoch 13/50] [Batch 0/516] [D loss: 0.000918, acc: 100%] [G loss: 11.698172, adv: 0.946354, cyc: 0.265260, id: 0.248614] time: 1:12:53.891156 
[Epoch 13/50] [Batch 100/516] [D loss: 0.001026, acc: 100%] [G loss: 11.836955, adv: 0.923734, cyc: 0.270319, id: 0.253951] time: 1:14:02.438295 
[Epoch 13/50] [Batch 200/516] [D loss: 0.000169, acc: 100%] [G loss: 12.166129, adv: 0.961394, cyc: 0.277654, id: 0.273428] time: 1:15:10.984729 
[Epoch 13/50] [Batch 300/516] [D loss: 0.001756, acc: 100%] [G loss: 12.225892, adv: 0.972583, cyc: 0.277644, id: 0.270792] time: 1:16:19.537956 
[Epoch 13/50] [Batch 400/516] [D loss: 0.000521, acc: 100%] [G loss: 11.684574, adv: 0.876748, cyc: 0.268384, id: 0.258376] time: 1:17:28.088990 
[Epoch 13/50] [Batch 500/516] [D loss: 0.000580, acc: 100%] [G loss: 12.038488, adv: 0.934659, cyc: 0.274399, id: 0.263828] time: 1:18:36.643826 
[Epoch 14/50] [Batch 0/516] [D loss: 0.000238, acc: 100%] [G loss: 11.610565, adv: 0.916312, cyc: 0.264797, id: 0.247377] time: 1:18:47.613835 
[Epoch 14/50] [Batch 100/516] [D loss: 0.000317, acc: 100%] [G loss: 11.756236, adv: 0.934208, cyc: 0.267520, id: 0.251747] time: 1:19:56.166063 
[Epoch 14/50] [Batch 200/516] [D loss: 0.002007, acc: 100%] [G loss: 12.189955, adv: 1.041316, cyc: 0.272253, id: 0.272764] time: 1:21:04.708652 
[Epoch 14/50] [Batch 300/516] [D loss: 0.000873, acc: 100%] [G loss: 12.050577, adv: 0.937616, cyc: 0.274624, id: 0.269175] time: 1:22:13.253233 
[Epoch 14/50] [Batch 400/516] [D loss: 0.000519, acc: 100%] [G loss: 11.781161, adv: 0.999231, cyc: 0.264170, id: 0.256022] time: 1:23:21.811853 
[Epoch 14/50] [Batch 500/516] [D loss: 0.000695, acc: 100%] [G loss: 11.999413, adv: 0.965336, cyc: 0.272073, id: 0.261005] time: 1:24:30.376182 
[Epoch 15/50] [Batch 0/516] [D loss: 0.000731, acc: 100%] [G loss: 11.521866, adv: 0.929798, cyc: 0.261725, id: 0.245727] time: 1:24:41.343198 
[Epoch 15/50] [Batch 100/516] [D loss: 0.000965, acc: 100%] [G loss: 11.659130, adv: 0.963492, cyc: 0.263280, id: 0.249294] time: 1:25:49.894771 
[Epoch 15/50] [Batch 200/516] [D loss: 0.000559, acc: 100%] [G loss: 11.951524, adv: 0.941787, cyc: 0.271323, id: 0.270205] time: 1:26:58.445620 
[Epoch 15/50] [Batch 300/516] [D loss: 0.000523, acc: 100%] [G loss: 11.932325, adv: 0.936637, cyc: 0.270696, id: 0.267477] time: 1:28:06.991758 
[Epoch 15/50] [Batch 400/516] [D loss: 0.000659, acc: 100%] [G loss: 11.623005, adv: 0.956191, cyc: 0.261850, id: 0.255344] time: 1:29:15.553601 
[Epoch 15/50] [Batch 500/516] [D loss: 0.000577, acc: 100%] [G loss: 11.859041, adv: 0.952677, cyc: 0.268285, id: 0.259083] time: 1:30:24.114250 
[Epoch 16/50] [Batch 0/516] [D loss: 0.000322, acc: 100%] [G loss: 11.583456, adv: 1.004889, cyc: 0.259608, id: 0.242856] time: 1:30:36.518052 
[Epoch 16/50] [Batch 100/516] [D loss: 0.000285, acc: 100%] [G loss: 11.673626, adv: 0.951225, cyc: 0.263629, id: 0.247594] time: 1:31:45.083697 
[Epoch 16/50] [Batch 200/516] [D loss: 0.000508, acc: 100%] [G loss: 11.764463, adv: 0.909795, cyc: 0.267417, id: 0.268072] time: 1:32:53.632956 
[Epoch 16/50] [Batch 300/516] [D loss: 0.000323, acc: 100%] [G loss: 11.973276, adv: 0.982102, cyc: 0.269726, id: 0.266235] time: 1:34:02.190762 
[Epoch 16/50] [Batch 400/516] [D loss: 0.000443, acc: 100%] [G loss: 11.516791, adv: 0.945720, cyc: 0.259252, id: 0.252198] time: 1:35:10.750581 
[Epoch 16/50] [Batch 500/516] [D loss: 0.000411, acc: 100%] [G loss: 11.838188, adv: 0.970329, cyc: 0.266684, id: 0.257266] time: 1:36:19.308539 
[Epoch 17/50] [Batch 0/516] [D loss: 0.000150, acc: 100%] [G loss: 11.424994, adv: 0.977870, cyc: 0.257094, id: 0.240362] time: 1:36:30.274570 
[Epoch 17/50] [Batch 100/516] [D loss: 0.000139, acc: 100%] [G loss: 11.562467, adv: 0.968470, cyc: 0.259396, id: 0.247236] time: 1:37:38.822986 
[Epoch 17/50] [Batch 200/516] [D loss: 0.000124, acc: 100%] [G loss: 11.768414, adv: 0.955267, cyc: 0.264716, id: 0.267589] time: 1:38:47.371287 
[Epoch 17/50] [Batch 300/516] [D loss: 0.000334, acc: 100%] [G loss: 11.757433, adv: 0.952888, cyc: 0.264677, id: 0.262637] time: 1:39:55.922640 
[Epoch 17/50] [Batch 400/516] [D loss: 0.000155, acc: 100%] [G loss: 11.499415, adv: 0.990087, cyc: 0.256293, id: 0.250265] time: 1:41:04.468672 
[Epoch 17/50] [Batch 500/516] [D loss: 0.006806, acc:  98%] [G loss: 11.655410, adv: 0.938590, cyc: 0.263041, id: 0.255797] time: 1:42:13.014960 
[Epoch 18/50] [Batch 0/516] [D loss: 0.000298, acc: 100%] [G loss: 11.341843, adv: 0.961609, cyc: 0.254188, id: 0.239895] time: 1:42:23.983587 
[Epoch 18/50] [Batch 100/516] [D loss: 0.000403, acc: 100%] [G loss: 11.386066, adv: 0.917364, cyc: 0.257335, id: 0.244777] time: 1:43:32.532293 
[Epoch 18/50] [Batch 200/516] [D loss: 0.000550, acc: 100%] [G loss: 11.722961, adv: 0.983936, cyc: 0.262363, id: 0.262941] time: 1:44:41.086208 
[Epoch 18/50] [Batch 300/516] [D loss: 0.000609, acc: 100%] [G loss: 11.796078, adv: 0.986939, cyc: 0.263758, id: 0.261674] time: 1:45:49.643937 
[Epoch 18/50] [Batch 400/516] [D loss: 0.008240, acc: 100%] [G loss: 11.524455, adv: 1.020410, cyc: 0.257052, id: 0.248110] time: 1:46:58.184031 
[Epoch 18/50] [Batch 500/516] [D loss: 0.000214, acc: 100%] [G loss: 11.582998, adv: 0.937346, cyc: 0.260232, id: 0.253230] time: 1:48:06.735736 
[Epoch 19/50] [Batch 0/516] [D loss: 0.000325, acc: 100%] [G loss: 11.395330, adv: 1.010716, cyc: 0.251783, id: 0.238287] time: 1:48:17.705218 
[Epoch 19/50] [Batch 100/516] [D loss: 0.000401, acc: 100%] [G loss: 11.377401, adv: 0.971771, cyc: 0.253320, id: 0.242129] time: 1:49:26.254241 
[Epoch 19/50] [Batch 200/516] [D loss: 0.000415, acc: 100%] [G loss: 11.625406, adv: 0.951585, cyc: 0.260871, id: 0.262805] time: 1:50:34.802874 
[Epoch 19/50] [Batch 300/516] [D loss: 0.000481, acc: 100%] [G loss: 11.672020, adv: 0.985821, cyc: 0.259356, id: 0.259743] time: 1:51:43.344111 
[Epoch 19/50] [Batch 400/516] [D loss: 0.000176, acc: 100%] [G loss: 11.283149, adv: 0.950619, cyc: 0.252593, id: 0.246701] time: 1:52:51.892002 
[Epoch 19/50] [Batch 500/516] [D loss: 0.000208, acc: 100%] [G loss: 11.511985, adv: 0.968653, cyc: 0.256910, id: 0.251585] time: 1:54:00.446799 
[Epoch 20/50] [Batch 0/516] [D loss: 0.000433, acc: 100%] [G loss: 11.129684, adv: 0.948625, cyc: 0.248976, id: 0.235780] time: 1:54:11.416642 
[Epoch 20/50] [Batch 100/516] [D loss: 0.000660, acc: 100%] [G loss: 11.276231, adv: 0.970065, cyc: 0.252182, id: 0.239800] time: 1:55:19.960865 
[Epoch 20/50] [Batch 200/516] [D loss: 0.000707, acc: 100%] [G loss: 11.561644, adv: 0.970258, cyc: 0.257751, id: 0.262838] time: 1:56:28.512928 
[Epoch 20/50] [Batch 300/516] [D loss: 0.000447, acc: 100%] [G loss: 11.618294, adv: 0.966915, cyc: 0.259621, id: 0.258811] time: 1:57:37.058015 
[Epoch 20/50] [Batch 400/516] [D loss: 0.000076, acc: 100%] [G loss: 11.230844, adv: 0.945380, cyc: 0.251085, id: 0.245635] time: 1:58:45.606342 
[Epoch 20/50] [Batch 500/516] [D loss: 0.000477, acc: 100%] [G loss: 11.533667, adv: 0.981572, cyc: 0.257075, id: 0.250940] time: 1:59:54.169193 
[Epoch 21/50] [Batch 0/516] [D loss: 0.000139, acc: 100%] [G loss: 11.020525, adv: 0.929837, cyc: 0.246944, id: 0.234442] time: 2:00:06.431547 
[Epoch 21/50] [Batch 100/516] [D loss: 0.001148, acc: 100%] [G loss: 11.197018, adv: 0.975053, cyc: 0.248390, id: 0.239481] time: 2:01:14.982184 
[Epoch 21/50] [Batch 200/516] [D loss: 0.000177, acc: 100%] [G loss: 11.509224, adv: 0.962257, cyc: 0.257293, id: 0.259846] time: 2:02:23.534347 
[Epoch 21/50] [Batch 300/516] [D loss: 0.000272, acc: 100%] [G loss: 11.418777, adv: 0.920928, cyc: 0.256142, id: 0.255166] time: 2:03:32.082752 
[Epoch 21/50] [Batch 400/516] [D loss: 0.000292, acc: 100%] [G loss: 11.298903, adv: 0.994795, cyc: 0.249933, id: 0.244205] time: 2:04:40.639192 
[Epoch 21/50] [Batch 500/516] [D loss: 0.000160, acc: 100%] [G loss: 11.397831, adv: 0.966656, cyc: 0.253463, id: 0.249238] time: 2:05:49.198203 
[Epoch 22/50] [Batch 0/516] [D loss: 0.000175, acc: 100%] [G loss: 10.996030, adv: 0.964337, cyc: 0.244243, id: 0.232896] time: 2:06:00.165997 
[Epoch 22/50] [Batch 100/516] [D loss: 0.000138, acc: 100%] [G loss: 11.108271, adv: 0.936000, cyc: 0.247843, id: 0.238599] time: 2:07:08.728726 
[Epoch 22/50] [Batch 200/516] [D loss: 0.000123, acc: 100%] [G loss: 11.459865, adv: 0.967596, cyc: 0.255865, id: 0.257638] time: 2:08:17.278287 
[Epoch 22/50] [Batch 300/516] [D loss: 0.000222, acc: 100%] [G loss: 11.474111, adv: 0.971817, cyc: 0.254877, id: 0.254807] time: 2:09:25.839495 
[Epoch 22/50] [Batch 400/516] [D loss: 0.000723, acc: 100%] [G loss: 11.194984, adv: 1.005062, cyc: 0.246527, id: 0.243325] time: 2:10:34.395844 
[Epoch 22/50] [Batch 500/516] [D loss: 0.000177, acc: 100%] [G loss: 11.416296, adv: 0.978671, cyc: 0.254370, id: 0.247560] time: 2:11:42.936656 
[Epoch 23/50] [Batch 0/516] [D loss: 0.000406, acc: 100%] [G loss: 11.057983, adv: 1.007204, cyc: 0.242481, id: 0.232505] time: 2:11:53.905350 
[Epoch 23/50] [Batch 100/516] [D loss: 0.000291, acc: 100%] [G loss: 11.138271, adv: 0.986913, cyc: 0.245173, id: 0.238634] time: 2:13:02.448216 
[Epoch 23/50] [Batch 200/516] [D loss: 0.000596, acc: 100%] [G loss: 11.403462, adv: 0.994218, cyc: 0.252149, id: 0.255922] time: 2:14:11.005346 
[Epoch 23/50] [Batch 300/516] [D loss: 0.000200, acc: 100%] [G loss: 11.454663, adv: 0.978649, cyc: 0.254529, id: 0.253676] time: 2:15:19.567814 
[Epoch 23/50] [Batch 400/516] [D loss: 0.000354, acc: 100%] [G loss: 11.060503, adv: 0.967333, cyc: 0.244202, id: 0.241441] time: 2:16:28.124858 
[Epoch 23/50] [Batch 500/516] [D loss: 0.000050, acc: 100%] [G loss: 11.324521, adv: 0.976309, cyc: 0.250711, id: 0.246906] time: 2:17:36.679378 
[Epoch 24/50] [Batch 0/516] [D loss: 0.000137, acc: 100%] [G loss: 10.812702, adv: 0.892443, cyc: 0.241535, id: 0.231022] time: 2:17:47.647466 
[Epoch 24/50] [Batch 100/516] [D loss: 0.000228, acc: 100%] [G loss: 10.996017, adv: 0.960293, cyc: 0.243600, id: 0.234512] time: 2:18:56.194355 
[Epoch 24/50] [Batch 200/516] [D loss: 0.001149, acc: 100%] [G loss: 11.341272, adv: 0.967973, cyc: 0.251732, id: 0.256520] time: 2:20:04.745681 
[Epoch 24/50] [Batch 300/516] [D loss: 0.000329, acc: 100%] [G loss: 11.352748, adv: 0.960881, cyc: 0.251842, id: 0.253298] time: 2:21:13.301203 
[Epoch 24/50] [Batch 400/516] [D loss: 0.000527, acc: 100%] [G loss: 11.069682, adv: 0.986264, cyc: 0.243712, id: 0.239563] time: 2:22:21.844785 
[Epoch 24/50] [Batch 500/516] [D loss: 0.000259, acc: 100%] [G loss: 11.245655, adv: 0.957681, cyc: 0.249539, id: 0.246079] time: 2:23:30.401753 
[Epoch 25/50] [Batch 0/516] [D loss: 0.000152, acc: 100%] [G loss: 10.871385, adv: 0.956776, cyc: 0.240622, id: 0.230387] time: 2:23:41.372727 
[Epoch 25/50] [Batch 100/516] [D loss: 0.001370, acc: 100%] [G loss: 11.078938, adv: 1.002412, cyc: 0.242773, id: 0.234296] time: 2:24:49.919123 
[Epoch 25/50] [Batch 200/516] [D loss: 0.000265, acc: 100%] [G loss: 11.302491, adv: 0.928610, cyc: 0.252943, id: 0.256836] time: 2:25:58.463681 
[Epoch 25/50] [Batch 300/516] [D loss: 0.000593, acc: 100%] [G loss: 11.370654, adv: 0.992614, cyc: 0.250922, id: 0.251122] time: 2:27:07.008805 
[Epoch 25/50] [Batch 400/516] [D loss: 0.000547, acc: 100%] [G loss: 10.912198, adv: 0.920006, cyc: 0.242844, id: 0.239205] time: 2:28:15.556122 
[Epoch 25/50] [Batch 500/516] [D loss: 0.000257, acc: 100%] [G loss: 11.214662, adv: 0.973066, cyc: 0.247278, id: 0.244810] time: 2:29:24.111220 
[Epoch 26/50] [Batch 0/516] [D loss: 0.000442, acc: 100%] [G loss: 10.924318, adv: 1.007156, cyc: 0.238472, id: 0.228483] time: 2:29:36.136966 
[Epoch 26/50] [Batch 100/516] [D loss: 0.000456, acc: 100%] [G loss: 10.906385, adv: 0.971353, cyc: 0.239417, id: 0.232010] time: 2:30:44.699187 
[Epoch 26/50] [Batch 200/516] [D loss: 0.000088, acc: 100%] [G loss: 11.202251, adv: 0.974887, cyc: 0.247873, id: 0.251410] time: 2:31:53.258511 
[Epoch 26/50] [Batch 300/516] [D loss: 0.000196, acc: 100%] [G loss: 11.222579, adv: 0.946594, cyc: 0.249554, id: 0.251425] time: 2:33:01.853973 
[Epoch 26/50] [Batch 400/516] [D loss: 0.000053, acc: 100%] [G loss: 10.977839, adv: 0.997508, cyc: 0.241547, id: 0.236940] time: 2:34:10.421485 
[Epoch 26/50] [Batch 500/516] [D loss: 0.000410, acc: 100%] [G loss: 11.047116, adv: 0.923428, cyc: 0.246273, id: 0.243236] time: 2:35:18.981552 
[Epoch 27/50] [Batch 0/516] [D loss: 0.000128, acc: 100%] [G loss: 10.722961, adv: 0.931941, cyc: 0.237923, id: 0.228693] time: 2:35:29.950510 
[Epoch 27/50] [Batch 100/516] [D loss: 0.003300, acc: 100%] [G loss: 11.056998, adv: 1.016338, cyc: 0.241468, id: 0.232044] time: 2:36:38.501946 
[Epoch 27/50] [Batch 200/516] [D loss: 0.000261, acc: 100%] [G loss: 11.205308, adv: 1.002705, cyc: 0.246271, id: 0.251057] time: 2:37:47.062855 
[Epoch 27/50] [Batch 300/516] [D loss: 0.000080, acc: 100%] [G loss: 11.137054, adv: 0.958822, cyc: 0.246236, id: 0.248951] time: 2:38:55.611657 
[Epoch 27/50] [Batch 400/516] [D loss: 0.000157, acc: 100%] [G loss: 10.898790, adv: 0.959152, cyc: 0.239825, id: 0.236781] time: 2:40:04.161207 
[Epoch 27/50] [Batch 500/516] [D loss: 0.000283, acc: 100%] [G loss: 11.163910, adv: 0.974906, cyc: 0.246671, id: 0.242858] time: 2:41:12.715860 
[Epoch 28/50] [Batch 0/516] [D loss: 0.000567, acc: 100%] [G loss: 10.691187, adv: 0.953055, cyc: 0.235719, id: 0.226129] time: 2:41:23.683496 
[Epoch 28/50] [Batch 100/516] [D loss: 0.000321, acc: 100%] [G loss: 10.887316, adv: 0.971639, cyc: 0.240167, id: 0.232351] time: 2:42:32.233164 
[Epoch 28/50] [Batch 200/516] [D loss: 0.000264, acc: 100%] [G loss: 11.142520, adv: 0.976825, cyc: 0.244972, id: 0.252114] time: 2:43:40.793762 
[Epoch 28/50] [Batch 300/516] [D loss: 0.000270, acc: 100%] [G loss: 11.149861, adv: 0.977328, cyc: 0.245602, id: 0.248439] time: 2:44:49.354616 
[Epoch 28/50] [Batch 400/516] [D loss: 0.000778, acc: 100%] [G loss: 10.880389, adv: 0.981645, cyc: 0.238115, id: 0.235363] time: 2:45:57.911278 
[Epoch 28/50] [Batch 500/516] [D loss: 0.000261, acc: 100%] [G loss: 11.065148, adv: 0.973302, cyc: 0.243628, id: 0.240870] time: 2:47:06.459226 
[Epoch 29/50] [Batch 0/516] [D loss: 0.000105, acc: 100%] [G loss: 10.561928, adv: 0.895269, cyc: 0.234763, id: 0.225546] time: 2:47:17.429835 
[Epoch 29/50] [Batch 100/516] [D loss: 0.000206, acc: 100%] [G loss: 10.780020, adv: 0.970499, cyc: 0.237105, id: 0.229791] time: 2:48:25.987992 
[Epoch 29/50] [Batch 200/516] [D loss: 0.000146, acc: 100%] [G loss: 11.135271, adv: 0.982855, cyc: 0.244788, id: 0.249332] time: 2:49:34.541205 
[Epoch 29/50] [Batch 300/516] [D loss: 0.000120, acc: 100%] [G loss: 11.012816, adv: 0.916651, cyc: 0.245829, id: 0.246755] time: 2:50:43.097751 
[Epoch 29/50] [Batch 400/516] [D loss: 0.000078, acc: 100%] [G loss: 10.814506, adv: 0.949100, cyc: 0.238243, id: 0.235470] time: 2:51:51.658736 
[Epoch 29/50] [Batch 500/516] [D loss: 0.000078, acc: 100%] [G loss: 11.008774, adv: 0.950685, cyc: 0.242927, id: 0.240891] time: 2:53:00.210902 
[Epoch 30/50] [Batch 0/516] [D loss: 0.000146, acc: 100%] [G loss: 10.637054, adv: 0.934257, cyc: 0.234238, id: 0.224822] time: 2:53:11.181191 
[Epoch 30/50] [Batch 100/516] [D loss: 0.000381, acc: 100%] [G loss: 10.815922, adv: 0.997781, cyc: 0.235988, id: 0.228797] time: 2:54:19.749887 
[Epoch 30/50] [Batch 200/516] [D loss: 0.000111, acc: 100%] [G loss: 11.086382, adv: 1.002826, cyc: 0.242160, id: 0.248309] time: 2:55:28.310347 
[Epoch 30/50] [Batch 300/516] [D loss: 0.000253, acc: 100%] [G loss: 11.004445, adv: 0.950022, cyc: 0.242690, id: 0.245775] time: 2:56:36.877837 
[Epoch 30/50] [Batch 400/516] [D loss: 0.000114, acc: 100%] [G loss: 10.758733, adv: 0.971327, cyc: 0.236572, id: 0.233163] time: 2:57:45.438784 
[Epoch 30/50] [Batch 500/516] [D loss: 0.000159, acc: 100%] [G loss: 11.039161, adv: 0.976719, cyc: 0.242498, id: 0.240954] time: 2:58:54.002674 
[Epoch 31/50] [Batch 0/516] [D loss: 0.000206, acc: 100%] [G loss: 10.581970, adv: 0.970906, cyc: 0.231228, id: 0.223645] time: 2:59:06.320963 
[Epoch 31/50] [Batch 100/516] [D loss: 0.000099, acc: 100%] [G loss: 10.678779, adv: 0.973617, cyc: 0.234200, id: 0.227009] time: 3:00:14.883856 
[Epoch 31/50] [Batch 200/516] [D loss: 0.000164, acc: 100%] [G loss: 11.047242, adv: 1.007447, cyc: 0.241211, id: 0.247483] time: 3:01:23.441746 
[Epoch 31/50] [Batch 300/516] [D loss: 0.000938, acc: 100%] [G loss: 11.018726, adv: 0.960105, cyc: 0.243289, id: 0.244887] time: 3:02:31.992322 
[Epoch 31/50] [Batch 400/516] [D loss: 0.000156, acc: 100%] [G loss: 10.822777, adv: 0.985540, cyc: 0.236632, id: 0.235881] time: 3:03:40.557091 
[Epoch 31/50] [Batch 500/516] [D loss: 0.000184, acc: 100%] [G loss: 10.865229, adv: 0.946334, cyc: 0.239506, id: 0.238007] time: 3:04:49.120766 
[Epoch 32/50] [Batch 0/516] [D loss: 0.000103, acc: 100%] [G loss: 10.604011, adv: 0.983219, cyc: 0.231986, id: 0.222288] time: 3:05:00.089420 
[Epoch 32/50] [Batch 100/516] [D loss: 0.000068, acc: 100%] [G loss: 10.773963, adv: 1.003250, cyc: 0.235497, id: 0.227908] time: 3:06:08.653663 
[Epoch 32/50] [Batch 200/516] [D loss: 0.000170, acc: 100%] [G loss: 11.030975, adv: 0.976842, cyc: 0.242903, id: 0.247968] time: 3:07:17.232721 
[Epoch 32/50] [Batch 300/516] [D loss: 0.000103, acc: 100%] [G loss: 11.042820, adv: 0.984354, cyc: 0.242394, id: 0.245672] time: 3:08:25.785869 
[Epoch 32/50] [Batch 400/516] [D loss: 0.000185, acc: 100%] [G loss: 10.793743, adv: 0.987588, cyc: 0.236039, id: 0.233135] time: 3:09:34.350765 
[Epoch 32/50] [Batch 500/516] [D loss: 0.000069, acc: 100%] [G loss: 10.928974, adv: 0.966646, cyc: 0.239417, id: 0.237502] time: 3:10:42.903370 
[Epoch 33/50] [Batch 0/516] [D loss: 0.000098, acc: 100%] [G loss: 10.562675, adv: 0.957243, cyc: 0.230691, id: 0.222049] time: 3:10:53.872458 
[Epoch 33/50] [Batch 100/516] [D loss: 0.000072, acc: 100%] [G loss: 10.701197, adv: 0.999277, cyc: 0.232621, id: 0.226381] time: 3:12:02.424388 
[Epoch 33/50] [Batch 200/516] [D loss: 0.000050, acc: 100%] [G loss: 10.923809, adv: 0.966871, cyc: 0.240009, id: 0.245963] time: 3:13:10.980080 
[Epoch 33/50] [Batch 300/516] [D loss: 0.000155, acc: 100%] [G loss: 10.955073, adv: 0.969913, cyc: 0.240916, id: 0.243119] time: 3:14:19.539199 
[Epoch 33/50] [Batch 400/516] [D loss: 0.000121, acc: 100%] [G loss: 10.614168, adv: 0.959338, cyc: 0.232331, id: 0.230971] time: 3:15:28.103765 
[Epoch 33/50] [Batch 500/516] [D loss: 0.000148, acc: 100%] [G loss: 10.754504, adv: 0.906977, cyc: 0.238624, id: 0.236146] time: 3:16:36.671215 
[Epoch 34/50] [Batch 0/516] [D loss: 0.000191, acc: 100%] [G loss: 10.488003, adv: 0.978424, cyc: 0.228434, id: 0.220960] time: 3:16:47.639552 
[Epoch 34/50] [Batch 100/516] [D loss: 0.000149, acc: 100%] [G loss: 10.609070, adv: 0.973386, cyc: 0.231463, id: 0.226484] time: 3:17:56.185686 
[Epoch 34/50] [Batch 200/516] [D loss: 0.000061, acc: 100%] [G loss: 10.964886, adv: 0.990529, cyc: 0.239696, id: 0.245843] time: 3:19:04.741117 
[Epoch 34/50] [Batch 300/516] [D loss: 0.000381, acc: 100%] [G loss: 10.929471, adv: 0.977650, cyc: 0.240016, id: 0.241982] time: 3:20:13.289878 
[Epoch 34/50] [Batch 400/516] [D loss: 0.000275, acc: 100%] [G loss: 10.726384, adv: 1.004572, cyc: 0.233421, id: 0.231788] time: 3:21:21.843722 
[Epoch 34/50] [Batch 500/516] [D loss: 0.000121, acc: 100%] [G loss: 10.868272, adv: 0.997534, cyc: 0.236819, id: 0.235002] time: 3:22:30.399435 
[Epoch 35/50] [Batch 0/516] [D loss: 0.000113, acc: 100%] [G loss: 10.416699, adv: 0.940145, cyc: 0.228665, id: 0.220470] time: 3:22:41.367551 
[Epoch 35/50] [Batch 100/516] [D loss: 0.000041, acc: 100%] [G loss: 10.706354, adv: 0.992933, cyc: 0.233847, id: 0.227147] time: 3:23:49.928627 
[Epoch 35/50] [Batch 200/516] [D loss: 0.000261, acc: 100%] [G loss: 10.868516, adv: 0.987066, cyc: 0.237002, id: 0.244406] time: 3:24:58.490792 
[Epoch 35/50] [Batch 300/516] [D loss: 0.000252, acc: 100%] [G loss: 10.769099, adv: 0.908517, cyc: 0.238287, id: 0.242538] time: 3:26:07.045117 
[Epoch 35/50] [Batch 400/516] [D loss: 0.000177, acc: 100%] [G loss: 10.655442, adv: 0.949452, cyc: 0.233643, id: 0.232372] time: 3:27:15.605352 
[Epoch 35/50] [Batch 500/516] [D loss: 0.000093, acc: 100%] [G loss: 10.800289, adv: 0.944564, cyc: 0.237356, id: 0.236197] time: 3:28:24.164287 
[Epoch 36/50] [Batch 0/516] [D loss: 0.000089, acc: 100%] [G loss: 10.318287, adv: 0.906877, cyc: 0.228112, id: 0.219659] time: 3:28:36.517333 
[Epoch 36/50] [Batch 100/516] [D loss: 0.000149, acc: 100%] [G loss: 10.554591, adv: 0.989436, cyc: 0.229331, id: 0.224018] time: 3:29:45.078375 
[Epoch 36/50] [Batch 200/516] [D loss: 0.000220, acc: 100%] [G loss: 10.927931, adv: 0.984019, cyc: 0.238738, id: 0.244048] time: 3:30:53.634337 
[Epoch 36/50] [Batch 300/516] [D loss: 0.000057, acc: 100%] [G loss: 10.887913, adv: 0.970021, cyc: 0.239074, id: 0.241905] time: 3:32:02.185845 
[Epoch 36/50] [Batch 400/516] [D loss: 0.000185, acc: 100%] [G loss: 10.571145, adv: 0.955646, cyc: 0.231186, id: 0.230497] time: 3:33:10.735395 
[Epoch 36/50] [Batch 500/516] [D loss: 0.000270, acc: 100%] [G loss: 10.782322, adv: 0.984736, cyc: 0.235853, id: 0.233510] time: 3:34:19.312283 
[Epoch 37/50] [Batch 0/516] [D loss: 0.000232, acc: 100%] [G loss: 10.419257, adv: 0.966965, cyc: 0.226493, id: 0.218538] time: 3:34:30.279833 
[Epoch 37/50] [Batch 100/516] [D loss: 0.000062, acc: 100%] [G loss: 10.541742, adv: 0.974966, cyc: 0.229086, id: 0.223988] time: 3:35:38.833145 
[Epoch 37/50] [Batch 200/516] [D loss: 0.000233, acc: 100%] [G loss: 10.854136, adv: 0.990458, cyc: 0.236781, id: 0.242994] time: 3:36:47.387414 
[Epoch 37/50] [Batch 300/516] [D loss: 0.000089, acc: 100%] [G loss: 10.898115, adv: 0.982428, cyc: 0.238557, id: 0.241667] time: 3:37:55.939350 
[Epoch 37/50] [Batch 400/516] [D loss: 0.000062, acc: 100%] [G loss: 10.603246, adv: 0.982176, cyc: 0.230782, id: 0.229935] time: 3:39:04.490901 
[Epoch 37/50] [Batch 500/516] [D loss: 0.000099, acc: 100%] [G loss: 10.709860, adv: 0.939254, cyc: 0.234371, id: 0.233946] time: 3:40:13.027918 
[Epoch 38/50] [Batch 0/516] [D loss: 0.000134, acc: 100%] [G loss: 10.405047, adv: 0.985727, cyc: 0.226048, id: 0.218271] time: 3:40:23.996145 
[Epoch 38/50] [Batch 100/516] [D loss: 0.000134, acc: 100%] [G loss: 10.516439, adv: 0.962266, cyc: 0.229578, id: 0.223990] time: 3:41:32.552908 
[Epoch 38/50] [Batch 200/516] [D loss: 0.000037, acc: 100%] [G loss: 10.826298, adv: 0.983381, cyc: 0.236368, id: 0.242954] time: 3:42:41.107204 
[Epoch 38/50] [Batch 300/516] [D loss: 0.001405, acc: 100%] [G loss: 10.716198, adv: 0.932692, cyc: 0.235967, id: 0.239906] time: 3:43:49.673377 
[Epoch 38/50] [Batch 400/516] [D loss: 0.000230, acc: 100%] [G loss: 10.592918, adv: 0.982034, cyc: 0.229922, id: 0.229403] time: 3:44:58.239088 
[Epoch 38/50] [Batch 500/516] [D loss: 0.000067, acc: 100%] [G loss: 10.771721, adv: 1.000610, cyc: 0.234159, id: 0.233133] time: 3:46:06.790451 
[Epoch 39/50] [Batch 0/516] [D loss: 0.000142, acc: 100%] [G loss: 10.433784, adv: 0.989963, cyc: 0.225221, id: 0.217915] time: 3:46:17.759399 
[Epoch 39/50] [Batch 100/516] [D loss: 0.000060, acc: 100%] [G loss: 10.476697, adv: 0.995089, cyc: 0.226205, id: 0.223238] time: 3:47:26.313549 
[Epoch 39/50] [Batch 200/516] [D loss: 0.000103, acc: 100%] [G loss: 10.776091, adv: 0.966960, cyc: 0.236228, id: 0.242616] time: 3:48:34.870861 
[Epoch 39/50] [Batch 300/516] [D loss: 0.000169, acc: 100%] [G loss: 10.781801, adv: 0.980419, cyc: 0.235204, id: 0.239371] time: 3:49:43.414437 
[Epoch 39/50] [Batch 400/516] [D loss: 0.000034, acc: 100%] [G loss: 10.463580, adv: 0.942034, cyc: 0.228307, id: 0.227967] time: 3:50:51.966629 
[Epoch 39/50] [Batch 500/516] [D loss: 0.000050, acc: 100%] [G loss: 10.741586, adv: 0.965418, cyc: 0.234443, id: 0.233312] time: 3:52:00.517791 
[Epoch 40/50] [Batch 0/516] [D loss: 0.000279, acc: 100%] [G loss: 10.407230, adv: 1.008697, cyc: 0.224713, id: 0.217346] time: 3:52:11.485741 
[Epoch 40/50] [Batch 100/516] [D loss: 0.000107, acc: 100%] [G loss: 10.430229, adv: 0.957635, cyc: 0.226642, id: 0.222233] time: 3:53:20.049301 
[Epoch 40/50] [Batch 200/516] [D loss: 0.000103, acc: 100%] [G loss: 10.796688, adv: 1.013295, cyc: 0.233596, id: 0.241822] time: 3:54:28.613237 
[Epoch 40/50] [Batch 300/516] [D loss: 0.000049, acc: 100%] [G loss: 10.830814, adv: 1.009707, cyc: 0.234627, id: 0.239039] time: 3:55:37.161947 
[Epoch 40/50] [Batch 400/516] [D loss: 0.000053, acc: 100%] [G loss: 10.504065, adv: 0.996609, cyc: 0.227455, id: 0.227626] time: 3:56:45.712648 
[Epoch 40/50] [Batch 500/516] [D loss: 0.000051, acc: 100%] [G loss: 10.749932, adv: 0.985217, cyc: 0.233389, id: 0.232575] time: 3:57:54.264668 
[Epoch 41/50] [Batch 0/516] [D loss: 0.000191, acc: 100%] [G loss: 10.168871, adv: 0.902827, cyc: 0.222364, id: 0.216534] time: 3:58:06.551634 
[Epoch 41/50] [Batch 100/516] [D loss: 0.000065, acc: 100%] [G loss: 10.491632, adv: 1.000377, cyc: 0.225608, id: 0.222834] time: 3:59:15.087909 
[Epoch 41/50] [Batch 200/516] [D loss: 0.000046, acc: 100%] [G loss: 10.772068, adv: 1.003726, cyc: 0.233466, id: 0.241844] time: 4:00:23.621153 
[Epoch 41/50] [Batch 300/516] [D loss: 0.000066, acc: 100%] [G loss: 10.768639, adv: 0.973052, cyc: 0.235744, id: 0.239455] time: 4:01:32.157681 
[Epoch 41/50] [Batch 400/516] [D loss: 0.000075, acc: 100%] [G loss: 10.266524, adv: 0.875238, cyc: 0.226843, id: 0.226424] time: 4:02:40.692305 
[Epoch 41/50] [Batch 500/516] [D loss: 0.000070, acc: 100%] [G loss: 10.629948, adv: 0.968710, cyc: 0.231237, id: 0.231039] time: 4:03:49.233892 
[Epoch 42/50] [Batch 0/516] [D loss: 0.000028, acc: 100%] [G loss: 10.268478, adv: 0.986043, cyc: 0.222319, id: 0.215059] time: 4:04:00.201492 
[Epoch 42/50] [Batch 100/516] [D loss: 0.000108, acc: 100%] [G loss: 10.364959, adv: 0.951192, cyc: 0.225247, id: 0.222631] time: 4:05:08.733842 
[Epoch 42/50] [Batch 200/516] [D loss: 0.000310, acc: 100%] [G loss: 10.680434, adv: 0.979591, cyc: 0.232148, id: 0.240144] time: 4:06:17.269643 
[Epoch 42/50] [Batch 300/516] [D loss: 0.000139, acc: 100%] [G loss: 10.766365, adv: 0.998797, cyc: 0.233660, id: 0.238263] time: 4:07:25.821003 
[Epoch 42/50] [Batch 400/516] [D loss: 0.000417, acc: 100%] [G loss: 10.467194, adv: 0.995666, cyc: 0.225781, id: 0.227064] time: 4:08:34.351303 
[Epoch 42/50] [Batch 500/516] [D loss: 0.000062, acc: 100%] [G loss: 10.729818, adv: 0.993625, cyc: 0.233651, id: 0.232685] time: 4:09:42.890103 
[Epoch 43/50] [Batch 0/516] [D loss: 0.001741, acc: 100%] [G loss: 10.246020, adv: 0.975730, cyc: 0.221482, id: 0.215874] time: 4:09:53.856086 
[Epoch 43/50] [Batch 100/516] [D loss: 0.000090, acc: 100%] [G loss: 10.381178, adv: 0.972412, cyc: 0.224659, id: 0.221631] time: 4:11:02.392067 
[Epoch 43/50] [Batch 200/516] [D loss: 0.000023, acc: 100%] [G loss: 10.719827, adv: 1.000980, cyc: 0.231628, id: 0.240549] time: 4:12:10.923445 
[Epoch 43/50] [Batch 300/516] [D loss: 0.000099, acc: 100%] [G loss: 10.664130, adv: 0.945576, cyc: 0.234029, id: 0.238366] time: 4:13:19.457445 
[Epoch 43/50] [Batch 400/516] [D loss: 0.000159, acc: 100%] [G loss: 10.415573, adv: 0.988886, cyc: 0.225355, id: 0.225504] time: 4:14:27.997750 
[Epoch 43/50] [Batch 500/516] [D loss: 0.000011, acc: 100%] [G loss: 10.637224, adv: 0.988967, cyc: 0.231125, id: 0.230465] time: 4:15:36.541179 
[Epoch 44/50] [Batch 0/516] [D loss: 0.000123, acc: 100%] [G loss: 10.275269, adv: 1.003424, cyc: 0.221383, id: 0.214958] time: 4:15:47.508375 
[Epoch 44/50] [Batch 100/516] [D loss: 0.000073, acc: 100%] [G loss: 10.378296, adv: 0.984723, cyc: 0.224846, id: 0.220730] time: 4:16:56.028929 
[Epoch 44/50] [Batch 200/516] [D loss: 0.000040, acc: 100%] [G loss: 10.724335, adv: 1.003703, cyc: 0.231444, id: 0.240830] time: 4:18:04.559669 
[Epoch 44/50] [Batch 300/516] [D loss: 0.000072, acc: 100%] [G loss: 10.765970, adv: 0.997825, cyc: 0.233285, id: 0.238182] time: 4:19:13.097513 
[Epoch 44/50] [Batch 400/516] [D loss: 0.000079, acc: 100%] [G loss: 10.419523, adv: 0.964022, cyc: 0.225430, id: 0.226928] time: 4:20:21.629345 
[Epoch 44/50] [Batch 500/516] [D loss: 0.000053, acc: 100%] [G loss: 10.676781, adv: 1.004330, cyc: 0.231390, id: 0.231395] time: 4:21:30.160039 
[Epoch 45/50] [Batch 0/516] [D loss: 0.000046, acc: 100%] [G loss: 10.314790, adv: 1.015329, cyc: 0.222192, id: 0.214900] time: 4:21:41.126220 
[Epoch 45/50] [Batch 100/516] [D loss: 0.000367, acc: 100%] [G loss: 10.342014, adv: 0.973317, cyc: 0.224459, id: 0.220365] time: 4:22:49.650843 
[Epoch 45/50] [Batch 200/516] [D loss: 0.000044, acc: 100%] [G loss: 10.638023, adv: 0.984390, cyc: 0.230957, id: 0.239459] time: 4:23:58.194634 
[Epoch 45/50] [Batch 300/516] [D loss: 0.000037, acc: 100%] [G loss: 10.677640, adv: 0.983638, cyc: 0.232499, id: 0.236275] time: 4:25:06.725344 
[Epoch 45/50] [Batch 400/516] [D loss: 0.000129, acc: 100%] [G loss: 10.362222, adv: 0.974589, cyc: 0.224253, id: 0.224511] time: 4:26:15.254412 
[Epoch 45/50] [Batch 500/516] [D loss: 0.000093, acc: 100%] [G loss: 10.599485, adv: 0.990806, cyc: 0.230018, id: 0.230307] time: 4:27:23.783310 
[Epoch 46/50] [Batch 0/516] [D loss: 0.000143, acc: 100%] [G loss: 10.234566, adv: 0.999457, cyc: 0.220279, id: 0.214383] time: 4:27:35.834243 
[Epoch 46/50] [Batch 100/516] [D loss: 0.000079, acc: 100%] [G loss: 10.295177, adv: 0.970915, cyc: 0.222676, id: 0.219338] time: 4:28:44.366515 
[Epoch 46/50] [Batch 200/516] [D loss: 0.000096, acc: 100%] [G loss: 10.621829, adv: 0.989186, cyc: 0.230239, id: 0.238172] time: 4:29:52.902922 
[Epoch 46/50] [Batch 300/516] [D loss: 0.000087, acc: 100%] [G loss: 10.636759, adv: 0.987881, cyc: 0.230615, id: 0.236472] time: 4:31:01.431160 
[Epoch 46/50] [Batch 400/516] [D loss: 0.000050, acc: 100%] [G loss: 10.375909, adv: 0.978136, cyc: 0.224717, id: 0.224598] time: 4:32:09.957001 
[Epoch 46/50] [Batch 500/516] [D loss: 0.000052, acc: 100%] [G loss: 10.583996, adv: 0.972331, cyc: 0.230177, id: 0.229733] time: 4:33:18.490402 
[Epoch 47/50] [Batch 0/516] [D loss: 0.000057, acc: 100%] [G loss: 10.217715, adv: 1.000045, cyc: 0.218613, id: 0.215186] time: 4:33:29.457838 
[Epoch 47/50] [Batch 100/516] [D loss: 0.000144, acc: 100%] [G loss: 10.345895, adv: 0.995158, cyc: 0.222711, id: 0.220020] time: 4:34:37.992295 
[Epoch 47/50] [Batch 200/516] [D loss: 0.000020, acc: 100%] [G loss: 10.613234, adv: 1.000468, cyc: 0.229806, id: 0.237735] time: 4:35:46.526093 
[Epoch 47/50] [Batch 300/516] [D loss: 0.000183, acc: 100%] [G loss: 10.653087, adv: 0.986117, cyc: 0.231148, id: 0.236596] time: 4:36:55.061471 
[Epoch 47/50] [Batch 400/516] [D loss: 0.000167, acc: 100%] [G loss: 10.404684, adv: 1.006984, cyc: 0.223557, id: 0.225180] time: 4:38:03.587741 
[Epoch 47/50] [Batch 500/516] [D loss: 0.000104, acc: 100%] [G loss: 10.631404, adv: 1.012594, cyc: 0.229330, id: 0.230401] time: 4:39:12.122192 
[Epoch 48/50] [Batch 0/516] [D loss: 0.000213, acc: 100%] [G loss: 10.297343, adv: 1.023180, cyc: 0.220140, id: 0.216117] time: 4:39:23.088985 
[Epoch 48/50] [Batch 100/516] [D loss: 0.000097, acc: 100%] [G loss: 10.254076, adv: 0.967953, cyc: 0.222201, id: 0.217515] time: 4:40:31.620190 
[Epoch 48/50] [Batch 200/516] [D loss: 0.000032, acc: 100%] [G loss: 10.601142, adv: 0.999824, cyc: 0.229274, id: 0.237765] time: 4:41:40.153518 
[Epoch 48/50] [Batch 300/516] [D loss: 0.000039, acc: 100%] [G loss: 10.669923, adv: 1.009775, cyc: 0.230808, id: 0.235996] time: 4:42:48.692253 
[Epoch 48/50] [Batch 400/516] [D loss: 0.000050, acc: 100%] [G loss: 10.197030, adv: 0.924012, cyc: 0.222803, id: 0.223480] time: 4:43:57.238305 
[Epoch 48/50] [Batch 500/516] [D loss: 0.000166, acc: 100%] [G loss: 10.392797, adv: 0.903465, cyc: 0.228684, id: 0.229618] time: 4:45:05.778217 
[Epoch 49/50] [Batch 0/516] [D loss: 0.000073, acc: 100%] [G loss: 10.148655, adv: 0.982046, cyc: 0.219413, id: 0.212587] time: 4:45:16.740612 
[Epoch 49/50] [Batch 100/516] [D loss: 0.000038, acc: 100%] [G loss: 10.316848, adv: 1.010115, cyc: 0.221279, id: 0.218105] time: 4:46:25.266953 
[Epoch 49/50] [Batch 200/516] [D loss: 0.000073, acc: 100%] [G loss: 10.520575, adv: 0.985824, cyc: 0.227567, id: 0.236853] time: 4:47:33.801917 
[Epoch 49/50] [Batch 300/516] [D loss: 0.000076, acc: 100%] [G loss: 10.655005, adv: 1.019408, cyc: 0.229218, id: 0.235231] time: 4:48:42.333651 
[Epoch 49/50] [Batch 400/516] [D loss: 0.000031, acc: 100%] [G loss: 10.245926, adv: 0.962395, cyc: 0.221850, id: 0.223308] time: 4:49:50.861908 
[Epoch 49/50] [Batch 500/516] [D loss: 0.000015, acc: 100%] [G loss: 10.475070, adv: 0.975351, cyc: 0.226787, id: 0.228066] time: 4:50:59.396418 
[Epoch 50/50] [Batch 0/516] [D loss: 0.000021, acc: 100%] [G loss: 10.144762, adv: 0.995487, cyc: 0.218324, id: 0.212556] time: 4:51:10.360067 
[Epoch 50/50] [Batch 100/516] [D loss: 0.000104, acc: 100%] [G loss: 10.206275, adv: 0.960473, cyc: 0.221179, id: 0.217492] time: 4:52:18.892398 
[Epoch 50/50] [Batch 200/516] [D loss: 0.000066, acc: 100%] [G loss: 10.446179, adv: 0.928518, cyc: 0.227935, id: 0.238053] time: 4:53:27.430220 
[Epoch 50/50] [Batch 300/516] [D loss: 0.000060, acc: 100%] [G loss: 10.643754, adv: 0.985643, cyc: 0.231306, id: 0.235901] time: 4:54:35.955038 
[Epoch 50/50] [Batch 400/516] [D loss: 0.000140, acc: 100%] [G loss: 10.289416, adv: 0.994174, cyc: 0.221312, id: 0.222175] time: 4:55:44.480213 
[Epoch 50/50] [Batch 500/516] [D loss: 0.000054, acc: 100%] [G loss: 10.516115, adv: 0.982499, cyc: 0.227390, id: 0.229497] time: 4:56:53.019500 
Train Finished.
