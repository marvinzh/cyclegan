_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_A_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_B_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
ivec_b (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
ivec_a (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
model_4 (Model)                 (None, 1, 600, 1)    653345      ivec_b[0][0]                     
                                                                 model_3[1][0]                    
                                                                 ivec_a[0][0]                     
__________________________________________________________________________________________________
model_3 (Model)                 (None, 1, 600, 1)    653345      ivec_a[0][0]                     
                                                                 model_4[1][0]                    
                                                                 ivec_b[0][0]                     
__________________________________________________________________________________________________
model_2 (Model)                 (None, 1)            39610241    model_4[1][0]                    
__________________________________________________________________________________________________
model_1 (Model)                 (None, 1)            39610241    model_3[1][0]                    
==================================================================================================
Total params: 80,527,172
Trainable params: 1,306,690
Non-trainable params: 79,220,482
__________________________________________________________________________________________________
Start CycleGAN training.
[Epoch 1/50] [Batch 0/516] [D loss: 15.277636, acc:   0%] [G loss: 38.444469, adv: 0.647420, cyc: 0.937155, id: 0.969390] time: 0:02:02.431334 
[Epoch 1/50] [Batch 100/516] [D loss: 0.051946, acc:  94%] [G loss: 21.619356, adv: 0.934087, cyc: 0.549197, id: 0.480870] time: 0:03:10.733260 
[Epoch 1/50] [Batch 200/516] [D loss: 0.021064, acc:  99%] [G loss: 19.699726, adv: 0.960175, cyc: 0.492157, id: 0.444471] time: 0:04:19.010159 
[Epoch 1/50] [Batch 300/516] [D loss: 0.022257, acc:  99%] [G loss: 18.054028, adv: 0.962067, cyc: 0.448715, id: 0.396348] time: 0:05:27.259691 
[Epoch 1/50] [Batch 400/516] [D loss: 0.013710, acc: 100%] [G loss: 17.198109, adv: 0.906576, cyc: 0.424755, id: 0.384337] time: 0:06:35.498792 
[Epoch 1/50] [Batch 500/516] [D loss: 0.015579, acc:  99%] [G loss: 17.055408, adv: 0.889707, cyc: 0.419076, id: 0.378751] time: 0:07:43.713224 
[Epoch 2/50] [Batch 0/516] [D loss: 0.019728, acc:  99%] [G loss: 16.878902, adv: 1.045119, cyc: 0.408457, id: 0.365329] time: 0:07:54.624349 
[Epoch 2/50] [Batch 100/516] [D loss: 0.014427, acc:  99%] [G loss: 16.133675, adv: 0.843076, cyc: 0.396639, id: 0.361056] time: 0:09:02.839794 
[Epoch 2/50] [Batch 200/516] [D loss: 0.020129, acc: 100%] [G loss: 16.349836, adv: 1.038850, cyc: 0.390587, id: 0.367355] time: 0:10:11.063424 
[Epoch 2/50] [Batch 300/516] [D loss: 0.005705, acc: 100%] [G loss: 15.278139, adv: 0.897715, cyc: 0.370541, id: 0.340426] time: 0:11:19.255593 
[Epoch 2/50] [Batch 400/516] [D loss: 0.007487, acc: 100%] [G loss: 15.137732, adv: 1.000970, cyc: 0.359193, id: 0.334359] time: 0:12:27.438662 
[Epoch 2/50] [Batch 500/516] [D loss: 0.003399, acc: 100%] [G loss: 15.264290, adv: 0.955327, cyc: 0.365155, id: 0.335500] time: 0:13:35.635406 
[Epoch 3/50] [Batch 0/516] [D loss: 0.003816, acc: 100%] [G loss: 14.956957, adv: 0.919120, cyc: 0.357265, id: 0.327379] time: 0:13:46.544554 
[Epoch 3/50] [Batch 100/516] [D loss: 0.007789, acc: 100%] [G loss: 15.009983, adv: 1.034103, cyc: 0.355045, id: 0.322971] time: 0:14:54.730877 
[Epoch 3/50] [Batch 200/516] [D loss: 0.006740, acc: 100%] [G loss: 14.719732, adv: 0.821212, cyc: 0.353901, id: 0.340079] time: 0:16:02.908597 
[Epoch 3/50] [Batch 300/516] [D loss: 0.004928, acc: 100%] [G loss: 14.055985, adv: 0.867749, cyc: 0.337469, id: 0.309851] time: 0:17:11.074204 
[Epoch 3/50] [Batch 400/516] [D loss: 0.003707, acc: 100%] [G loss: 13.906504, adv: 0.879188, cyc: 0.330810, id: 0.309875] time: 0:18:19.253429 
[Epoch 3/50] [Batch 500/516] [D loss: 0.002136, acc: 100%] [G loss: 14.347804, adv: 0.947422, cyc: 0.338675, id: 0.316095] time: 0:19:27.442561 
[Epoch 4/50] [Batch 0/516] [D loss: 0.004400, acc: 100%] [G loss: 14.128141, adv: 0.941444, cyc: 0.332825, id: 0.309195] time: 0:19:38.354925 
[Epoch 4/50] [Batch 100/516] [D loss: 0.002236, acc: 100%] [G loss: 14.078230, adv: 0.938047, cyc: 0.332446, id: 0.309554] time: 0:20:46.537583 
[Epoch 4/50] [Batch 200/516] [D loss: 0.002338, acc: 100%] [G loss: 14.150023, adv: 0.924199, cyc: 0.333238, id: 0.322810] time: 0:21:54.712428 
[Epoch 4/50] [Batch 300/516] [D loss: 0.008714, acc: 100%] [G loss: 13.658186, adv: 0.952753, cyc: 0.321766, id: 0.296726] time: 0:23:02.904502 
[Epoch 4/50] [Batch 400/516] [D loss: 0.002620, acc: 100%] [G loss: 13.451280, adv: 0.935838, cyc: 0.316763, id: 0.296829] time: 0:24:11.076003 
[Epoch 4/50] [Batch 500/516] [D loss: 0.003202, acc: 100%] [G loss: 13.770425, adv: 0.885100, cyc: 0.325208, id: 0.307310] time: 0:25:19.308581 
[Epoch 5/50] [Batch 0/516] [D loss: 0.005161, acc: 100%] [G loss: 13.862730, adv: 1.042190, cyc: 0.319632, id: 0.300023] time: 0:25:30.216956 
[Epoch 5/50] [Batch 100/516] [D loss: 0.001704, acc: 100%] [G loss: 13.573280, adv: 0.912616, cyc: 0.319517, id: 0.300069] time: 0:26:38.398128 
[Epoch 5/50] [Batch 200/516] [D loss: 0.001553, acc: 100%] [G loss: 13.810367, adv: 0.975212, cyc: 0.320677, id: 0.312986] time: 0:27:46.575836 
[Epoch 5/50] [Batch 300/516] [D loss: 0.002631, acc: 100%] [G loss: 13.346518, adv: 0.981194, cyc: 0.310385, id: 0.291104] time: 0:28:54.790869 
[Epoch 5/50] [Batch 400/516] [D loss: 0.002665, acc: 100%] [G loss: 13.109487, adv: 0.953780, cyc: 0.306319, id: 0.288188] time: 0:30:02.988458 
[Epoch 5/50] [Batch 500/516] [D loss: 0.001283, acc: 100%] [G loss: 13.570591, adv: 0.980031, cyc: 0.314699, id: 0.297954] time: 0:31:11.173012 
[Epoch 6/50] [Batch 0/516] [D loss: 0.002843, acc: 100%] [G loss: 13.220660, adv: 0.934254, cyc: 0.308705, id: 0.289288] time: 0:31:28.092502 
[Epoch 6/50] [Batch 100/516] [D loss: 0.001174, acc: 100%] [G loss: 13.348431, adv: 0.989030, cyc: 0.309733, id: 0.290669] time: 0:32:36.275910 
[Epoch 6/50] [Batch 200/516] [D loss: 0.004259, acc: 100%] [G loss: 13.481281, adv: 0.964879, cyc: 0.312284, id: 0.305648] time: 0:33:44.478495 
[Epoch 6/50] [Batch 300/516] [D loss: 0.001680, acc: 100%] [G loss: 12.988716, adv: 0.943541, cyc: 0.303091, id: 0.282488] time: 0:34:52.660694 
[Epoch 6/50] [Batch 400/516] [D loss: 0.002457, acc: 100%] [G loss: 12.677679, adv: 0.891988, cyc: 0.297096, id: 0.282355] time: 0:36:00.851448 
[Epoch 6/50] [Batch 500/516] [D loss: 0.003257, acc: 100%] [G loss: 13.341149, adv: 0.991805, cyc: 0.306840, id: 0.295518] time: 0:37:09.019239 
[Epoch 7/50] [Batch 0/516] [D loss: 0.002570, acc: 100%] [G loss: 13.015793, adv: 0.960275, cyc: 0.300467, id: 0.286701] time: 0:37:19.923477 
[Epoch 7/50] [Batch 100/516] [D loss: 0.001876, acc: 100%] [G loss: 13.070707, adv: 0.970467, cyc: 0.302949, id: 0.285083] time: 0:38:28.097831 
[Epoch 7/50] [Batch 200/516] [D loss: 0.000840, acc: 100%] [G loss: 13.136949, adv: 0.927346, cyc: 0.305288, id: 0.299582] time: 0:39:36.262653 
[Epoch 7/50] [Batch 300/516] [D loss: 0.001150, acc: 100%] [G loss: 12.714454, adv: 0.966853, cyc: 0.292947, id: 0.276968] time: 0:40:44.415083 
[Epoch 7/50] [Batch 400/516] [D loss: 0.001734, acc: 100%] [G loss: 12.596662, adv: 0.960720, cyc: 0.290403, id: 0.278534] time: 0:41:52.574212 
[Epoch 7/50] [Batch 500/516] [D loss: 0.002648, acc: 100%] [G loss: 12.935038, adv: 0.923600, cyc: 0.299552, id: 0.288503] time: 0:43:00.705828 
[Epoch 8/50] [Batch 0/516] [D loss: 0.002215, acc: 100%] [G loss: 12.619389, adv: 0.887698, cyc: 0.294596, id: 0.277823] time: 0:43:11.606486 
[Epoch 8/50] [Batch 100/516] [D loss: 0.002271, acc: 100%] [G loss: 12.826956, adv: 1.007119, cyc: 0.293039, id: 0.279027] time: 0:44:19.719696 
[Epoch 8/50] [Batch 200/516] [D loss: 0.002094, acc: 100%] [G loss: 12.982956, adv: 0.974643, cyc: 0.298494, id: 0.292787] time: 0:45:27.815456 
[Epoch 8/50] [Batch 300/516] [D loss: 0.001286, acc: 100%] [G loss: 12.583244, adv: 0.994014, cyc: 0.287483, id: 0.273395] time: 0:46:35.927260 
[Epoch 8/50] [Batch 400/516] [D loss: 0.000937, acc: 100%] [G loss: 12.383536, adv: 0.991648, cyc: 0.281950, id: 0.274427] time: 0:47:44.020711 
[Epoch 8/50] [Batch 500/516] [D loss: 0.003884, acc: 100%] [G loss: 13.002466, adv: 1.071227, cyc: 0.294472, id: 0.281320] time: 0:48:52.110613 
[Epoch 9/50] [Batch 0/516] [D loss: 0.001376, acc: 100%] [G loss: 12.678219, adv: 0.992373, cyc: 0.291024, id: 0.274209] time: 0:49:03.004065 
[Epoch 9/50] [Batch 100/516] [D loss: 0.000757, acc: 100%] [G loss: 12.570431, adv: 0.970438, cyc: 0.287867, id: 0.274921] time: 0:50:11.104729 
[Epoch 9/50] [Batch 200/516] [D loss: 0.000905, acc: 100%] [G loss: 12.888734, adv: 1.004146, cyc: 0.293811, id: 0.289380] time: 0:51:19.208845 
[Epoch 9/50] [Batch 300/516] [D loss: 0.000818, acc: 100%] [G loss: 12.251282, adv: 0.925075, cyc: 0.282995, id: 0.267731] time: 0:52:27.299482 
[Epoch 9/50] [Batch 400/516] [D loss: 0.002372, acc: 100%] [G loss: 12.224162, adv: 0.943037, cyc: 0.280927, id: 0.271376] time: 0:53:35.413946 
[Epoch 9/50] [Batch 500/516] [D loss: 0.000612, acc: 100%] [G loss: 12.743595, adv: 0.971091, cyc: 0.292406, id: 0.281036] time: 0:54:43.544099 
[Epoch 10/50] [Batch 0/516] [D loss: 0.001122, acc: 100%] [G loss: 12.395450, adv: 0.970396, cyc: 0.283849, id: 0.269581] time: 0:54:54.441954 
[Epoch 10/50] [Batch 100/516] [D loss: 0.000919, acc: 100%] [G loss: 12.540979, adv: 1.012898, cyc: 0.285514, id: 0.271477] time: 0:56:02.550785 
[Epoch 10/50] [Batch 200/516] [D loss: 0.002193, acc: 100%] [G loss: 12.583028, adv: 0.935000, cyc: 0.289563, id: 0.285477] time: 0:57:10.656311 
[Epoch 10/50] [Batch 300/516] [D loss: 0.000395, acc: 100%] [G loss: 12.229198, adv: 1.003342, cyc: 0.276795, id: 0.265704] time: 0:58:18.761100 
[Epoch 10/50] [Batch 400/516] [D loss: 0.001598, acc: 100%] [G loss: 12.113617, adv: 0.985524, cyc: 0.274614, id: 0.268728] time: 0:59:26.871440 
[Epoch 10/50] [Batch 500/516] [D loss: 0.001024, acc: 100%] [G loss: 12.479291, adv: 0.955192, cyc: 0.286568, id: 0.274784] time: 1:00:34.984998 
[Epoch 11/50] [Batch 0/516] [D loss: 0.000857, acc: 100%] [G loss: 12.260178, adv: 0.969168, cyc: 0.279097, id: 0.267540] time: 1:00:47.199399 
[Epoch 11/50] [Batch 100/516] [D loss: 0.001995, acc: 100%] [G loss: 12.183670, adv: 0.907136, cyc: 0.280448, id: 0.268653] time: 1:01:55.320514 
[Epoch 11/50] [Batch 200/516] [D loss: 0.001057, acc: 100%] [G loss: 12.509748, adv: 0.962150, cyc: 0.286806, id: 0.282080] time: 1:03:03.444531 
[Epoch 11/50] [Batch 300/516] [D loss: 0.000353, acc: 100%] [G loss: 12.049159, adv: 0.973527, cyc: 0.272879, id: 0.263454] time: 1:04:11.558009 
[Epoch 11/50] [Batch 400/516] [D loss: 0.000170, acc: 100%] [G loss: 11.836529, adv: 0.941412, cyc: 0.269436, id: 0.263564] time: 1:05:19.673228 
[Epoch 11/50] [Batch 500/516] [D loss: 0.000814, acc: 100%] [G loss: 12.485760, adv: 1.011633, cyc: 0.282766, id: 0.273682] time: 1:06:27.793015 
[Epoch 12/50] [Batch 0/516] [D loss: 0.000305, acc: 100%] [G loss: 12.121536, adv: 0.969045, cyc: 0.275034, id: 0.264671] time: 1:06:38.692766 
[Epoch 12/50] [Batch 100/516] [D loss: 0.000413, acc: 100%] [G loss: 12.203995, adv: 0.940935, cyc: 0.278622, id: 0.269101] time: 1:07:46.800460 
[Epoch 12/50] [Batch 200/516] [D loss: 0.000287, acc: 100%] [G loss: 12.425580, adv: 1.003270, cyc: 0.280698, id: 0.280028] time: 1:08:54.908080 
[Epoch 12/50] [Batch 300/516] [D loss: 0.000592, acc: 100%] [G loss: 11.924615, adv: 0.968619, cyc: 0.269517, id: 0.261700] time: 1:10:03.021038 
[Epoch 12/50] [Batch 400/516] [D loss: 0.001137, acc: 100%] [G loss: 11.826153, adv: 0.984077, cyc: 0.266721, id: 0.261691] time: 1:11:11.120923 
[Epoch 12/50] [Batch 500/516] [D loss: 0.000334, acc: 100%] [G loss: 12.226226, adv: 0.926911, cyc: 0.279824, id: 0.270948] time: 1:12:19.225640 
[Epoch 13/50] [Batch 0/516] [D loss: 0.000534, acc: 100%] [G loss: 12.025232, adv: 0.968337, cyc: 0.271990, id: 0.263467] time: 1:12:30.128893 
[Epoch 13/50] [Batch 100/516] [D loss: 0.001889, acc: 100%] [G loss: 12.078488, adv: 0.979959, cyc: 0.273087, id: 0.263055] time: 1:13:38.237352 
[Epoch 13/50] [Batch 200/516] [D loss: 0.001476, acc: 100%] [G loss: 12.322115, adv: 1.002587, cyc: 0.278133, id: 0.276719] time: 1:14:46.349249 
[Epoch 13/50] [Batch 300/516] [D loss: 0.000856, acc: 100%] [G loss: 11.879469, adv: 0.995740, cyc: 0.266823, id: 0.258127] time: 1:15:54.450331 
[Epoch 13/50] [Batch 400/516] [D loss: 0.000553, acc: 100%] [G loss: 11.729191, adv: 1.005545, cyc: 0.262370, id: 0.258776] time: 1:17:02.545838 
[Epoch 13/50] [Batch 500/516] [D loss: 0.000448, acc: 100%] [G loss: 12.210750, adv: 0.950763, cyc: 0.277660, id: 0.271498] time: 1:18:10.637628 
[Epoch 14/50] [Batch 0/516] [D loss: 0.000205, acc: 100%] [G loss: 11.940386, adv: 0.967798, cyc: 0.269705, id: 0.261090] time: 1:18:21.533732 
[Epoch 14/50] [Batch 100/516] [D loss: 0.000981, acc: 100%] [G loss: 11.975041, adv: 0.985307, cyc: 0.269114, id: 0.262614] time: 1:19:29.643273 
[Epoch 14/50] [Batch 200/516] [D loss: 0.000420, acc: 100%] [G loss: 12.152202, adv: 0.971887, cyc: 0.274935, id: 0.275536] time: 1:20:37.770328 
[Epoch 14/50] [Batch 300/516] [D loss: 0.000932, acc: 100%] [G loss: 11.693696, adv: 0.969161, cyc: 0.262538, id: 0.257163] time: 1:21:45.880164 
[Epoch 14/50] [Batch 400/516] [D loss: 0.000205, acc: 100%] [G loss: 11.621034, adv: 0.970137, cyc: 0.261203, id: 0.257939] time: 1:22:53.978393 
[Epoch 14/50] [Batch 500/516] [D loss: 0.000460, acc: 100%] [G loss: 12.043453, adv: 0.969230, cyc: 0.272756, id: 0.265331] time: 1:24:02.079878 
[Epoch 15/50] [Batch 0/516] [D loss: 0.000319, acc: 100%] [G loss: 11.797330, adv: 0.941825, cyc: 0.267080, id: 0.259630] time: 1:24:12.978030 
[Epoch 15/50] [Batch 100/516] [D loss: 0.001030, acc: 100%] [G loss: 11.820628, adv: 0.976410, cyc: 0.264331, id: 0.260262] time: 1:25:21.071359 
[Epoch 15/50] [Batch 200/516] [D loss: 0.000650, acc: 100%] [G loss: 11.981831, adv: 0.951787, cyc: 0.270624, id: 0.272763] time: 1:26:29.189334 
[Epoch 15/50] [Batch 300/516] [D loss: 0.000278, acc: 100%] [G loss: 11.685772, adv: 0.986587, cyc: 0.262587, id: 0.254076] time: 1:27:37.279864 
[Epoch 15/50] [Batch 400/516] [D loss: 0.001175, acc: 100%] [G loss: 11.423106, adv: 0.926247, cyc: 0.258257, id: 0.255293] time: 1:28:45.371614 
[Epoch 15/50] [Batch 500/516] [D loss: 0.000505, acc: 100%] [G loss: 12.011890, adv: 0.974369, cyc: 0.269274, id: 0.268682] time: 1:29:53.480484 
[Epoch 16/50] [Batch 0/516] [D loss: 0.000415, acc: 100%] [G loss: 11.750689, adv: 0.988222, cyc: 0.263243, id: 0.255957] time: 1:30:13.874941 
[Epoch 16/50] [Batch 100/516] [D loss: 0.000159, acc: 100%] [G loss: 11.736545, adv: 0.954821, cyc: 0.264357, id: 0.258554] time: 1:31:21.979428 
[Epoch 16/50] [Batch 200/516] [D loss: 0.000922, acc: 100%] [G loss: 11.965087, adv: 0.964337, cyc: 0.269146, id: 0.272382] time: 1:32:30.085530 
[Epoch 16/50] [Batch 300/516] [D loss: 0.001023, acc: 100%] [G loss: 11.407885, adv: 0.909041, cyc: 0.257964, id: 0.251970] time: 1:33:38.192325 
[Epoch 16/50] [Batch 400/516] [D loss: 0.000320, acc: 100%] [G loss: 11.534192, adv: 1.019280, cyc: 0.256292, id: 0.252723] time: 1:34:46.298418 
[Epoch 16/50] [Batch 500/516] [D loss: 0.000419, acc: 100%] [G loss: 11.841504, adv: 0.959786, cyc: 0.267425, id: 0.261487] time: 1:35:54.401377 
[Epoch 17/50] [Batch 0/516] [D loss: 0.000509, acc: 100%] [G loss: 11.647863, adv: 0.953920, cyc: 0.263579, id: 0.254558] time: 1:36:05.303018 
[Epoch 17/50] [Batch 100/516] [D loss: 0.000409, acc: 100%] [G loss: 11.673075, adv: 0.969299, cyc: 0.261914, id: 0.255955] time: 1:37:13.405007 
[Epoch 17/50] [Batch 200/516] [D loss: 0.000568, acc: 100%] [G loss: 11.871243, adv: 0.971620, cyc: 0.266746, id: 0.269437] time: 1:38:21.505126 
[Epoch 17/50] [Batch 300/516] [D loss: 0.000608, acc: 100%] [G loss: 11.376925, adv: 0.952334, cyc: 0.254514, id: 0.249717] time: 1:39:29.608294 
[Epoch 17/50] [Batch 400/516] [D loss: 0.000463, acc: 100%] [G loss: 11.297126, adv: 0.944715, cyc: 0.253315, id: 0.251981] time: 1:40:37.716414 
[Epoch 17/50] [Batch 500/516] [D loss: 0.005885, acc: 100%] [G loss: 11.830816, adv: 0.980482, cyc: 0.265576, id: 0.260942] time: 1:41:45.837765 
[Epoch 18/50] [Batch 0/516] [D loss: 0.000256, acc: 100%] [G loss: 11.593643, adv: 0.974316, cyc: 0.258691, id: 0.254200] time: 1:41:56.736894 
[Epoch 18/50] [Batch 100/516] [D loss: 0.000219, acc: 100%] [G loss: 11.566563, adv: 0.960675, cyc: 0.259187, id: 0.253400] time: 1:43:04.824980 
[Epoch 18/50] [Batch 200/516] [D loss: 0.000120, acc: 100%] [G loss: 11.892260, adv: 0.993168, cyc: 0.266320, id: 0.268716] time: 1:44:12.939785 
[Epoch 18/50] [Batch 300/516] [D loss: 0.000349, acc: 100%] [G loss: 11.452273, adv: 0.954665, cyc: 0.256558, id: 0.251744] time: 1:45:21.060480 
[Epoch 18/50] [Batch 400/516] [D loss: 0.000404, acc: 100%] [G loss: 11.321440, adv: 0.979183, cyc: 0.252209, id: 0.250162] time: 1:46:29.174445 
[Epoch 18/50] [Batch 500/516] [D loss: 0.000419, acc: 100%] [G loss: 11.791485, adv: 0.997681, cyc: 0.262575, id: 0.260320] time: 1:47:37.279843 
[Epoch 19/50] [Batch 0/516] [D loss: 0.000298, acc: 100%] [G loss: 11.503855, adv: 0.985507, cyc: 0.256727, id: 0.249645] time: 1:47:48.177710 
[Epoch 19/50] [Batch 100/516] [D loss: 0.000145, acc: 100%] [G loss: 11.489079, adv: 0.950848, cyc: 0.257039, id: 0.252851] time: 1:48:56.291375 
[Epoch 19/50] [Batch 200/516] [D loss: 0.000175, acc: 100%] [G loss: 11.804083, adv: 0.976794, cyc: 0.262977, id: 0.268643] time: 1:50:04.394655 
[Epoch 19/50] [Batch 300/516] [D loss: 0.000355, acc: 100%] [G loss: 11.388569, adv: 0.995095, cyc: 0.252537, id: 0.248110] time: 1:51:12.496928 
[Epoch 19/50] [Batch 400/516] [D loss: 0.000647, acc: 100%] [G loss: 11.202352, adv: 0.962339, cyc: 0.249656, id: 0.248650] time: 1:52:20.599482 
[Epoch 19/50] [Batch 500/516] [D loss: 0.000248, acc: 100%] [G loss: 11.660470, adv: 0.988987, cyc: 0.258851, id: 0.257841] time: 1:53:28.713804 
[Epoch 20/50] [Batch 0/516] [D loss: 0.000452, acc: 100%] [G loss: 11.456536, adv: 0.993424, cyc: 0.254111, id: 0.249426] time: 1:53:39.610841 
[Epoch 20/50] [Batch 100/516] [D loss: 0.000227, acc: 100%] [G loss: 11.305119, adv: 0.882603, cyc: 0.255678, id: 0.252203] time: 1:54:47.716533 
[Epoch 20/50] [Batch 200/516] [D loss: 0.000576, acc: 100%] [G loss: 11.606298, adv: 0.915581, cyc: 0.261335, id: 0.266429] time: 1:55:55.831873 
[Epoch 20/50] [Batch 300/516] [D loss: 0.000285, acc: 100%] [G loss: 11.348541, adv: 0.986016, cyc: 0.251929, id: 0.247517] time: 1:57:03.953771 
[Epoch 20/50] [Batch 400/516] [D loss: 0.000374, acc: 100%] [G loss: 11.163869, adv: 0.970529, cyc: 0.248013, id: 0.247153] time: 1:58:12.071387 
[Epoch 20/50] [Batch 500/516] [D loss: 0.000342, acc: 100%] [G loss: 11.530190, adv: 0.949580, cyc: 0.258133, id: 0.255481] time: 1:59:20.185658 
[Epoch 21/50] [Batch 0/516] [D loss: 0.000490, acc: 100%] [G loss: 11.402278, adv: 0.991314, cyc: 0.252185, id: 0.249236] time: 1:59:43.163007 
[Epoch 21/50] [Batch 100/516] [D loss: 0.000190, acc: 100%] [G loss: 11.368081, adv: 0.958840, cyc: 0.252892, id: 0.249639] time: 2:00:51.274822 
[Epoch 21/50] [Batch 200/516] [D loss: 0.000376, acc: 100%] [G loss: 11.631680, adv: 0.998706, cyc: 0.257800, id: 0.262405] time: 2:01:59.390867 
[Epoch 21/50] [Batch 300/516] [D loss: 0.000186, acc: 100%] [G loss: 11.241287, adv: 0.954110, cyc: 0.250811, id: 0.245060] time: 2:03:07.507156 
[Epoch 21/50] [Batch 400/516] [D loss: 0.000417, acc: 100%] [G loss: 11.135448, adv: 0.991987, cyc: 0.245645, id: 0.245004] time: 2:04:15.609823 
[Epoch 21/50] [Batch 500/516] [D loss: 0.000109, acc: 100%] [G loss: 11.542361, adv: 0.982207, cyc: 0.256143, id: 0.254690] time: 2:05:23.738659 
[Epoch 22/50] [Batch 0/516] [D loss: 0.000168, acc: 100%] [G loss: 11.243047, adv: 0.932282, cyc: 0.251242, id: 0.247051] time: 2:05:34.641289 
[Epoch 22/50] [Batch 100/516] [D loss: 0.000288, acc: 100%] [G loss: 11.363422, adv: 0.983878, cyc: 0.252016, id: 0.248067] time: 2:06:42.756602 
[Epoch 22/50] [Batch 200/516] [D loss: 0.000198, acc: 100%] [G loss: 11.560660, adv: 0.975822, cyc: 0.256968, id: 0.262032] time: 2:07:50.871441 
[Epoch 22/50] [Batch 300/516] [D loss: 0.000334, acc: 100%] [G loss: 11.133542, adv: 0.950729, cyc: 0.247937, id: 0.243099] time: 2:08:58.996077 
[Epoch 22/50] [Batch 400/516] [D loss: 0.000422, acc: 100%] [G loss: 11.117661, adv: 1.005934, cyc: 0.244157, id: 0.244212] time: 2:10:07.111130 
[Epoch 22/50] [Batch 500/516] [D loss: 0.000156, acc: 100%] [G loss: 11.479812, adv: 0.950070, cyc: 0.255610, id: 0.256330] time: 2:11:15.218845 
[Epoch 23/50] [Batch 0/516] [D loss: 0.000711, acc: 100%] [G loss: 11.372730, adv: 1.020271, cyc: 0.251029, id: 0.245088] time: 2:11:26.115798 
[Epoch 23/50] [Batch 100/516] [D loss: 0.000065, acc: 100%] [G loss: 11.318288, adv: 0.993004, cyc: 0.249059, id: 0.248028] time: 2:12:34.228739 
[Epoch 23/50] [Batch 200/516] [D loss: 0.000087, acc: 100%] [G loss: 11.512900, adv: 0.973714, cyc: 0.255483, id: 0.261106] time: 2:13:42.354442 
[Epoch 23/50] [Batch 300/516] [D loss: 0.000411, acc: 100%] [G loss: 11.076434, adv: 0.972279, cyc: 0.245300, id: 0.241549] time: 2:14:50.472911 
[Epoch 23/50] [Batch 400/516] [D loss: 0.000373, acc: 100%] [G loss: 10.959448, adv: 0.938564, cyc: 0.243883, id: 0.243218] time: 2:15:58.586089 
[Epoch 23/50] [Batch 500/516] [D loss: 0.000327, acc: 100%] [G loss: 11.322380, adv: 0.900919, cyc: 0.254433, id: 0.253258] time: 2:17:06.693965 
[Epoch 24/50] [Batch 0/516] [D loss: 0.000952, acc: 100%] [G loss: 11.310363, adv: 1.005712, cyc: 0.247875, id: 0.246579] time: 2:17:17.592557 
[Epoch 24/50] [Batch 100/516] [D loss: 0.000488, acc: 100%] [G loss: 11.189260, adv: 0.943619, cyc: 0.249255, id: 0.245409] time: 2:18:25.713070 
[Epoch 24/50] [Batch 200/516] [D loss: 0.000133, acc: 100%] [G loss: 11.469410, adv: 0.979602, cyc: 0.253327, id: 0.260050] time: 2:19:33.835522 
[Epoch 24/50] [Batch 300/516] [D loss: 0.000065, acc: 100%] [G loss: 10.998470, adv: 0.957379, cyc: 0.243631, id: 0.241007] time: 2:20:41.965601 
[Epoch 24/50] [Batch 400/516] [D loss: 0.000161, acc: 100%] [G loss: 10.990199, adv: 0.987455, cyc: 0.241664, id: 0.242481] time: 2:21:50.092404 
[Epoch 24/50] [Batch 500/516] [D loss: 0.000202, acc: 100%] [G loss: 11.303473, adv: 0.930866, cyc: 0.252595, id: 0.251297] time: 2:22:58.202289 
[Epoch 25/50] [Batch 0/516] [D loss: 0.000136, acc: 100%] [G loss: 11.143347, adv: 0.972622, cyc: 0.246230, id: 0.242562] time: 2:23:09.099947 
[Epoch 25/50] [Batch 100/516] [D loss: 0.000138, acc: 100%] [G loss: 11.132637, adv: 0.951303, cyc: 0.246712, id: 0.245113] time: 2:24:17.200824 
[Epoch 25/50] [Batch 200/516] [D loss: 0.000288, acc: 100%] [G loss: 11.475230, adv: 1.001768, cyc: 0.253575, id: 0.258997] time: 2:25:25.316107 
[Epoch 25/50] [Batch 300/516] [D loss: 0.000330, acc: 100%] [G loss: 11.023705, adv: 0.982708, cyc: 0.243374, id: 0.239511] time: 2:26:33.428845 
[Epoch 25/50] [Batch 400/516] [D loss: 0.000142, acc: 100%] [G loss: 10.882816, adv: 0.965934, cyc: 0.239877, id: 0.240839] time: 2:27:41.533364 
[Epoch 25/50] [Batch 500/516] [D loss: 0.001156, acc: 100%] [G loss: 11.429361, adv: 0.996068, cyc: 0.251943, id: 0.250628] time: 2:28:49.636852 
[Epoch 26/50] [Batch 0/516] [D loss: 0.000227, acc: 100%] [G loss: 11.130005, adv: 0.986999, cyc: 0.245332, id: 0.242560] time: 2:29:06.473917 
[Epoch 26/50] [Batch 100/516] [D loss: 0.000403, acc: 100%] [G loss: 11.220166, adv: 0.997058, cyc: 0.247001, id: 0.243983] time: 2:30:14.595604 
[Epoch 26/50] [Batch 200/516] [D loss: 0.000186, acc: 100%] [G loss: 11.378775, adv: 0.988762, cyc: 0.250840, id: 0.256924] time: 2:31:22.707673 
[Epoch 26/50] [Batch 300/516] [D loss: 0.000122, acc: 100%] [G loss: 10.990416, adv: 0.991609, cyc: 0.241044, id: 0.239132] time: 2:32:30.828335 
[Epoch 26/50] [Batch 400/516] [D loss: 0.000347, acc: 100%] [G loss: 10.887080, adv: 0.989484, cyc: 0.238868, id: 0.239731] time: 2:33:38.944004 
[Epoch 26/50] [Batch 500/516] [D loss: 0.000160, acc: 100%] [G loss: 11.295814, adv: 0.971528, cyc: 0.249398, id: 0.249543] time: 2:34:47.058728 
[Epoch 27/50] [Batch 0/516] [D loss: 0.000168, acc: 100%] [G loss: 11.058052, adv: 0.990301, cyc: 0.241975, id: 0.242362] time: 2:34:57.955324 
[Epoch 27/50] [Batch 100/516] [D loss: 0.000267, acc: 100%] [G loss: 11.170525, adv: 1.005516, cyc: 0.244819, id: 0.243084] time: 2:36:06.071986 
[Epoch 27/50] [Batch 200/516] [D loss: 0.000082, acc: 100%] [G loss: 11.346546, adv: 0.970799, cyc: 0.251119, id: 0.256953] time: 2:37:14.164727 
[Epoch 27/50] [Batch 300/516] [D loss: 0.000232, acc: 100%] [G loss: 10.815733, adv: 0.927196, cyc: 0.240129, id: 0.237730] time: 2:38:22.268619 
[Epoch 27/50] [Batch 400/516] [D loss: 0.000209, acc: 100%] [G loss: 10.800802, adv: 0.957156, cyc: 0.238213, id: 0.239635] time: 2:39:30.383071 
[Epoch 27/50] [Batch 500/516] [D loss: 0.000206, acc: 100%] [G loss: 11.264000, adv: 0.968189, cyc: 0.249226, id: 0.248240] time: 2:40:38.490943 
[Epoch 28/50] [Batch 0/516] [D loss: 0.000230, acc: 100%] [G loss: 11.057810, adv: 0.975384, cyc: 0.242638, id: 0.240639] time: 2:40:49.387937 
[Epoch 28/50] [Batch 100/516] [D loss: 0.000150, acc: 100%] [G loss: 11.053225, adv: 0.985868, cyc: 0.242731, id: 0.241294] time: 2:41:57.493600 
[Epoch 28/50] [Batch 200/516] [D loss: 0.000405, acc: 100%] [G loss: 11.294736, adv: 0.972416, cyc: 0.249747, id: 0.255910] time: 2:43:05.606028 
[Epoch 28/50] [Batch 300/516] [D loss: 0.000214, acc: 100%] [G loss: 10.893938, adv: 0.985550, cyc: 0.238010, id: 0.236508] time: 2:44:13.721963 
[Epoch 28/50] [Batch 400/516] [D loss: 0.000104, acc: 100%] [G loss: 10.808339, adv: 0.982520, cyc: 0.236500, id: 0.237809] time: 2:45:21.831385 
[Epoch 28/50] [Batch 500/516] [D loss: 0.000136, acc: 100%] [G loss: 11.265654, adv: 0.999446, cyc: 0.247719, id: 0.246437] time: 2:46:29.948032 
[Epoch 29/50] [Batch 0/516] [D loss: 0.000054, acc: 100%] [G loss: 11.023789, adv: 0.999627, cyc: 0.241387, id: 0.238642] time: 2:46:40.848259 
[Epoch 29/50] [Batch 100/516] [D loss: 0.000318, acc: 100%] [G loss: 11.103018, adv: 0.989005, cyc: 0.243401, id: 0.240982] time: 2:47:48.968071 
[Epoch 29/50] [Batch 200/516] [D loss: 0.000299, acc: 100%] [G loss: 11.160716, adv: 0.925926, cyc: 0.248996, id: 0.254084] time: 2:48:57.093281 
[Epoch 29/50] [Batch 300/516] [D loss: 0.000181, acc: 100%] [G loss: 10.924569, adv: 1.015342, cyc: 0.237495, id: 0.237333] time: 2:50:05.217710 
[Epoch 29/50] [Batch 400/516] [D loss: 0.000407, acc: 100%] [G loss: 10.892096, adv: 1.027649, cyc: 0.236464, id: 0.238760] time: 2:51:13.341080 
[Epoch 29/50] [Batch 500/516] [D loss: 0.000737, acc: 100%] [G loss: 11.199368, adv: 0.972801, cyc: 0.247737, id: 0.246425] time: 2:52:21.464446 
[Epoch 30/50] [Batch 0/516] [D loss: 0.000146, acc: 100%] [G loss: 10.989964, adv: 0.997623, cyc: 0.239977, id: 0.239210] time: 2:52:32.365053 
[Epoch 30/50] [Batch 100/516] [D loss: 0.000104, acc: 100%] [G loss: 11.190792, adv: 1.023314, cyc: 0.244420, id: 0.241120] time: 2:53:40.492241 
[Epoch 30/50] [Batch 200/516] [D loss: 0.000146, acc: 100%] [G loss: 11.252441, adv: 0.985178, cyc: 0.248106, id: 0.254140] time: 2:54:48.617706 
[Epoch 30/50] [Batch 300/516] [D loss: 0.000117, acc: 100%] [G loss: 10.748388, adv: 0.950274, cyc: 0.236635, id: 0.234772] time: 2:55:56.749375 
[Epoch 30/50] [Batch 400/516] [D loss: 0.000136, acc: 100%] [G loss: 10.766226, adv: 0.980773, cyc: 0.236617, id: 0.236721] time: 2:57:04.862733 
[Epoch 30/50] [Batch 500/516] [D loss: 0.000131, acc: 100%] [G loss: 11.150267, adv: 0.975487, cyc: 0.244895, id: 0.245916] time: 2:58:12.980307 
[Epoch 31/50] [Batch 0/516] [D loss: 0.000262, acc: 100%] [G loss: 10.934412, adv: 0.980757, cyc: 0.239411, id: 0.237815] time: 2:58:33.586175 
[Epoch 31/50] [Batch 100/516] [D loss: 0.000332, acc: 100%] [G loss: 10.988188, adv: 0.991210, cyc: 0.241189, id: 0.239289] time: 2:59:41.711426 
[Epoch 31/50] [Batch 200/516] [D loss: 0.000243, acc: 100%] [G loss: 11.265957, adv: 0.997981, cyc: 0.247948, id: 0.253574] time: 3:00:49.829090 
[Epoch 31/50] [Batch 300/516] [D loss: 0.000156, acc: 100%] [G loss: 10.815373, adv: 0.980499, cyc: 0.236485, id: 0.236926] time: 3:01:57.915309 
[Epoch 31/50] [Batch 400/516] [D loss: 0.000085, acc: 100%] [G loss: 10.712610, adv: 1.001230, cyc: 0.233495, id: 0.235129] time: 3:03:05.949474 
[Epoch 31/50] [Batch 500/516] [D loss: 0.000124, acc: 100%] [G loss: 11.147434, adv: 0.990626, cyc: 0.243029, id: 0.245696] time: 3:04:13.988220 
[Epoch 32/50] [Batch 0/516] [D loss: 0.000065, acc: 100%] [G loss: 10.860218, adv: 0.921547, cyc: 0.240241, id: 0.238361] time: 3:04:24.874941 
[Epoch 32/50] [Batch 100/516] [D loss: 0.000365, acc: 100%] [G loss: 10.866299, adv: 0.927502, cyc: 0.240773, id: 0.240395] time: 3:05:32.925610 
[Epoch 32/50] [Batch 200/516] [D loss: 0.000467, acc: 100%] [G loss: 11.174938, adv: 0.976934, cyc: 0.246550, id: 0.252229] time: 3:06:40.962229 
[Epoch 32/50] [Batch 300/516] [D loss: 0.000128, acc: 100%] [G loss: 10.717904, adv: 0.973631, cyc: 0.234614, id: 0.233482] time: 3:07:49.003184 
[Epoch 32/50] [Batch 400/516] [D loss: 0.000129, acc: 100%] [G loss: 10.700889, adv: 1.015701, cyc: 0.231753, id: 0.235330] time: 3:08:57.041419 
[Epoch 32/50] [Batch 500/516] [D loss: 0.000119, acc: 100%] [G loss: 11.053200, adv: 0.966085, cyc: 0.242693, id: 0.245107] time: 3:10:05.084740 
[Epoch 33/50] [Batch 0/516] [D loss: 0.000127, acc: 100%] [G loss: 10.898487, adv: 0.994515, cyc: 0.237750, id: 0.236850] time: 3:10:15.973074 
[Epoch 33/50] [Batch 100/516] [D loss: 0.000238, acc: 100%] [G loss: 10.967163, adv: 1.012612, cyc: 0.238554, id: 0.238123] time: 3:11:24.014673 
[Epoch 33/50] [Batch 200/516] [D loss: 0.000391, acc: 100%] [G loss: 11.175406, adv: 0.993936, cyc: 0.244135, id: 0.253044] time: 3:12:32.053099 
[Epoch 33/50] [Batch 300/516] [D loss: 0.000064, acc: 100%] [G loss: 10.718081, adv: 1.001767, cyc: 0.232970, id: 0.232349] time: 3:13:40.089336 
[Epoch 33/50] [Batch 400/516] [D loss: 0.000030, acc: 100%] [G loss: 10.591299, adv: 0.957839, cyc: 0.231808, id: 0.234566] time: 3:14:48.132384 
[Epoch 33/50] [Batch 500/516] [D loss: 0.000155, acc: 100%] [G loss: 11.094801, adv: 0.983220, cyc: 0.243658, id: 0.244035] time: 3:15:56.175606 
[Epoch 34/50] [Batch 0/516] [D loss: 0.000110, acc: 100%] [G loss: 10.858353, adv: 0.988044, cyc: 0.237584, id: 0.236156] time: 3:16:07.063611 
[Epoch 34/50] [Batch 100/516] [D loss: 0.000082, acc: 100%] [G loss: 10.841454, adv: 0.975227, cyc: 0.236533, id: 0.237410] time: 3:17:15.098798 
[Epoch 34/50] [Batch 200/516] [D loss: 0.000187, acc: 100%] [G loss: 11.105942, adv: 0.997632, cyc: 0.242515, id: 0.251215] time: 3:18:23.139324 
[Epoch 34/50] [Batch 300/516] [D loss: 0.000099, acc: 100%] [G loss: 10.583773, adv: 0.927246, cyc: 0.233170, id: 0.232647] time: 3:19:31.179365 
[Epoch 34/50] [Batch 400/516] [D loss: 0.000122, acc: 100%] [G loss: 10.591349, adv: 0.974687, cyc: 0.231114, id: 0.234320] time: 3:20:39.217941 
[Epoch 34/50] [Batch 500/516] [D loss: 0.000124, acc: 100%] [G loss: 11.117302, adv: 1.012268, cyc: 0.240892, id: 0.245716] time: 3:21:47.259359 
[Epoch 35/50] [Batch 0/516] [D loss: 0.000218, acc: 100%] [G loss: 10.672031, adv: 0.926212, cyc: 0.235098, id: 0.235381] time: 3:21:58.143472 
[Epoch 35/50] [Batch 100/516] [D loss: 0.000324, acc: 100%] [G loss: 10.759972, adv: 0.952766, cyc: 0.235664, id: 0.236714] time: 3:23:06.200254 
[Epoch 35/50] [Batch 200/516] [D loss: 0.000152, acc: 100%] [G loss: 11.050155, adv: 0.980935, cyc: 0.242462, id: 0.249919] time: 3:24:14.261062 
[Epoch 35/50] [Batch 300/516] [D loss: 0.000144, acc: 100%] [G loss: 10.620690, adv: 0.981122, cyc: 0.231717, id: 0.231046] time: 3:25:22.299415 
[Epoch 35/50] [Batch 400/516] [D loss: 0.000195, acc: 100%] [G loss: 10.572487, adv: 0.982516, cyc: 0.230717, id: 0.232652] time: 3:26:30.344214 
[Epoch 35/50] [Batch 500/516] [D loss: 0.000153, acc: 100%] [G loss: 11.049479, adv: 0.967444, cyc: 0.242643, id: 0.245395] time: 3:27:38.388474 
[Epoch 36/50] [Batch 0/516] [D loss: 0.000035, acc: 100%] [G loss: 10.823192, adv: 0.994320, cyc: 0.235565, id: 0.234376] time: 3:27:50.412276 
[Epoch 36/50] [Batch 100/516] [D loss: 0.000164, acc: 100%] [G loss: 10.802770, adv: 0.988146, cyc: 0.235599, id: 0.235636] time: 3:28:58.450653 
[Epoch 36/50] [Batch 200/516] [D loss: 0.000205, acc: 100%] [G loss: 11.113101, adv: 1.020682, cyc: 0.241921, id: 0.249632] time: 3:30:06.487667 
[Epoch 36/50] [Batch 300/516] [D loss: 0.000165, acc: 100%] [G loss: 10.611975, adv: 0.991209, cyc: 0.230259, id: 0.231170] time: 3:31:14.534873 
[Epoch 36/50] [Batch 400/516] [D loss: 0.000395, acc: 100%] [G loss: 10.673025, adv: 1.009031, cyc: 0.231657, id: 0.234394] time: 3:32:22.579443 
[Epoch 36/50] [Batch 500/516] [D loss: 0.000064, acc: 100%] [G loss: 11.012360, adv: 1.006491, cyc: 0.239762, id: 0.241563] time: 3:33:30.627666 
[Epoch 37/50] [Batch 0/516] [D loss: 0.000059, acc: 100%] [G loss: 10.737804, adv: 0.982534, cyc: 0.234622, id: 0.233432] time: 3:33:41.514341 
[Epoch 37/50] [Batch 100/516] [D loss: 0.000042, acc: 100%] [G loss: 10.825193, adv: 1.000884, cyc: 0.235439, id: 0.235366] time: 3:34:49.552295 
[Epoch 37/50] [Batch 200/516] [D loss: 0.000210, acc: 100%] [G loss: 11.090562, adv: 0.978307, cyc: 0.243436, id: 0.249585] time: 3:35:57.591065 
[Epoch 37/50] [Batch 300/516] [D loss: 0.000035, acc: 100%] [G loss: 10.600410, adv: 0.987503, cyc: 0.229999, id: 0.230191] time: 3:37:05.623533 
[Epoch 37/50] [Batch 400/516] [D loss: 0.000064, acc: 100%] [G loss: 10.682586, adv: 0.986131, cyc: 0.233636, id: 0.234799] time: 3:38:13.664779 
[Epoch 37/50] [Batch 500/516] [D loss: 0.000304, acc: 100%] [G loss: 10.989746, adv: 0.936374, cyc: 0.242277, id: 0.245180] time: 3:39:21.705301 
[Epoch 38/50] [Batch 0/516] [D loss: 0.000124, acc: 100%] [G loss: 10.819384, adv: 1.008523, cyc: 0.235032, id: 0.234939] time: 3:39:32.592360 
[Epoch 38/50] [Batch 100/516] [D loss: 0.000143, acc: 100%] [G loss: 10.741729, adv: 0.982014, cyc: 0.233742, id: 0.234083] time: 3:40:40.647116 
[Epoch 38/50] [Batch 200/516] [D loss: 0.000125, acc: 100%] [G loss: 11.049061, adv: 1.012712, cyc: 0.240867, id: 0.247857] time: 3:41:48.680579 
[Epoch 38/50] [Batch 300/516] [D loss: 0.000105, acc: 100%] [G loss: 10.666100, adv: 1.030475, cyc: 0.229982, id: 0.230282] time: 3:42:56.723883 
[Epoch 38/50] [Batch 400/516] [D loss: 0.000080, acc: 100%] [G loss: 10.565304, adv: 1.013813, cyc: 0.227595, id: 0.232913] time: 3:44:04.760102 
[Epoch 38/50] [Batch 500/516] [D loss: 0.000186, acc: 100%] [G loss: 10.939888, adv: 0.985586, cyc: 0.239633, id: 0.240573] time: 3:45:12.793264 
[Epoch 39/50] [Batch 0/516] [D loss: 0.000069, acc: 100%] [G loss: 10.732955, adv: 0.991969, cyc: 0.233898, id: 0.233284] time: 3:45:23.678700 
[Epoch 39/50] [Batch 100/516] [D loss: 0.003283, acc: 100%] [G loss: 10.873177, adv: 1.042045, cyc: 0.233766, id: 0.235485] time: 3:46:31.719318 
[Epoch 39/50] [Batch 200/516] [D loss: 0.000040, acc: 100%] [G loss: 10.892883, adv: 0.937936, cyc: 0.238897, id: 0.247873] time: 3:47:39.757347 
[Epoch 39/50] [Batch 300/516] [D loss: 0.000548, acc: 100%] [G loss: 10.541576, adv: 0.958424, cyc: 0.230219, id: 0.229922] time: 3:48:47.802516 
[Epoch 39/50] [Batch 400/516] [D loss: 0.000055, acc: 100%] [G loss: 10.504251, adv: 0.978099, cyc: 0.227529, id: 0.232781] time: 3:49:55.845140 
[Epoch 39/50] [Batch 500/516] [D loss: 0.000057, acc: 100%] [G loss: 10.941324, adv: 1.008324, cyc: 0.237495, id: 0.239615] time: 3:51:03.882493 
[Epoch 40/50] [Batch 0/516] [D loss: 0.000045, acc: 100%] [G loss: 10.732142, adv: 0.982092, cyc: 0.233387, id: 0.234638] time: 3:51:14.769725 
[Epoch 40/50] [Batch 100/516] [D loss: 0.000056, acc: 100%] [G loss: 10.711018, adv: 0.983172, cyc: 0.232599, id: 0.234610] time: 3:52:22.809178 
[Epoch 40/50] [Batch 200/516] [D loss: 0.000091, acc: 100%] [G loss: 10.988963, adv: 1.012961, cyc: 0.237565, id: 0.247752] time: 3:53:30.850094 
[Epoch 40/50] [Batch 300/516] [D loss: 0.000087, acc: 100%] [G loss: 10.514147, adv: 0.970128, cyc: 0.227961, id: 0.229090] time: 3:54:38.892817 
[Epoch 40/50] [Batch 400/516] [D loss: 0.000082, acc: 100%] [G loss: 10.479827, adv: 1.001197, cyc: 0.226528, id: 0.230313] time: 3:55:46.934043 
[Epoch 40/50] [Batch 500/516] [D loss: 0.000073, acc: 100%] [G loss: 10.791221, adv: 0.931755, cyc: 0.237677, id: 0.239790] time: 3:56:54.973027 
[Epoch 41/50] [Batch 0/516] [D loss: 0.000074, acc: 100%] [G loss: 10.625500, adv: 0.964453, cyc: 0.231609, id: 0.231553] time: 3:57:07.002110 
[Epoch 41/50] [Batch 100/516] [D loss: 0.000211, acc: 100%] [G loss: 10.669394, adv: 0.968139, cyc: 0.233063, id: 0.233004] time: 3:58:15.109557 
[Epoch 41/50] [Batch 200/516] [D loss: 0.000032, acc: 100%] [G loss: 10.901567, adv: 0.953208, cyc: 0.239145, id: 0.247087] time: 3:59:23.227031 
[Epoch 41/50] [Batch 300/516] [D loss: 0.000091, acc: 100%] [G loss: 10.609823, adv: 1.011349, cyc: 0.229518, id: 0.228941] time: 4:00:31.341654 
[Epoch 41/50] [Batch 400/516] [D loss: 0.000039, acc: 100%] [G loss: 10.460053, adv: 0.989044, cyc: 0.226585, id: 0.230788] time: 4:01:39.450426 
[Epoch 41/50] [Batch 500/516] [D loss: 0.000069, acc: 100%] [G loss: 10.967701, adv: 1.020470, cyc: 0.236650, id: 0.239755] time: 4:02:47.562356 
[Epoch 42/50] [Batch 0/516] [D loss: 0.000051, acc: 100%] [G loss: 10.641694, adv: 0.987529, cyc: 0.231614, id: 0.231383] time: 4:02:58.462401 
[Epoch 42/50] [Batch 100/516] [D loss: 0.000040, acc: 100%] [G loss: 10.682996, adv: 0.985184, cyc: 0.231787, id: 0.232923] time: 4:04:06.575156 
[Epoch 42/50] [Batch 200/516] [D loss: 0.000095, acc: 100%] [G loss: 10.918400, adv: 1.003669, cyc: 0.236416, id: 0.245599] time: 4:05:14.695614 
[Epoch 42/50] [Batch 300/516] [D loss: 0.000160, acc: 100%] [G loss: 10.540446, adv: 0.993594, cyc: 0.228048, id: 0.229420] time: 4:06:22.811502 
[Epoch 42/50] [Batch 400/516] [D loss: 0.000016, acc: 100%] [G loss: 10.441868, adv: 0.990689, cyc: 0.226465, id: 0.229655] time: 4:07:30.935127 
[Epoch 42/50] [Batch 500/516] [D loss: 0.000059, acc: 100%] [G loss: 10.887978, adv: 1.000796, cyc: 0.235834, id: 0.238993] time: 4:08:39.053651 
[Epoch 43/50] [Batch 0/516] [D loss: 0.000056, acc: 100%] [G loss: 10.640535, adv: 0.986105, cyc: 0.230972, id: 0.231591] time: 4:08:49.952486 
[Epoch 43/50] [Batch 100/516] [D loss: 0.000089, acc: 100%] [G loss: 10.607593, adv: 0.967742, cyc: 0.230896, id: 0.231699] time: 4:09:58.077462 
[Epoch 43/50] [Batch 200/516] [D loss: 0.000101, acc: 100%] [G loss: 10.908008, adv: 0.983564, cyc: 0.238273, id: 0.246577] time: 4:11:06.196828 
[Epoch 43/50] [Batch 300/516] [D loss: 0.000069, acc: 100%] [G loss: 10.540545, adv: 1.010108, cyc: 0.227095, id: 0.228414] time: 4:12:14.316216 
[Epoch 43/50] [Batch 400/516] [D loss: 0.000061, acc: 100%] [G loss: 10.408203, adv: 0.972316, cyc: 0.226484, id: 0.229660] time: 4:13:22.443650 
[Epoch 43/50] [Batch 500/516] [D loss: 0.000091, acc: 100%] [G loss: 10.824179, adv: 0.972052, cyc: 0.236104, id: 0.239068] time: 4:14:30.534797 
[Epoch 44/50] [Batch 0/516] [D loss: 0.000079, acc: 100%] [G loss: 10.667147, adv: 1.004696, cyc: 0.231263, id: 0.231009] time: 4:14:41.423576 
[Epoch 44/50] [Batch 100/516] [D loss: 0.000088, acc: 100%] [G loss: 10.668902, adv: 0.984827, cyc: 0.230756, id: 0.232290] time: 4:15:49.457889 
[Epoch 44/50] [Batch 200/516] [D loss: 0.000061, acc: 100%] [G loss: 10.860483, adv: 0.986802, cyc: 0.236950, id: 0.244269] time: 4:16:57.493666 
[Epoch 44/50] [Batch 300/516] [D loss: 0.000080, acc: 100%] [G loss: 10.456842, adv: 0.997784, cyc: 0.225257, id: 0.226823] time: 4:18:05.534447 
[Epoch 44/50] [Batch 400/516] [D loss: 0.000035, acc: 100%] [G loss: 10.343564, adv: 0.969117, cyc: 0.224277, id: 0.228791] time: 4:19:13.564604 
[Epoch 44/50] [Batch 500/516] [D loss: 0.000060, acc: 100%] [G loss: 10.824283, adv: 0.990920, cyc: 0.234854, id: 0.238601] time: 4:20:21.609314 
[Epoch 45/50] [Batch 0/516] [D loss: 0.000121, acc: 100%] [G loss: 10.702826, adv: 1.019390, cyc: 0.229963, id: 0.231459] time: 4:20:32.498412 
[Epoch 45/50] [Batch 100/516] [D loss: 0.000060, acc: 100%] [G loss: 10.626677, adv: 0.982203, cyc: 0.230652, id: 0.231857] time: 4:21:40.540542 
[Epoch 45/50] [Batch 200/516] [D loss: 0.000069, acc: 100%] [G loss: 10.874598, adv: 1.012673, cyc: 0.234926, id: 0.244984] time: 4:22:48.577703 
[Epoch 45/50] [Batch 300/516] [D loss: 0.000195, acc: 100%] [G loss: 10.427657, adv: 0.966881, cyc: 0.225303, id: 0.228686] time: 4:23:56.615152 
[Epoch 45/50] [Batch 400/516] [D loss: 0.000139, acc: 100%] [G loss: 10.366832, adv: 0.990985, cyc: 0.223409, id: 0.229242] time: 4:25:04.655407 
[Epoch 45/50] [Batch 500/516] [D loss: 0.000055, acc: 100%] [G loss: 10.782759, adv: 0.983931, cyc: 0.234596, id: 0.237514] time: 4:26:12.699622 
[Epoch 46/50] [Batch 0/516] [D loss: 0.000244, acc: 100%] [G loss: 10.543010, adv: 0.961325, cyc: 0.229134, id: 0.231360] time: 4:26:30.118552 
[Epoch 46/50] [Batch 100/516] [D loss: 0.000051, acc: 100%] [G loss: 10.536621, adv: 0.953968, cyc: 0.229006, id: 0.232355] time: 4:27:38.233691 
[Epoch 46/50] [Batch 200/516] [D loss: 0.000119, acc: 100%] [G loss: 10.758711, adv: 0.934342, cyc: 0.235796, id: 0.245436] time: 4:28:46.351739 
[Epoch 46/50] [Batch 300/516] [D loss: 0.000030, acc: 100%] [G loss: 10.443496, adv: 0.998225, cyc: 0.224745, id: 0.227046] time: 4:29:54.469906 
[Epoch 46/50] [Batch 400/516] [D loss: 0.000057, acc: 100%] [G loss: 10.365885, adv: 1.003667, cyc: 0.222313, id: 0.228074] time: 4:31:02.594500 
[Epoch 46/50] [Batch 500/516] [D loss: 0.000137, acc: 100%] [G loss: 10.751313, adv: 0.943963, cyc: 0.234583, id: 0.238781] time: 4:32:10.723142 
[Epoch 47/50] [Batch 0/516] [D loss: 0.000066, acc: 100%] [G loss: 10.544915, adv: 0.990103, cyc: 0.227354, id: 0.229727] time: 4:32:21.621591 
[Epoch 47/50] [Batch 100/516] [D loss: 0.000035, acc: 100%] [G loss: 10.584907, adv: 1.003501, cyc: 0.227685, id: 0.230290] time: 4:33:29.738413 
[Epoch 47/50] [Batch 200/516] [D loss: 0.000067, acc: 100%] [G loss: 10.803580, adv: 0.983202, cyc: 0.233907, id: 0.244699] time: 4:34:37.861232 
[Epoch 47/50] [Batch 300/516] [D loss: 0.000022, acc: 100%] [G loss: 10.434296, adv: 0.995625, cyc: 0.224753, id: 0.227048] time: 4:35:45.980333 
[Epoch 47/50] [Batch 400/516] [D loss: 0.000226, acc: 100%] [G loss: 10.320410, adv: 0.987967, cyc: 0.222433, id: 0.227725] time: 4:36:54.100143 
[Epoch 47/50] [Batch 500/516] [D loss: 0.000157, acc: 100%] [G loss: 10.794867, adv: 0.992909, cyc: 0.232952, id: 0.238181] time: 4:38:02.218639 
[Epoch 48/50] [Batch 0/516] [D loss: 0.000076, acc: 100%] [G loss: 10.509491, adv: 0.987190, cyc: 0.226783, id: 0.229017] time: 4:38:13.117371 
[Epoch 48/50] [Batch 100/516] [D loss: 0.000044, acc: 100%] [G loss: 10.581416, adv: 0.999403, cyc: 0.228485, id: 0.229873] time: 4:39:21.236306 
[Epoch 48/50] [Batch 200/516] [D loss: 0.000042, acc: 100%] [G loss: 10.807254, adv: 0.990106, cyc: 0.234826, id: 0.244265] time: 4:40:29.358663 
[Epoch 48/50] [Batch 300/516] [D loss: 0.000087, acc: 100%] [G loss: 10.324833, adv: 0.959850, cyc: 0.223068, id: 0.224923] time: 4:41:37.484089 
[Epoch 48/50] [Batch 400/516] [D loss: 0.000676, acc: 100%] [G loss: 10.368150, adv: 1.017709, cyc: 0.222110, id: 0.227031] time: 4:42:45.598239 
[Epoch 48/50] [Batch 500/516] [D loss: 0.000104, acc: 100%] [G loss: 10.345453, adv: 0.781937, cyc: 0.232756, id: 0.236952] time: 4:43:53.707628 
[Epoch 49/50] [Batch 0/516] [D loss: 0.000061, acc: 100%] [G loss: 10.500803, adv: 0.990595, cyc: 0.226994, id: 0.228350] time: 4:44:04.603050 
[Epoch 49/50] [Batch 100/516] [D loss: 0.000107, acc: 100%] [G loss: 10.575962, adv: 1.010328, cyc: 0.227226, id: 0.229907] time: 4:45:12.720368 
[Epoch 49/50] [Batch 200/516] [D loss: 0.000044, acc: 100%] [G loss: 10.786978, adv: 0.984165, cyc: 0.233844, id: 0.244462] time: 4:46:20.839250 
[Epoch 49/50] [Batch 300/516] [D loss: 0.000083, acc: 100%] [G loss: 10.326942, adv: 0.954319, cyc: 0.223252, id: 0.225433] time: 4:47:28.957492 
[Epoch 49/50] [Batch 400/516] [D loss: 0.000050, acc: 100%] [G loss: 10.288675, adv: 0.984798, cyc: 0.220865, id: 0.227663] time: 4:48:37.082665 
[Epoch 49/50] [Batch 500/516] [D loss: 0.000029, acc: 100%] [G loss: 10.804109, adv: 1.015438, cyc: 0.232109, id: 0.237776] time: 4:49:45.213369 
[Epoch 50/50] [Batch 0/516] [D loss: 0.000030, acc: 100%] [G loss: 10.444728, adv: 0.976575, cyc: 0.225914, id: 0.227873] time: 4:49:56.119010 
[Epoch 50/50] [Batch 100/516] [D loss: 0.000068, acc: 100%] [G loss: 10.493282, adv: 0.971168, cyc: 0.227087, id: 0.229721] time: 4:51:04.257131 
[Epoch 50/50] [Batch 200/516] [D loss: 0.000129, acc: 100%] [G loss: 10.795097, adv: 1.003861, cyc: 0.233532, id: 0.242955] time: 4:52:12.390307 
[Epoch 50/50] [Batch 300/516] [D loss: 0.000056, acc: 100%] [G loss: 10.356898, adv: 1.016913, cyc: 0.221459, id: 0.223732] time: 4:53:20.523732 
[Epoch 50/50] [Batch 400/516] [D loss: 0.000013, acc: 100%] [G loss: 10.305370, adv: 0.990856, cyc: 0.222060, id: 0.227727] time: 4:54:28.653653 
[Epoch 50/50] [Batch 500/516] [D loss: 0.000022, acc: 100%] [G loss: 10.731241, adv: 0.992627, cyc: 0.231768, id: 0.236593] time: 4:55:36.784723 
Train Finished.
