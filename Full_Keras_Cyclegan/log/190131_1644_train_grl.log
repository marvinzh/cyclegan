_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_A_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_B_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 600)               0         
_________________________________________________________________
gradient_reversal_1 (Gradien (None, 600)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 1024)              615424    
_________________________________________________________________
leaky_re_lu_43 (LeakyReLU)   (None, 1024)              0         
_________________________________________________________________
dense_6 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
leaky_re_lu_44 (LeakyReLU)   (None, 1024)              0         
_________________________________________________________________
Dom_Pred (Dense)             (None, 2)                 2050      
=================================================================
Total params: 3,334,148
Trainable params: 1,667,074
Non-trainable params: 1,667,074
_________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
ivec_b (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
ivec_a (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
model_4 (Model)                 (None, 1, 600, 1)    653345      ivec_b[0][0]                     
                                                                 model_3[1][0]                    
                                                                 ivec_a[0][0]                     
__________________________________________________________________________________________________
model_3 (Model)                 (None, 1, 600, 1)    653345      ivec_a[0][0]                     
                                                                 model_4[1][0]                    
                                                                 ivec_b[0][0]                     
__________________________________________________________________________________________________
model_2 (Model)                 (None, 1)            39610241    model_4[1][0]                    
__________________________________________________________________________________________________
model_1 (Model)                 (None, 1)            39610241    model_3[1][0]                    
__________________________________________________________________________________________________
model_5 (Model)                 (None, 2)            1667074     model_4[1][0]                    
                                                                 model_3[1][0]                    
==================================================================================================
Total params: 82,194,246
Trainable params: 1,306,690
Non-trainable params: 80,887,556
__________________________________________________________________________________________________
Start CycleGAN training.
[Epoch 1/30] [Batch 0/516] [D loss: 22.677601, acc:   0%] [G loss: 29.550753, adv: 0.383010, cyc: 0.932488, id: 0.974049] [Dompred loss: 1.166062] time: 0:01:59.548778 
[Epoch 1/30] [Batch 100/516] [D loss: 0.136572, acc:  80%] [G loss: 21.570150, adv: 0.709317, cyc: 0.791491, id: 0.820230] [Dompred loss: 0.380909] time: 0:03:17.261636 
[Epoch 1/30] [Batch 200/516] [D loss: 0.078539, acc:  92%] [G loss: 18.945759, adv: 1.049492, cyc: 0.684438, id: 0.661202] [Dompred loss: 1.638254] time: 0:04:34.935147 
[Epoch 1/30] [Batch 300/516] [D loss: 0.015097, acc: 100%] [G loss: 14.969544, adv: 0.915627, cyc: 0.576395, id: 0.555199] [Dompred loss: 0.286469] time: 0:05:52.599268 
[Epoch 1/30] [Batch 400/516] [D loss: 0.035348, acc: 100%] [G loss: 14.017859, adv: 0.979685, cyc: 0.516538, id: 0.477342] [Dompred loss: 0.313845] time: 0:07:10.242066 
[Epoch 1/30] [Batch 500/516] [D loss: 0.007702, acc:  99%] [G loss: 12.865150, adv: 0.894018, cyc: 0.486844, id: 0.452553] [Dompred loss: 0.310727] time: 0:08:27.874005 
[Epoch 2/30] [Batch 0/516] [D loss: 0.034642, acc:  98%] [G loss: 12.883483, adv: 0.878016, cyc: 0.479114, id: 0.453188] [Dompred loss: 0.435993] time: 0:08:40.288683 
[Epoch 2/30] [Batch 100/516] [D loss: 0.008028, acc: 100%] [G loss: 12.372669, adv: 0.804058, cyc: 0.461071, id: 0.438801] [Dompred loss: 0.703032] time: 0:09:57.889087 
[Epoch 2/30] [Batch 200/516] [D loss: 0.010191, acc:  99%] [G loss: 11.928893, adv: 0.780539, cyc: 0.441076, id: 0.401462] [Dompred loss: 0.499771] time: 0:11:15.483559 
[Epoch 2/30] [Batch 300/516] [D loss: 0.009520, acc: 100%] [G loss: 11.944775, adv: 0.965292, cyc: 0.432667, id: 0.431297] [Dompred loss: 0.462150] time: 0:12:33.054263 
[Epoch 2/30] [Batch 400/516] [D loss: 0.005745, acc: 100%] [G loss: 11.636063, adv: 0.854008, cyc: 0.413475, id: 0.399619] [Dompred loss: 0.225372] time: 0:13:50.626429 
[Epoch 2/30] [Batch 500/516] [D loss: 0.005303, acc: 100%] [G loss: 11.775286, adv: 0.925480, cyc: 0.405514, id: 0.395172] [Dompred loss: 0.448524] time: 0:15:08.198224 
[Epoch 3/30] [Batch 0/516] [D loss: 0.002539, acc: 100%] [G loss: 11.509189, adv: 0.842358, cyc: 0.409591, id: 0.399269] [Dompred loss: 0.290988] time: 0:15:20.611172 
[Epoch 3/30] [Batch 100/516] [D loss: 0.006261, acc: 100%] [G loss: 11.000443, adv: 0.864063, cyc: 0.399198, id: 0.392037] [Dompred loss: 0.424243] time: 0:16:38.175355 
[Epoch 3/30] [Batch 200/516] [D loss: 0.005546, acc:  99%] [G loss: 11.401537, adv: 0.897657, cyc: 0.391457, id: 0.362197] [Dompred loss: 0.685901] time: 0:17:55.729133 
[Epoch 3/30] [Batch 300/516] [D loss: 0.011196, acc: 100%] [G loss: 12.863203, adv: 1.003989, cyc: 0.389314, id: 0.391286] [Dompred loss: 0.409527] time: 0:19:13.288440 
[Epoch 3/30] [Batch 400/516] [D loss: 0.004043, acc: 100%] [G loss: 10.402096, adv: 0.863474, cyc: 0.375210, id: 0.370239] [Dompred loss: 0.184979] time: 0:20:30.841145 
[Epoch 3/30] [Batch 500/516] [D loss: 0.004670, acc: 100%] [G loss: 10.823187, adv: 0.904915, cyc: 0.371625, id: 0.359088] [Dompred loss: 0.221921] time: 0:21:48.391254 
[Epoch 4/30] [Batch 0/516] [D loss: 0.003538, acc: 100%] [G loss: 11.155731, adv: 0.912927, cyc: 0.374452, id: 0.371490] [Dompred loss: 0.270786] time: 0:22:00.803677 
[Epoch 4/30] [Batch 100/516] [D loss: 0.005073, acc: 100%] [G loss: 10.706359, adv: 0.994322, cyc: 0.369932, id: 0.368720] [Dompred loss: 0.184190] time: 0:23:18.347314 
[Epoch 4/30] [Batch 200/516] [D loss: 0.002967, acc:  99%] [G loss: 11.819228, adv: 0.971408, cyc: 0.365160, id: 0.342160] [Dompred loss: 0.900821] time: 0:24:35.886749 
[Epoch 4/30] [Batch 300/516] [D loss: 0.002072, acc: 100%] [G loss: 11.031230, adv: 0.995376, cyc: 0.363205, id: 0.370839] [Dompred loss: 0.176682] time: 0:25:53.415444 
[Epoch 4/30] [Batch 400/516] [D loss: 0.001394, acc: 100%] [G loss: 11.320352, adv: 0.941501, cyc: 0.353133, id: 0.351349] [Dompred loss: 0.488529] time: 0:27:10.948454 
[Epoch 4/30] [Batch 500/516] [D loss: 0.002676, acc: 100%] [G loss: 11.867605, adv: 0.914919, cyc: 0.353283, id: 0.350934] [Dompred loss: 0.487786] time: 0:28:28.467860 
[Epoch 5/30] [Batch 0/516] [D loss: 0.002259, acc: 100%] [G loss: 12.644305, adv: 0.924448, cyc: 0.356846, id: 0.358734] [Dompred loss: 0.790902] time: 0:28:40.871449 
[Epoch 5/30] [Batch 100/516] [D loss: 0.002441, acc: 100%] [G loss: 11.816533, adv: 0.930726, cyc: 0.349746, id: 0.350265] [Dompred loss: 0.593546] time: 0:29:58.398392 
[Epoch 5/30] [Batch 200/516] [D loss: 0.005978, acc:  99%] [G loss: 14.190866, adv: 1.007645, cyc: 0.349712, id: 0.327575] [Dompred loss: 2.385768] time: 0:31:15.904982 
[Epoch 5/30] [Batch 300/516] [D loss: 0.001884, acc: 100%] [G loss: 11.068479, adv: 0.873547, cyc: 0.348794, id: 0.357920] [Dompred loss: 0.790297] time: 0:32:33.415041 
[Epoch 5/30] [Batch 400/516] [D loss: 0.002329, acc: 100%] [G loss: 9.907519, adv: 0.907210, cyc: 0.338563, id: 0.330940] [Dompred loss: 0.569206] time: 0:33:50.921997 
[Epoch 5/30] [Batch 500/516] [D loss: 0.001935, acc: 100%] [G loss: 10.105005, adv: 0.983931, cyc: 0.337234, id: 0.333291] [Dompred loss: 0.490912] time: 0:35:08.431513 
[Epoch 6/30] [Batch 0/516] [D loss: 0.000621, acc: 100%] [G loss: 10.071861, adv: 0.906398, cyc: 0.341693, id: 0.348752] [Dompred loss: 0.528651] time: 0:35:31.376961 
[Epoch 6/30] [Batch 100/516] [D loss: 0.003983, acc: 100%] [G loss: 9.855495, adv: 0.909166, cyc: 0.336841, id: 0.330334] [Dompred loss: 0.209427] time: 0:36:48.888456 
[Epoch 6/30] [Batch 200/516] [D loss: 0.005453, acc:  99%] [G loss: 9.961954, adv: 1.000921, cyc: 0.334082, id: 0.313958] [Dompred loss: 0.477797] time: 0:38:06.385809 
[Epoch 6/30] [Batch 300/516] [D loss: 0.001583, acc: 100%] [G loss: 9.809609, adv: 1.034890, cyc: 0.336974, id: 0.344232] [Dompred loss: 0.209897] time: 0:39:23.895021 
[Epoch 6/30] [Batch 400/516] [D loss: 0.000970, acc: 100%] [G loss: 9.421623, adv: 0.954996, cyc: 0.324205, id: 0.315580] [Dompred loss: 0.415718] time: 0:40:41.415191 
[Epoch 6/30] [Batch 500/516] [D loss: 0.001387, acc: 100%] [G loss: 9.656010, adv: 0.941592, cyc: 0.326896, id: 0.321619] [Dompred loss: 0.445930] time: 0:41:58.928893 
[Epoch 7/30] [Batch 0/516] [D loss: 0.004002, acc: 100%] [G loss: 9.576082, adv: 0.956972, cyc: 0.333001, id: 0.332106] [Dompred loss: 0.473611] time: 0:42:11.328180 
[Epoch 7/30] [Batch 100/516] [D loss: 0.001236, acc: 100%] [G loss: 9.800824, adv: 0.946516, cyc: 0.326508, id: 0.325478] [Dompred loss: 0.139528] time: 0:43:28.835499 
[Epoch 7/30] [Batch 200/516] [D loss: 0.007496, acc:  99%] [G loss: 9.810162, adv: 0.918466, cyc: 0.325469, id: 0.306141] [Dompred loss: 0.657582] time: 0:44:46.343941 
[Epoch 7/30] [Batch 300/516] [D loss: 0.010804, acc:  99%] [G loss: 9.330193, adv: 0.926415, cyc: 0.326548, id: 0.330413] [Dompred loss: 0.148090] time: 0:46:03.873528 
[Epoch 7/30] [Batch 400/516] [D loss: 0.001689, acc: 100%] [G loss: 9.203868, adv: 0.981842, cyc: 0.316094, id: 0.309659] [Dompred loss: 0.397665] time: 0:47:21.386337 
[Epoch 7/30] [Batch 500/516] [D loss: 0.001158, acc: 100%] [G loss: 9.241891, adv: 0.952949, cyc: 0.318879, id: 0.313809] [Dompred loss: 0.453540] time: 0:48:38.901885 
[Epoch 8/30] [Batch 0/516] [D loss: 0.000492, acc: 100%] [G loss: 9.755379, adv: 0.945191, cyc: 0.322153, id: 0.320884] [Dompred loss: 0.432052] time: 0:48:51.302463 
[Epoch 8/30] [Batch 100/516] [D loss: 0.002208, acc: 100%] [G loss: 9.257047, adv: 0.975208, cyc: 0.321414, id: 0.316196] [Dompred loss: 0.119922] time: 0:50:08.817337 
[Epoch 8/30] [Batch 200/516] [D loss: 0.003467, acc:  99%] [G loss: 9.624658, adv: 0.952564, cyc: 0.317959, id: 0.296330] [Dompred loss: 0.891366] time: 0:51:26.335935 
[Epoch 8/30] [Batch 300/516] [D loss: 0.002135, acc: 100%] [G loss: 9.559525, adv: 1.004699, cyc: 0.318238, id: 0.322438] [Dompred loss: 0.149384] time: 0:52:43.861882 
[Epoch 8/30] [Batch 400/516] [D loss: 0.000724, acc: 100%] [G loss: 9.064451, adv: 0.883344, cyc: 0.311035, id: 0.306057] [Dompred loss: 0.414322] time: 0:54:01.377932 
[Epoch 8/30] [Batch 500/516] [D loss: 0.002137, acc: 100%] [G loss: 10.085699, adv: 0.960463, cyc: 0.310502, id: 0.309840] [Dompred loss: 0.239199] time: 0:55:18.885684 
[Epoch 9/30] [Batch 0/516] [D loss: 0.001579, acc: 100%] [G loss: 10.966311, adv: 0.928665, cyc: 0.312670, id: 0.326809] [Dompred loss: 0.946898] time: 0:55:31.288302 
[Epoch 9/30] [Batch 100/516] [D loss: 0.000978, acc: 100%] [G loss: 13.311944, adv: 1.019809, cyc: 0.312884, id: 0.308821] [Dompred loss: 0.845876] time: 0:56:48.799113 
[Epoch 9/30] [Batch 200/516] [D loss: 0.003799, acc:  99%] [G loss: 10.262878, adv: 0.962231, cyc: 0.313422, id: 0.293321] [Dompred loss: 0.597358] time: 0:58:06.296673 
[Epoch 9/30] [Batch 300/516] [D loss: 0.000379, acc: 100%] [G loss: 10.045117, adv: 0.957619, cyc: 0.313092, id: 0.325567] [Dompred loss: 0.382766] time: 0:59:23.783084 
[Epoch 9/30] [Batch 400/516] [D loss: 0.000786, acc: 100%] [G loss: 10.854410, adv: 0.993800, cyc: 0.301698, id: 0.299086] [Dompred loss: 0.866531] time: 1:00:41.283156 
[Epoch 9/30] [Batch 500/516] [D loss: 0.000521, acc: 100%] [G loss: 10.154624, adv: 0.935504, cyc: 0.305792, id: 0.303154] [Dompred loss: 0.869985] time: 1:01:58.750736 
[Epoch 10/30] [Batch 0/516] [D loss: 0.000551, acc: 100%] [G loss: 10.163373, adv: 0.967509, cyc: 0.311626, id: 0.316917] [Dompred loss: 0.732195] time: 1:02:11.146470 
[Epoch 10/30] [Batch 100/516] [D loss: 0.001023, acc: 100%] [G loss: 10.855241, adv: 0.951039, cyc: 0.307309, id: 0.306561] [Dompred loss: 1.308360] time: 1:03:28.609391 
[Epoch 10/30] [Batch 200/516] [D loss: 0.002052, acc: 100%] [G loss: 10.864977, adv: 1.001665, cyc: 0.306001, id: 0.286379] [Dompred loss: 2.151101] time: 1:04:46.048937 
[Epoch 10/30] [Batch 300/516] [D loss: 0.001342, acc: 100%] [G loss: 10.123178, adv: 0.956632, cyc: 0.305592, id: 0.316552] [Dompred loss: 1.294209] time: 1:06:03.489810 
[Epoch 10/30] [Batch 400/516] [D loss: 0.001315, acc: 100%] [G loss: 9.698115, adv: 1.009892, cyc: 0.297432, id: 0.293232] [Dompred loss: 0.738589] time: 1:07:20.907916 
[Epoch 10/30] [Batch 500/516] [D loss: 0.001832, acc: 100%] [G loss: 9.059577, adv: 0.980320, cyc: 0.300571, id: 0.300057] [Dompred loss: 0.501952] time: 1:08:38.329380 
[Epoch 11/30] [Batch 0/516] [D loss: 0.000831, acc: 100%] [G loss: 8.988203, adv: 0.961573, cyc: 0.300973, id: 0.311112] [Dompred loss: 0.293045] time: 1:08:57.164194 
[Epoch 11/30] [Batch 100/516] [D loss: 0.000521, acc: 100%] [G loss: 8.949130, adv: 0.975133, cyc: 0.299857, id: 0.305805] [Dompred loss: 0.202965] time: 1:10:14.583947 
[Epoch 11/30] [Batch 200/516] [D loss: 0.005354, acc:  99%] [G loss: 9.595639, adv: 0.967502, cyc: 0.301725, id: 0.284042] [Dompred loss: 0.952560] time: 1:11:32.001335 
[Epoch 11/30] [Batch 300/516] [D loss: 0.001002, acc: 100%] [G loss: 8.995332, adv: 0.993289, cyc: 0.301897, id: 0.316739] [Dompred loss: 0.189706] time: 1:12:49.416798 
[Epoch 11/30] [Batch 400/516] [D loss: 0.001024, acc: 100%] [G loss: 9.268648, adv: 0.984510, cyc: 0.294270, id: 0.293191] [Dompred loss: 0.196695] time: 1:14:06.832050 
[Epoch 11/30] [Batch 500/516] [D loss: 0.001054, acc: 100%] [G loss: 9.233696, adv: 0.968587, cyc: 0.295926, id: 0.298281] [Dompred loss: 0.280313] time: 1:15:24.251444 
[Epoch 12/30] [Batch 0/516] [D loss: 0.000408, acc: 100%] [G loss: 9.068307, adv: 0.969319, cyc: 0.295947, id: 0.311026] [Dompred loss: 0.467739] time: 1:15:36.639163 
[Epoch 12/30] [Batch 100/516] [D loss: 0.000565, acc: 100%] [G loss: 9.496070, adv: 1.002182, cyc: 0.297185, id: 0.301418] [Dompred loss: 0.190006] time: 1:16:54.056878 
[Epoch 12/30] [Batch 200/516] [D loss: 0.002453, acc:  99%] [G loss: 9.105581, adv: 1.031332, cyc: 0.297178, id: 0.283985] [Dompred loss: 0.897612] time: 1:18:11.474815 
[Epoch 12/30] [Batch 300/516] [D loss: 0.000959, acc: 100%] [G loss: 8.745922, adv: 0.948631, cyc: 0.298489, id: 0.314563] [Dompred loss: 0.146079] time: 1:19:28.883473 
[Epoch 12/30] [Batch 400/516] [D loss: 0.000685, acc: 100%] [G loss: 10.528950, adv: 0.955954, cyc: 0.289272, id: 0.288439] [Dompred loss: 2.179693] time: 1:20:46.297736 
[Epoch 12/30] [Batch 500/516] [D loss: 0.001225, acc: 100%] [G loss: 16.631262, adv: 0.990143, cyc: 0.292989, id: 0.308244] [Dompred loss: 5.637687] time: 1:22:03.706232 
[Epoch 13/30] [Batch 0/516] [D loss: 0.000213, acc: 100%] [G loss: 10.343156, adv: 0.946784, cyc: 0.294643, id: 0.314073] [Dompred loss: 1.268814] time: 1:22:16.092562 
[Epoch 13/30] [Batch 100/516] [D loss: 0.001271, acc: 100%] [G loss: 13.140852, adv: 0.912879, cyc: 0.293391, id: 0.296880] [Dompred loss: 3.048965] time: 1:23:33.505671 
[Epoch 13/30] [Batch 200/516] [D loss: 0.001213, acc: 100%] [G loss: 11.603138, adv: 0.938342, cyc: 0.294107, id: 0.275033] [Dompred loss: 3.353386] time: 1:24:50.917324 
[Epoch 13/30] [Batch 300/516] [D loss: 0.000861, acc: 100%] [G loss: 10.290203, adv: 1.005367, cyc: 0.294321, id: 0.313568] [Dompred loss: 0.501746] time: 1:26:08.331417 
[Epoch 13/30] [Batch 400/516] [D loss: 0.000742, acc: 100%] [G loss: 8.851115, adv: 0.935579, cyc: 0.287892, id: 0.285933] [Dompred loss: 0.247977] time: 1:27:25.758077 
[Epoch 13/30] [Batch 500/516] [D loss: 0.000502, acc: 100%] [G loss: 8.925064, adv: 0.959537, cyc: 0.287470, id: 0.294655] [Dompred loss: 0.304505] time: 1:28:43.171170 
[Epoch 14/30] [Batch 0/516] [D loss: 0.001513, acc: 100%] [G loss: 8.826713, adv: 1.000292, cyc: 0.289619, id: 0.300332] [Dompred loss: 0.485647] time: 1:28:55.558189 
[Epoch 14/30] [Batch 100/516] [D loss: 0.000992, acc: 100%] [G loss: 9.091810, adv: 1.012032, cyc: 0.293437, id: 0.300149] [Dompred loss: 0.175026] time: 1:30:12.973093 
[Epoch 14/30] [Batch 200/516] [D loss: 0.001247, acc: 100%] [G loss: 9.245497, adv: 0.986602, cyc: 0.288396, id: 0.280247] [Dompred loss: 0.979214] time: 1:31:30.382635 
[Epoch 14/30] [Batch 300/516] [D loss: 0.001211, acc: 100%] [G loss: 8.730379, adv: 0.988980, cyc: 0.292787, id: 0.309913] [Dompred loss: 0.208666] time: 1:32:47.793423 
[Epoch 14/30] [Batch 400/516] [D loss: 0.000338, acc: 100%] [G loss: 9.959544, adv: 0.971367, cyc: 0.282780, id: 0.283381] [Dompred loss: 1.154695] time: 1:34:05.198720 
[Epoch 14/30] [Batch 500/516] [D loss: 0.000487, acc: 100%] [G loss: 8.753104, adv: 0.939951, cyc: 0.285260, id: 0.289796] [Dompred loss: 0.473367] time: 1:35:22.618245 
[Epoch 15/30] [Batch 0/516] [D loss: 0.000233, acc: 100%] [G loss: 9.155943, adv: 0.983013, cyc: 0.289488, id: 0.302014] [Dompred loss: 0.684242] time: 1:35:35.005623 
[Epoch 15/30] [Batch 100/516] [D loss: 0.000314, acc: 100%] [G loss: 9.512014, adv: 0.958243, cyc: 0.290001, id: 0.293892] [Dompred loss: 0.364026] time: 1:36:52.420675 
[Epoch 15/30] [Batch 200/516] [D loss: 0.001151, acc: 100%] [G loss: 9.632134, adv: 1.027376, cyc: 0.287411, id: 0.287539] [Dompred loss: 1.160457] time: 1:38:09.845795 
[Epoch 15/30] [Batch 300/516] [D loss: 0.000463, acc: 100%] [G loss: 9.324670, adv: 0.968156, cyc: 0.291100, id: 0.303582] [Dompred loss: 0.669734] time: 1:39:27.265204 
[Epoch 15/30] [Batch 400/516] [D loss: 0.000634, acc: 100%] [G loss: 12.968389, adv: 0.999783, cyc: 0.282733, id: 0.292909] [Dompred loss: 4.043320] time: 1:40:44.692234 
[Epoch 15/30] [Batch 500/516] [D loss: 0.003089, acc: 100%] [G loss: 11.920565, adv: 0.995438, cyc: 0.284551, id: 0.289186] [Dompred loss: 3.776002] time: 1:42:02.117194 
[Epoch 16/30] [Batch 0/516] [D loss: 0.000264, acc: 100%] [G loss: 12.949915, adv: 0.958877, cyc: 0.286713, id: 0.300209] [Dompred loss: 4.133209] time: 1:42:21.093158 
[Epoch 16/30] [Batch 100/516] [D loss: 0.000626, acc: 100%] [G loss: 12.327473, adv: 1.008642, cyc: 0.286666, id: 0.295452] [Dompred loss: 4.088156] time: 1:43:38.509984 
[Epoch 16/30] [Batch 200/516] [D loss: 0.001751, acc: 100%] [G loss: 11.542870, adv: 0.949461, cyc: 0.285544, id: 0.277022] [Dompred loss: 3.220095] time: 1:44:55.921054 
[Epoch 16/30] [Batch 300/516] [D loss: 0.000392, acc: 100%] [G loss: 12.858233, adv: 0.966403, cyc: 0.288378, id: 0.300925] [Dompred loss: 4.207348] time: 1:46:13.348778 
[Epoch 16/30] [Batch 400/516] [D loss: 0.000220, acc: 100%] [G loss: 11.019961, adv: 0.974497, cyc: 0.279342, id: 0.293858] [Dompred loss: 2.861459] time: 1:47:30.764094 
[Epoch 16/30] [Batch 500/516] [D loss: 0.000506, acc: 100%] [G loss: 10.734806, adv: 0.991102, cyc: 0.283323, id: 0.291930] [Dompred loss: 2.299582] time: 1:48:48.183611 
[Epoch 17/30] [Batch 0/516] [D loss: 0.000203, acc: 100%] [G loss: 11.109468, adv: 0.953493, cyc: 0.284633, id: 0.303421] [Dompred loss: 2.645106] time: 1:49:00.571206 
[Epoch 17/30] [Batch 100/516] [D loss: 0.000371, acc: 100%] [G loss: 10.891692, adv: 0.999377, cyc: 0.283965, id: 0.302432] [Dompred loss: 3.412117] time: 1:50:17.985537 
[Epoch 17/30] [Batch 200/516] [D loss: 0.000516, acc: 100%] [G loss: 11.985740, adv: 0.997585, cyc: 0.286623, id: 0.283162] [Dompred loss: 3.168781] time: 1:51:35.398241 
[Epoch 17/30] [Batch 300/516] [D loss: 0.000724, acc: 100%] [G loss: 11.056556, adv: 0.963243, cyc: 0.287288, id: 0.307673] [Dompred loss: 2.527750] time: 1:52:52.827613 
[Epoch 17/30] [Batch 400/516] [D loss: 0.001062, acc: 100%] [G loss: 9.835564, adv: 0.949249, cyc: 0.277485, id: 0.288034] [Dompred loss: 2.502012] time: 1:54:10.241995 
[Epoch 17/30] [Batch 500/516] [D loss: 0.000333, acc: 100%] [G loss: 10.035900, adv: 0.963124, cyc: 0.280511, id: 0.287538] [Dompred loss: 1.751957] time: 1:55:27.659304 
[Epoch 18/30] [Batch 0/516] [D loss: 0.000423, acc: 100%] [G loss: 10.077352, adv: 0.977334, cyc: 0.281932, id: 0.303014] [Dompred loss: 0.974556] time: 1:55:40.047503 
[Epoch 18/30] [Batch 100/516] [D loss: 0.001831, acc: 100%] [G loss: 11.605876, adv: 0.985755, cyc: 0.282410, id: 0.294296] [Dompred loss: 2.805216] time: 1:56:57.464851 
[Epoch 18/30] [Batch 200/516] [D loss: 0.001773, acc: 100%] [G loss: 10.894052, adv: 0.961771, cyc: 0.282129, id: 0.279364] [Dompred loss: 1.281172] time: 1:58:14.877870 
[Epoch 18/30] [Batch 300/516] [D loss: 0.001167, acc: 100%] [G loss: 10.966152, adv: 1.012220, cyc: 0.284216, id: 0.310657] [Dompred loss: 2.028811] time: 1:59:32.289588 
[Epoch 18/30] [Batch 400/516] [D loss: 0.000190, acc: 100%] [G loss: 9.994900, adv: 0.999668, cyc: 0.275059, id: 0.286796] [Dompred loss: 1.703362] time: 2:00:49.696407 
[Epoch 18/30] [Batch 500/516] [D loss: 0.000527, acc: 100%] [G loss: 10.976311, adv: 0.977811, cyc: 0.281192, id: 0.288773] [Dompred loss: 2.922707] time: 2:02:07.108677 
[Epoch 19/30] [Batch 0/516] [D loss: 0.000554, acc: 100%] [G loss: 12.105025, adv: 0.924798, cyc: 0.281347, id: 0.302321] [Dompred loss: 2.646662] time: 2:02:19.497151 
[Epoch 19/30] [Batch 100/516] [D loss: 0.000237, acc: 100%] [G loss: 10.695457, adv: 0.964627, cyc: 0.281575, id: 0.295425] [Dompred loss: 3.702279] time: 2:03:36.898664 
[Epoch 19/30] [Batch 200/516] [D loss: 0.000841, acc: 100%] [G loss: 11.886952, adv: 0.959127, cyc: 0.284024, id: 0.279873] [Dompred loss: 3.314157] time: 2:04:54.316757 
[Epoch 19/30] [Batch 300/516] [D loss: 0.000442, acc: 100%] [G loss: 9.641793, adv: 0.937670, cyc: 0.284188, id: 0.303668] [Dompred loss: 2.555933] time: 2:06:11.730649 
[Epoch 19/30] [Batch 400/516] [D loss: 0.000531, acc: 100%] [G loss: 10.269183, adv: 0.958886, cyc: 0.275154, id: 0.288138] [Dompred loss: 2.853255] time: 2:07:29.138622 
[Epoch 19/30] [Batch 500/516] [D loss: 0.000436, acc: 100%] [G loss: 10.591566, adv: 0.982019, cyc: 0.282302, id: 0.305265] [Dompred loss: 3.028413] time: 2:08:46.547404 
[Epoch 20/30] [Batch 0/516] [D loss: 0.000198, acc: 100%] [G loss: 11.401280, adv: 0.953026, cyc: 0.280107, id: 0.318747] [Dompred loss: 3.319961] time: 2:08:58.932240 
[Epoch 20/30] [Batch 100/516] [D loss: 0.000246, acc: 100%] [G loss: 11.571414, adv: 1.002290, cyc: 0.279883, id: 0.299042] [Dompred loss: 3.265580] time: 2:10:16.339387 
[Epoch 20/30] [Batch 200/516] [D loss: 0.000295, acc: 100%] [G loss: 10.144753, adv: 0.961830, cyc: 0.280302, id: 0.274195] [Dompred loss: 2.067795] time: 2:11:33.758876 
[Epoch 20/30] [Batch 300/516] [D loss: 0.000551, acc: 100%] [G loss: 9.515625, adv: 0.984503, cyc: 0.281806, id: 0.303324] [Dompred loss: 1.671088] time: 2:12:51.176113 
[Epoch 20/30] [Batch 400/516] [D loss: 0.000316, acc: 100%] [G loss: 9.156597, adv: 0.975838, cyc: 0.273172, id: 0.296298] [Dompred loss: 1.790518] time: 2:14:08.590527 
[Epoch 20/30] [Batch 500/516] [D loss: 0.000424, acc: 100%] [G loss: 10.297906, adv: 0.975671, cyc: 0.278475, id: 0.286392] [Dompred loss: 2.701560] time: 2:15:26.007210 
[Epoch 21/30] [Batch 0/516] [D loss: 0.000052, acc: 100%] [G loss: 10.177184, adv: 0.979375, cyc: 0.279409, id: 0.298480] [Dompred loss: 1.488301] time: 2:15:44.531093 
[Epoch 21/30] [Batch 100/516] [D loss: 0.000383, acc: 100%] [G loss: 10.735931, adv: 1.000539, cyc: 0.281403, id: 0.285626] [Dompred loss: 1.912595] time: 2:17:01.958138 
[Epoch 21/30] [Batch 200/516] [D loss: 0.001572, acc: 100%] [G loss: 9.767176, adv: 0.995585, cyc: 0.278214, id: 0.280739] [Dompred loss: 2.060395] time: 2:18:19.375095 
[Epoch 21/30] [Batch 300/516] [D loss: 0.000230, acc: 100%] [G loss: 9.940413, adv: 0.994062, cyc: 0.279650, id: 0.304749] [Dompred loss: 2.258441] time: 2:19:36.780267 
[Epoch 21/30] [Batch 400/516] [D loss: 0.000388, acc: 100%] [G loss: 10.234776, adv: 0.943715, cyc: 0.272448, id: 0.280963] [Dompred loss: 2.009725] time: 2:20:54.200057 
[Epoch 21/30] [Batch 500/516] [D loss: 0.000223, acc: 100%] [G loss: 11.457041, adv: 1.011947, cyc: 0.275368, id: 0.286570] [Dompred loss: 2.572357] time: 2:22:11.618456 
[Epoch 22/30] [Batch 0/516] [D loss: 0.000080, acc: 100%] [G loss: 10.085997, adv: 0.970732, cyc: 0.277786, id: 0.297321] [Dompred loss: 2.192275] time: 2:22:24.002072 
[Epoch 22/30] [Batch 100/516] [D loss: 0.000499, acc: 100%] [G loss: 9.270796, adv: 0.985092, cyc: 0.275680, id: 0.293288] [Dompred loss: 2.169635] time: 2:23:41.413976 
[Epoch 22/30] [Batch 200/516] [D loss: 0.001105, acc: 100%] [G loss: 10.199538, adv: 0.976940, cyc: 0.277031, id: 0.288068] [Dompred loss: 2.039199] time: 2:24:58.832418 
[Epoch 22/30] [Batch 300/516] [D loss: 0.000355, acc: 100%] [G loss: 9.714114, adv: 1.006063, cyc: 0.282222, id: 0.301669] [Dompred loss: 2.010141] time: 2:26:16.264921 
[Epoch 22/30] [Batch 400/516] [D loss: 0.000789, acc: 100%] [G loss: 10.659725, adv: 1.028751, cyc: 0.271133, id: 0.295098] [Dompred loss: 1.219166] time: 2:27:33.689668 
[Epoch 22/30] [Batch 500/516] [D loss: 0.000147, acc: 100%] [G loss: 10.934300, adv: 0.973526, cyc: 0.273029, id: 0.282719] [Dompred loss: 1.807322] time: 2:28:51.109958 
[Epoch 23/30] [Batch 0/516] [D loss: 0.000233, acc: 100%] [G loss: 9.939954, adv: 0.989628, cyc: 0.275066, id: 0.302540] [Dompred loss: 2.668638] time: 2:29:03.496613 
[Epoch 23/30] [Batch 100/516] [D loss: 0.000360, acc: 100%] [G loss: 11.109915, adv: 1.028187, cyc: 0.276723, id: 0.297953] [Dompred loss: 3.676142] time: 2:30:20.910919 
[Epoch 23/30] [Batch 200/516] [D loss: 0.000756, acc: 100%] [G loss: 10.271381, adv: 1.022198, cyc: 0.279294, id: 0.274320] [Dompred loss: 1.981532] time: 2:31:38.332573 
[Epoch 23/30] [Batch 300/516] [D loss: 0.000266, acc: 100%] [G loss: 9.790358, adv: 0.960977, cyc: 0.277628, id: 0.306643] [Dompred loss: 2.150394] time: 2:32:55.752612 
[Epoch 23/30] [Batch 400/516] [D loss: 0.000094, acc: 100%] [G loss: 9.577848, adv: 0.982930, cyc: 0.270582, id: 0.282929] [Dompred loss: 2.016746] time: 2:34:13.164108 
[Epoch 23/30] [Batch 500/516] [D loss: 0.000168, acc: 100%] [G loss: 10.662884, adv: 0.965177, cyc: 0.271732, id: 0.287090] [Dompred loss: 3.152660] time: 2:35:30.580237 
[Epoch 24/30] [Batch 0/516] [D loss: 0.000127, acc: 100%] [G loss: 11.369226, adv: 0.997622, cyc: 0.274651, id: 0.320895] [Dompred loss: 3.540381] time: 2:35:42.965140 
[Epoch 24/30] [Batch 100/516] [D loss: 0.000197, acc: 100%] [G loss: 9.877081, adv: 1.003932, cyc: 0.274304, id: 0.296574] [Dompred loss: 0.795779] time: 2:37:00.372387 
[Epoch 24/30] [Batch 200/516] [D loss: 0.001434, acc:  99%] [G loss: 9.862595, adv: 0.989921, cyc: 0.273837, id: 0.274465] [Dompred loss: 3.066385] time: 2:38:17.782116 
[Epoch 24/30] [Batch 300/516] [D loss: 0.000144, acc: 100%] [G loss: 10.551079, adv: 0.986687, cyc: 0.275871, id: 0.308389] [Dompred loss: 1.757236] time: 2:39:35.188191 
[Epoch 24/30] [Batch 400/516] [D loss: 0.000303, acc: 100%] [G loss: 8.586604, adv: 0.997269, cyc: 0.268571, id: 0.278730] [Dompred loss: 0.746854] time: 2:40:52.606942 
[Epoch 24/30] [Batch 500/516] [D loss: 0.000191, acc: 100%] [G loss: 9.953011, adv: 0.995321, cyc: 0.271426, id: 0.287400] [Dompred loss: 1.947901] time: 2:42:10.023866 
[Epoch 25/30] [Batch 0/516] [D loss: 0.000103, acc: 100%] [G loss: 10.091220, adv: 0.995000, cyc: 0.272105, id: 0.301480] [Dompred loss: 1.667371] time: 2:42:22.407927 
[Epoch 25/30] [Batch 100/516] [D loss: 0.000533, acc: 100%] [G loss: 9.196742, adv: 0.991959, cyc: 0.272673, id: 0.287861] [Dompred loss: 0.588969] time: 2:43:39.812772 
[Epoch 25/30] [Batch 200/516] [D loss: 0.000505, acc: 100%] [G loss: 10.596354, adv: 0.982285, cyc: 0.272662, id: 0.270995] [Dompred loss: 2.366872] time: 2:44:57.220692 
[Epoch 25/30] [Batch 300/516] [D loss: 0.000196, acc: 100%] [G loss: 9.044834, adv: 0.987963, cyc: 0.274741, id: 0.308793] [Dompred loss: 1.873445] time: 2:46:14.643995 
[Epoch 25/30] [Batch 400/516] [D loss: 0.000150, acc: 100%] [G loss: 10.137419, adv: 0.996004, cyc: 0.265737, id: 0.282852] [Dompred loss: 3.232429] time: 2:47:32.065283 
[Epoch 25/30] [Batch 500/516] [D loss: 0.000353, acc: 100%] [G loss: 9.968710, adv: 0.976918, cyc: 0.269821, id: 0.287747] [Dompred loss: 1.790568] time: 2:48:49.494435 
[Epoch 26/30] [Batch 0/516] [D loss: 0.000106, acc: 100%] [G loss: 11.111848, adv: 0.969711, cyc: 0.272157, id: 0.306363] [Dompred loss: 2.042897] time: 2:49:03.024844 
[Epoch 26/30] [Batch 100/516] [D loss: 0.000165, acc: 100%] [G loss: 8.890777, adv: 0.952767, cyc: 0.275016, id: 0.291373] [Dompred loss: 1.094856] time: 2:50:20.447537 
[Epoch 26/30] [Batch 200/516] [D loss: 0.001610, acc: 100%] [G loss: 10.263487, adv: 0.949548, cyc: 0.273767, id: 0.277306] [Dompred loss: 1.512058] time: 2:51:37.871251 
[Epoch 26/30] [Batch 300/516] [D loss: 0.000268, acc: 100%] [G loss: 9.302487, adv: 1.015867, cyc: 0.275125, id: 0.303411] [Dompred loss: 1.178984] time: 2:52:55.286232 
[Epoch 26/30] [Batch 400/516] [D loss: 0.000506, acc: 100%] [G loss: 11.070264, adv: 0.990518, cyc: 0.267700, id: 0.279231] [Dompred loss: 1.167591] time: 2:54:12.704207 
[Epoch 26/30] [Batch 500/516] [D loss: 0.000226, acc: 100%] [G loss: 10.330055, adv: 1.003493, cyc: 0.268562, id: 0.286386] [Dompred loss: 2.398675] time: 2:55:30.128114 
[Epoch 27/30] [Batch 0/516] [D loss: 0.000263, acc: 100%] [G loss: 10.199294, adv: 0.992161, cyc: 0.270873, id: 0.300049] [Dompred loss: 2.151472] time: 2:55:42.516175 
[Epoch 27/30] [Batch 100/516] [D loss: 0.000111, acc: 100%] [G loss: 9.139197, adv: 1.004055, cyc: 0.270698, id: 0.290855] [Dompred loss: 2.072856] time: 2:56:59.931915 
[Epoch 27/30] [Batch 200/516] [D loss: 0.000103, acc: 100%] [G loss: 9.810718, adv: 1.005270, cyc: 0.270892, id: 0.272467] [Dompred loss: 1.475358] time: 2:58:17.341898 
[Epoch 27/30] [Batch 300/516] [D loss: 0.000164, acc: 100%] [G loss: 8.734302, adv: 0.976549, cyc: 0.274421, id: 0.308629] [Dompred loss: 1.639083] time: 2:59:34.747874 
[Epoch 27/30] [Batch 400/516] [D loss: 0.000150, acc: 100%] [G loss: 10.124433, adv: 0.964530, cyc: 0.264147, id: 0.285784] [Dompred loss: 2.332813] time: 3:00:52.164020 
[Epoch 27/30] [Batch 500/516] [D loss: 0.000225, acc: 100%] [G loss: 9.844574, adv: 0.972639, cyc: 0.267643, id: 0.282557] [Dompred loss: 2.446830] time: 3:02:09.571166 
[Epoch 28/30] [Batch 0/516] [D loss: 0.000123, acc: 100%] [G loss: 10.148417, adv: 0.959403, cyc: 0.270721, id: 0.298219] [Dompred loss: 3.140421] time: 3:02:21.956397 
[Epoch 28/30] [Batch 100/516] [D loss: 0.000093, acc: 100%] [G loss: 9.561999, adv: 0.952981, cyc: 0.270105, id: 0.285014] [Dompred loss: 1.860335] time: 3:03:39.372711 
[Epoch 28/30] [Batch 200/516] [D loss: 0.001158, acc: 100%] [G loss: 9.871243, adv: 0.976552, cyc: 0.270310, id: 0.282036] [Dompred loss: 2.199180] time: 3:04:56.794041 
[Epoch 28/30] [Batch 300/516] [D loss: 0.000512, acc: 100%] [G loss: 8.587992, adv: 0.958385, cyc: 0.272447, id: 0.298109] [Dompred loss: 0.818051] time: 3:06:14.213253 
[Epoch 28/30] [Batch 400/516] [D loss: 0.000538, acc: 100%] [G loss: 10.250298, adv: 0.999897, cyc: 0.263552, id: 0.282086] [Dompred loss: 2.163607] time: 3:07:31.614025 
[Epoch 28/30] [Batch 500/516] [D loss: 0.000310, acc: 100%] [G loss: 10.841398, adv: 0.939118, cyc: 0.271577, id: 0.287393] [Dompred loss: 3.383276] time: 3:08:49.029506 
[Epoch 29/30] [Batch 0/516] [D loss: 0.000108, acc: 100%] [G loss: 10.384058, adv: 0.965398, cyc: 0.268182, id: 0.296178] [Dompred loss: 3.630357] time: 3:09:01.415578 
[Epoch 29/30] [Batch 100/516] [D loss: 0.000281, acc: 100%] [G loss: 10.178267, adv: 1.021717, cyc: 0.269557, id: 0.290125] [Dompred loss: 1.910778] time: 3:10:18.821177 
[Epoch 29/30] [Batch 200/516] [D loss: 0.000454, acc: 100%] [G loss: 9.678572, adv: 0.988262, cyc: 0.267818, id: 0.271328] [Dompred loss: 2.791394] time: 3:11:36.226827 
[Epoch 29/30] [Batch 300/516] [D loss: 0.000079, acc: 100%] [G loss: 10.598071, adv: 1.001830, cyc: 0.271265, id: 0.302492] [Dompred loss: 2.320009] time: 3:12:53.633320 
[Epoch 29/30] [Batch 400/516] [D loss: 0.000494, acc: 100%] [G loss: 11.016157, adv: 1.019634, cyc: 0.263491, id: 0.279232] [Dompred loss: 2.330922] time: 3:14:11.035035 
[Epoch 29/30] [Batch 500/516] [D loss: 0.000249, acc: 100%] [G loss: 10.714566, adv: 0.968548, cyc: 0.266093, id: 0.280768] [Dompred loss: 2.506401] time: 3:15:28.456881 
[Epoch 30/30] [Batch 0/516] [D loss: 0.000034, acc: 100%] [G loss: 11.677481, adv: 0.963668, cyc: 0.267914, id: 0.296564] [Dompred loss: 3.404125] time: 3:15:40.842580 
[Epoch 30/30] [Batch 100/516] [D loss: 0.000072, acc: 100%] [G loss: 10.342990, adv: 0.967881, cyc: 0.269294, id: 0.288578] [Dompred loss: 2.406975] time: 3:16:58.255420 
[Epoch 30/30] [Batch 200/516] [D loss: 0.000665, acc: 100%] [G loss: 10.027477, adv: 0.973985, cyc: 0.267917, id: 0.273706] [Dompred loss: 2.198895] time: 3:18:15.668705 
[Epoch 30/30] [Batch 300/516] [D loss: 0.000071, acc: 100%] [G loss: 9.340516, adv: 0.992837, cyc: 0.270709, id: 0.298757] [Dompred loss: 1.425081] time: 3:19:33.072151 
[Epoch 30/30] [Batch 400/516] [D loss: 0.000744, acc: 100%] [G loss: 10.870153, adv: 1.032688, cyc: 0.262714, id: 0.287749] [Dompred loss: 1.735635] time: 3:20:50.485019 
[Epoch 30/30] [Batch 500/516] [D loss: 0.000190, acc: 100%] [G loss: 9.415252, adv: 0.965446, cyc: 0.264768, id: 0.281990] [Dompred loss: 1.075722] time: 3:22:07.899460 
Train Finished.
