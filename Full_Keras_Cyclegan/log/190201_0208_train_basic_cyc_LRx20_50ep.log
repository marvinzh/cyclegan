_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_A_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_B_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
ivec_b (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
ivec_a (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
model_4 (Model)                 (None, 1, 600, 1)    653345      ivec_b[0][0]                     
                                                                 model_3[1][0]                    
                                                                 ivec_a[0][0]                     
__________________________________________________________________________________________________
model_3 (Model)                 (None, 1, 600, 1)    653345      ivec_a[0][0]                     
                                                                 model_4[1][0]                    
                                                                 ivec_b[0][0]                     
__________________________________________________________________________________________________
model_2 (Model)                 (None, 1)            39610241    model_4[1][0]                    
__________________________________________________________________________________________________
model_1 (Model)                 (None, 1)            39610241    model_3[1][0]                    
==================================================================================================
Total params: 80,527,172
Trainable params: 1,306,690
Non-trainable params: 79,220,482
__________________________________________________________________________________________________
Start CycleGAN training.
[Epoch 1/50] [Batch 0/516] [D loss: 0.488827, acc:  50%] [G loss: 22.179052, adv: 0.746338, cyc: 0.940931, id: 0.948260] time: 0:02:00.369954 
[Epoch 1/50] [Batch 100/516] [D loss: 0.057357, acc: 100%] [G loss: 19.142262, adv: 0.408136, cyc: 0.835299, id: 0.847927] time: 0:03:06.927870 
[Epoch 1/50] [Batch 200/516] [D loss: 0.023387, acc: 100%] [G loss: 18.747519, adv: 0.859514, cyc: 0.777825, id: 0.793213] time: 0:04:13.462846 
[Epoch 1/50] [Batch 300/516] [D loss: 0.056696, acc:  98%] [G loss: 18.501328, adv: 1.125397, cyc: 0.745059, id: 0.721069] time: 0:05:19.997338 
[Epoch 1/50] [Batch 400/516] [D loss: 0.048475, acc:  98%] [G loss: 17.283291, adv: 1.181912, cyc: 0.687005, id: 0.634982] time: 0:06:26.528633 
[Epoch 1/50] [Batch 500/516] [D loss: 0.099515, acc:  91%] [G loss: 16.298927, adv: 1.136772, cyc: 0.648701, id: 0.564849] time: 0:07:33.062502 
[Epoch 2/50] [Batch 0/516] [D loss: 0.115260, acc:  85%] [G loss: 16.204628, adv: 1.138336, cyc: 0.644617, id: 0.551046] time: 0:07:43.710001 
[Epoch 2/50] [Batch 100/516] [D loss: 0.067967, acc:  93%] [G loss: 15.018506, adv: 1.118014, cyc: 0.591750, id: 0.515240] time: 0:08:50.240797 
[Epoch 2/50] [Batch 200/516] [D loss: 0.069262, acc:  92%] [G loss: 14.376340, adv: 1.071689, cyc: 0.566612, id: 0.495142] time: 0:09:56.769656 
[Epoch 2/50] [Batch 300/516] [D loss: 0.072929, acc:  93%] [G loss: 13.893970, adv: 1.072847, cyc: 0.543852, id: 0.474861] time: 0:11:03.304366 
[Epoch 2/50] [Batch 400/516] [D loss: 0.059626, acc:  95%] [G loss: 13.332157, adv: 1.060307, cyc: 0.519156, id: 0.450899] time: 0:12:09.836700 
[Epoch 2/50] [Batch 500/516] [D loss: 0.042864, acc:  97%] [G loss: 13.236573, adv: 1.039852, cyc: 0.516683, id: 0.448464] time: 0:13:16.360824 
[Epoch 3/50] [Batch 0/516] [D loss: 0.061572, acc:  95%] [G loss: 13.148750, adv: 1.029968, cyc: 0.513260, id: 0.440691] time: 0:13:27.006003 
[Epoch 3/50] [Batch 100/516] [D loss: 0.042803, acc:  96%] [G loss: 12.858439, adv: 1.038223, cyc: 0.499260, id: 0.429763] time: 0:14:33.532145 
[Epoch 3/50] [Batch 200/516] [D loss: 0.036378, acc:  98%] [G loss: 12.677902, adv: 1.039149, cyc: 0.490629, id: 0.427351] time: 0:15:40.050838 
[Epoch 3/50] [Batch 300/516] [D loss: 0.043216, acc:  98%] [G loss: 12.489999, adv: 0.987952, cyc: 0.486524, id: 0.423566] time: 0:16:46.575814 
[Epoch 3/50] [Batch 400/516] [D loss: 0.037372, acc:  98%] [G loss: 12.144795, adv: 0.998098, cyc: 0.469807, id: 0.405553] time: 0:17:53.091848 
[Epoch 3/50] [Batch 500/516] [D loss: 0.026359, acc: 100%] [G loss: 12.226870, adv: 0.990859, cyc: 0.474000, id: 0.415618] time: 0:18:59.605070 
[Epoch 4/50] [Batch 0/516] [D loss: 0.038694, acc:  99%] [G loss: 12.084207, adv: 0.964525, cyc: 0.469484, id: 0.407396] time: 0:19:10.248985 
[Epoch 4/50] [Batch 100/516] [D loss: 0.030355, acc:  99%] [G loss: 11.932920, adv: 0.964462, cyc: 0.462827, id: 0.402528] time: 0:20:16.760383 
[Epoch 4/50] [Batch 200/516] [D loss: 0.025126, acc:  99%] [G loss: 11.825269, adv: 0.961623, cyc: 0.457933, id: 0.404036] time: 0:21:23.281799 
[Epoch 4/50] [Batch 300/516] [D loss: 0.033285, acc:  99%] [G loss: 11.750571, adv: 0.924387, cyc: 0.457861, id: 0.403105] time: 0:22:29.787496 
[Epoch 4/50] [Batch 400/516] [D loss: 0.029092, acc:  99%] [G loss: 11.466065, adv: 0.938985, cyc: 0.443509, id: 0.387881] time: 0:23:36.286598 
[Epoch 4/50] [Batch 500/516] [D loss: 0.019620, acc: 100%] [G loss: 11.526585, adv: 0.897020, cyc: 0.449840, id: 0.399989] time: 0:24:42.791074 
[Epoch 5/50] [Batch 0/516] [D loss: 0.028868, acc: 100%] [G loss: 11.513995, adv: 0.899455, cyc: 0.449042, id: 0.390678] time: 0:24:53.430987 
[Epoch 5/50] [Batch 100/516] [D loss: 0.026945, acc:  99%] [G loss: 11.351276, adv: 0.899785, cyc: 0.441523, id: 0.391261] time: 0:25:59.922396 
[Epoch 5/50] [Batch 200/516] [D loss: 0.020205, acc: 100%] [G loss: 11.298972, adv: 0.891425, cyc: 0.439685, id: 0.395078] time: 0:27:06.414578 
[Epoch 5/50] [Batch 300/516] [D loss: 0.033591, acc:  99%] [G loss: 11.314609, adv: 0.904201, cyc: 0.439073, id: 0.395991] time: 0:28:12.902297 
[Epoch 5/50] [Batch 400/516] [D loss: 0.025296, acc:  99%] [G loss: 11.025957, adv: 0.899241, cyc: 0.426478, id: 0.381558] time: 0:29:19.385664 
[Epoch 5/50] [Batch 500/516] [D loss: 0.017564, acc: 100%] [G loss: 11.113590, adv: 0.840341, cyc: 0.435788, id: 0.393689] time: 0:30:25.865582 
[Epoch 6/50] [Batch 0/516] [D loss: 0.026064, acc: 100%] [G loss: 11.099683, adv: 0.865458, cyc: 0.432776, id: 0.383671] time: 0:30:43.331992 
[Epoch 6/50] [Batch 100/516] [D loss: 0.036231, acc:  99%] [G loss: 11.065944, adv: 0.915139, cyc: 0.426508, id: 0.385792] time: 0:31:49.819250 
[Epoch 6/50] [Batch 200/516] [D loss: 0.021102, acc: 100%] [G loss: 10.963831, adv: 0.871745, cyc: 0.425733, id: 0.387909] time: 0:32:56.296215 
[Epoch 6/50] [Batch 300/516] [D loss: 0.035831, acc:  99%] [G loss: 11.016598, adv: 0.892963, cyc: 0.426117, id: 0.390123] time: 0:34:02.770197 
[Epoch 6/50] [Batch 400/516] [D loss: 0.022993, acc:  99%] [G loss: 10.688371, adv: 0.866772, cyc: 0.413687, id: 0.374294] time: 0:35:09.233979 
[Epoch 6/50] [Batch 500/516] [D loss: 0.019222, acc: 100%] [G loss: 10.828763, adv: 0.853047, cyc: 0.420992, id: 0.388856] time: 0:36:15.701629 
[Epoch 7/50] [Batch 0/516] [D loss: 0.023911, acc: 100%] [G loss: 10.756248, adv: 0.820096, cyc: 0.420775, id: 0.379104] time: 0:36:26.334791 
[Epoch 7/50] [Batch 100/516] [D loss: 0.034136, acc:  99%] [G loss: 10.787707, adv: 0.901032, cyc: 0.414711, id: 0.380127] time: 0:37:32.799734 
[Epoch 7/50] [Batch 200/516] [D loss: 0.020033, acc: 100%] [G loss: 10.693384, adv: 0.856399, cyc: 0.414396, id: 0.385015] time: 0:38:39.259831 
[Epoch 7/50] [Batch 300/516] [D loss: 0.034610, acc:  99%] [G loss: 10.735656, adv: 0.865406, cyc: 0.415527, id: 0.383481] time: 0:39:45.716163 
[Epoch 7/50] [Batch 400/516] [D loss: 0.022504, acc:  99%] [G loss: 10.381274, adv: 0.834775, cyc: 0.402187, id: 0.370521] time: 0:40:52.166909 
[Epoch 7/50] [Batch 500/516] [D loss: 0.016812, acc: 100%] [G loss: 10.534707, adv: 0.810052, cyc: 0.411073, id: 0.385619] time: 0:41:58.624669 
[Epoch 8/50] [Batch 0/516] [D loss: 0.021681, acc: 100%] [G loss: 10.473700, adv: 0.784216, cyc: 0.410839, id: 0.376139] time: 0:42:09.255829 
[Epoch 8/50] [Batch 100/516] [D loss: 0.031677, acc:  99%] [G loss: 10.506006, adv: 0.862167, cyc: 0.405076, id: 0.376606] time: 0:43:15.704891 
[Epoch 8/50] [Batch 200/516] [D loss: 0.018323, acc: 100%] [G loss: 10.435380, adv: 0.832080, cyc: 0.404421, id: 0.381921] time: 0:44:22.147733 
[Epoch 8/50] [Batch 300/516] [D loss: 0.033680, acc:  99%] [G loss: 10.488921, adv: 0.840822, cyc: 0.406075, id: 0.381578] time: 0:45:28.597134 
[Epoch 8/50] [Batch 400/516] [D loss: 0.021870, acc:  99%] [G loss: 10.166345, adv: 0.822351, cyc: 0.393120, id: 0.367765] time: 0:46:35.042383 
[Epoch 8/50] [Batch 500/516] [D loss: 0.015233, acc: 100%] [G loss: 10.268718, adv: 0.772343, cyc: 0.402011, id: 0.383854] time: 0:47:41.481656 
[Epoch 9/50] [Batch 0/516] [D loss: 0.020387, acc: 100%] [G loss: 10.256412, adv: 0.768054, cyc: 0.401980, id: 0.374064] time: 0:47:52.111185 
[Epoch 9/50] [Batch 100/516] [D loss: 0.027744, acc:  99%] [G loss: 10.254792, adv: 0.816193, cyc: 0.397589, id: 0.374092] time: 0:48:58.544084 
[Epoch 9/50] [Batch 200/516] [D loss: 0.016948, acc: 100%] [G loss: 10.176593, adv: 0.787214, cyc: 0.396469, id: 0.378634] time: 0:50:04.982114 
[Epoch 9/50] [Batch 300/516] [D loss: 0.030877, acc:  99%] [G loss: 10.247256, adv: 0.798761, cyc: 0.398634, id: 0.379520] time: 0:51:11.416702 
[Epoch 9/50] [Batch 400/516] [D loss: 0.020937, acc:  99%] [G loss: 9.978498, adv: 0.790557, cyc: 0.387365, id: 0.363835] time: 0:52:17.847195 
[Epoch 9/50] [Batch 500/516] [D loss: 0.014236, acc: 100%] [G loss: 10.123759, adv: 0.749517, cyc: 0.397427, id: 0.381357] time: 0:53:24.272154 
[Epoch 10/50] [Batch 0/516] [D loss: 0.019162, acc: 100%] [G loss: 10.090668, adv: 0.762925, cyc: 0.394652, id: 0.370778] time: 0:53:34.900291 
[Epoch 10/50] [Batch 100/516] [D loss: 0.024986, acc:  99%] [G loss: 10.049976, adv: 0.788341, cyc: 0.390538, id: 0.371327] time: 0:54:41.320998 
[Epoch 10/50] [Batch 200/516] [D loss: 0.015506, acc: 100%] [G loss: 10.049861, adv: 0.774749, cyc: 0.391724, id: 0.377108] time: 0:55:47.738653 
[Epoch 10/50] [Batch 300/516] [D loss: 0.027849, acc:  99%] [G loss: 10.119465, adv: 0.795598, cyc: 0.392835, id: 0.378220] time: 0:56:54.147885 
[Epoch 10/50] [Batch 400/516] [D loss: 0.019967, acc:  99%] [G loss: 9.796061, adv: 0.790765, cyc: 0.378561, id: 0.361916] time: 0:58:00.555879 
[Epoch 10/50] [Batch 500/516] [D loss: 0.013375, acc: 100%] [G loss: 9.916042, adv: 0.707264, cyc: 0.391651, id: 0.379711] time: 0:59:06.962917 
[Epoch 11/50] [Batch 0/516] [D loss: 0.017849, acc: 100%] [G loss: 9.862827, adv: 0.732977, cyc: 0.386780, id: 0.366675] time: 0:59:19.965153 
[Epoch 11/50] [Batch 100/516] [D loss: 0.022903, acc:  99%] [G loss: 9.861737, adv: 0.755211, cyc: 0.384692, id: 0.370369] time: 1:00:26.378249 
[Epoch 11/50] [Batch 200/516] [D loss: 0.014293, acc: 100%] [G loss: 9.819007, adv: 0.751183, cyc: 0.383040, id: 0.371932] time: 1:01:32.799288 
[Epoch 11/50] [Batch 300/516] [D loss: 0.026061, acc:  99%] [G loss: 9.941149, adv: 0.783122, cyc: 0.385746, id: 0.372032] time: 1:02:39.207819 
[Epoch 11/50] [Batch 400/516] [D loss: 0.018052, acc: 100%] [G loss: 9.626097, adv: 0.727981, cyc: 0.376558, id: 0.362384] time: 1:03:45.616161 
[Epoch 11/50] [Batch 500/516] [D loss: 0.012370, acc: 100%] [G loss: 9.770985, adv: 0.686715, cyc: 0.386635, id: 0.379059] time: 1:04:52.028813 
[Epoch 12/50] [Batch 0/516] [D loss: 0.016303, acc: 100%] [G loss: 9.734321, adv: 0.708591, cyc: 0.382993, id: 0.365643] time: 1:05:02.655831 
[Epoch 12/50] [Batch 100/516] [D loss: 0.020649, acc:  99%] [G loss: 9.750570, adv: 0.754511, cyc: 0.379715, id: 0.364462] time: 1:06:09.052951 
[Epoch 12/50] [Batch 200/516] [D loss: 0.012934, acc: 100%] [G loss: 9.636247, adv: 0.717538, cyc: 0.377604, id: 0.369329] time: 1:07:15.449936 
[Epoch 12/50] [Batch 300/516] [D loss: 0.021557, acc:  99%] [G loss: 9.806760, adv: 0.740236, cyc: 0.383410, id: 0.374376] time: 1:08:21.850540 
[Epoch 12/50] [Batch 400/516] [D loss: 0.015619, acc: 100%] [G loss: 9.491938, adv: 0.709674, cyc: 0.371693, id: 0.364079] time: 1:09:28.241746 
[Epoch 12/50] [Batch 500/516] [D loss: 0.011614, acc: 100%] [G loss: 9.630835, adv: 0.667217, cyc: 0.381819, id: 0.378342] time: 1:10:34.625690 
[Epoch 13/50] [Batch 0/516] [D loss: 0.014920, acc: 100%] [G loss: 9.667853, adv: 0.715327, cyc: 0.379237, id: 0.364689] time: 1:10:45.248354 
[Epoch 13/50] [Batch 100/516] [D loss: 0.017985, acc:  99%] [G loss: 9.606606, adv: 0.742013, cyc: 0.374055, id: 0.361881] time: 1:11:51.651494 
[Epoch 13/50] [Batch 200/516] [D loss: 0.011433, acc: 100%] [G loss: 9.638424, adv: 0.697056, cyc: 0.379543, id: 0.376916] time: 1:12:58.025006 
[Epoch 13/50] [Batch 300/516] [D loss: 0.019000, acc:  99%] [G loss: 9.614318, adv: 0.699183, cyc: 0.378255, id: 0.370442] time: 1:14:04.400488 
[Epoch 13/50] [Batch 400/516] [D loss: 0.014665, acc: 100%] [G loss: 9.328880, adv: 0.703050, cyc: 0.364882, id: 0.354832] time: 1:15:10.773421 
[Epoch 13/50] [Batch 500/516] [D loss: 0.010467, acc: 100%] [G loss: 9.538928, adv: 0.696402, cyc: 0.374802, id: 0.370881] time: 1:16:17.145751 
[Epoch 14/50] [Batch 0/516] [D loss: 0.013267, acc: 100%] [G loss: 9.466507, adv: 0.668071, cyc: 0.374307, id: 0.359313] time: 1:16:27.763375 
[Epoch 14/50] [Batch 100/516] [D loss: 0.016493, acc:  99%] [G loss: 9.500592, adv: 0.712078, cyc: 0.371857, id: 0.361921] time: 1:17:34.130492 
[Epoch 14/50] [Batch 200/516] [D loss: 0.010331, acc: 100%] [G loss: 9.460691, adv: 0.680979, cyc: 0.372824, id: 0.368294] time: 1:18:40.472461 
[Epoch 14/50] [Batch 300/516] [D loss: 0.016451, acc:  99%] [G loss: 9.505990, adv: 0.698798, cyc: 0.373013, id: 0.368288] time: 1:19:46.801092 
[Epoch 14/50] [Batch 400/516] [D loss: 0.012711, acc: 100%] [G loss: 9.290836, adv: 0.677552, cyc: 0.365602, id: 0.356723] time: 1:20:53.116670 
[Epoch 14/50] [Batch 500/516] [D loss: 0.009571, acc: 100%] [G loss: 9.391338, adv: 0.667078, cyc: 0.370583, id: 0.368278] time: 1:21:59.438077 
[Epoch 15/50] [Batch 0/516] [D loss: 0.012109, acc: 100%] [G loss: 9.406214, adv: 0.688814, cyc: 0.369383, id: 0.357148] time: 1:22:10.045202 
[Epoch 15/50] [Batch 100/516] [D loss: 0.014211, acc:  99%] [G loss: 9.368347, adv: 0.684930, cyc: 0.368097, id: 0.362653] time: 1:23:16.353755 
[Epoch 15/50] [Batch 200/516] [D loss: 0.009347, acc: 100%] [G loss: 9.422727, adv: 0.661843, cyc: 0.372777, id: 0.370667] time: 1:24:22.671162 
[Epoch 15/50] [Batch 300/516] [D loss: 0.015379, acc:  99%] [G loss: 9.435719, adv: 0.691072, cyc: 0.370481, id: 0.366861] time: 1:25:28.982935 
[Epoch 15/50] [Batch 400/516] [D loss: 0.011636, acc: 100%] [G loss: 9.201518, adv: 0.674167, cyc: 0.361686, id: 0.353937] time: 1:26:35.294395 
[Epoch 15/50] [Batch 500/516] [D loss: 0.008743, acc: 100%] [G loss: 9.310518, adv: 0.661707, cyc: 0.367460, id: 0.363854] time: 1:27:41.609306 
[Epoch 16/50] [Batch 0/516] [D loss: 0.010796, acc: 100%] [G loss: 9.316908, adv: 0.672684, cyc: 0.366752, id: 0.355311] time: 1:27:53.637644 
[Epoch 16/50] [Batch 100/516] [D loss: 0.012971, acc: 100%] [G loss: 9.230534, adv: 0.676503, cyc: 0.362538, id: 0.353922] time: 1:28:59.943731 
[Epoch 16/50] [Batch 200/516] [D loss: 0.008349, acc: 100%] [G loss: 9.264211, adv: 0.674027, cyc: 0.364205, id: 0.361921] time: 1:30:06.252299 
[Epoch 16/50] [Batch 300/516] [D loss: 0.013206, acc:  99%] [G loss: 9.430670, adv: 0.691391, cyc: 0.370163, id: 0.369135] time: 1:31:12.570690 
[Epoch 16/50] [Batch 400/516] [D loss: 0.010906, acc: 100%] [G loss: 9.094312, adv: 0.683361, cyc: 0.355871, id: 0.346066] time: 1:32:18.882978 
[Epoch 16/50] [Batch 500/516] [D loss: 0.007912, acc: 100%] [G loss: 9.221172, adv: 0.639480, cyc: 0.365307, id: 0.362983] time: 1:33:25.200103 
[Epoch 17/50] [Batch 0/516] [D loss: 0.009951, acc: 100%] [G loss: 9.232237, adv: 0.664556, cyc: 0.363544, id: 0.352657] time: 1:33:35.810386 
[Epoch 17/50] [Batch 100/516] [D loss: 0.010815, acc: 100%] [G loss: 9.130947, adv: 0.652903, cyc: 0.359904, id: 0.356325] time: 1:34:42.122804 
[Epoch 17/50] [Batch 200/516] [D loss: 0.007464, acc: 100%] [G loss: 9.173182, adv: 0.656640, cyc: 0.361579, id: 0.358540] time: 1:35:48.430596 
[Epoch 17/50] [Batch 300/516] [D loss: 0.012115, acc:  99%] [G loss: 9.254238, adv: 0.680923, cyc: 0.363039, id: 0.357461] time: 1:36:54.747281 
[Epoch 17/50] [Batch 400/516] [D loss: 0.010194, acc: 100%] [G loss: 9.003080, adv: 0.668309, cyc: 0.352848, id: 0.346089] time: 1:38:01.052576 
[Epoch 17/50] [Batch 500/516] [D loss: 0.007256, acc: 100%] [G loss: 9.141713, adv: 0.628930, cyc: 0.362578, id: 0.361776] time: 1:39:07.362228 
[Epoch 18/50] [Batch 0/516] [D loss: 0.008723, acc: 100%] [G loss: 9.199147, adv: 0.664255, cyc: 0.362065, id: 0.350286] time: 1:39:17.973879 
[Epoch 18/50] [Batch 100/516] [D loss: 0.009691, acc: 100%] [G loss: 9.124632, adv: 0.671646, cyc: 0.357981, id: 0.352450] time: 1:40:24.278961 
[Epoch 18/50] [Batch 200/516] [D loss: 0.006791, acc: 100%] [G loss: 9.128681, adv: 0.655811, cyc: 0.359718, id: 0.354859] time: 1:41:30.587752 
[Epoch 18/50] [Batch 300/516] [D loss: 0.010056, acc: 100%] [G loss: 9.192422, adv: 0.659095, cyc: 0.362068, id: 0.360712] time: 1:42:36.889477 
[Epoch 18/50] [Batch 400/516] [D loss: 0.008733, acc: 100%] [G loss: 8.913663, adv: 0.667834, cyc: 0.348636, id: 0.342960] time: 1:43:43.190788 
[Epoch 18/50] [Batch 500/516] [D loss: 0.006542, acc: 100%] [G loss: 9.044451, adv: 0.626348, cyc: 0.358221, id: 0.357683] time: 1:44:49.492832 
[Epoch 19/50] [Batch 0/516] [D loss: 0.007857, acc: 100%] [G loss: 9.093800, adv: 0.651123, cyc: 0.358310, id: 0.347165] time: 1:45:00.101326 
[Epoch 19/50] [Batch 100/516] [D loss: 0.008772, acc: 100%] [G loss: 9.057179, adv: 0.655355, cyc: 0.356351, id: 0.349919] time: 1:46:06.398222 
[Epoch 19/50] [Batch 200/516] [D loss: 0.006162, acc: 100%] [G loss: 9.024122, adv: 0.638411, cyc: 0.356449, id: 0.352556] time: 1:47:12.695389 
[Epoch 19/50] [Batch 300/516] [D loss: 0.009484, acc: 100%] [G loss: 9.108437, adv: 0.667492, cyc: 0.357391, id: 0.354928] time: 1:48:18.995907 
[Epoch 19/50] [Batch 400/516] [D loss: 0.008197, acc: 100%] [G loss: 8.882479, adv: 0.653596, cyc: 0.348608, id: 0.342069] time: 1:49:25.286551 
[Epoch 19/50] [Batch 500/516] [D loss: 0.005966, acc: 100%] [G loss: 9.044371, adv: 0.642999, cyc: 0.356723, id: 0.354911] time: 1:50:31.574648 
[Epoch 20/50] [Batch 0/516] [D loss: 0.007108, acc: 100%] [G loss: 9.017216, adv: 0.638602, cyc: 0.355819, id: 0.346863] time: 1:50:42.179934 
[Epoch 20/50] [Batch 100/516] [D loss: 0.007745, acc: 100%] [G loss: 8.932126, adv: 0.641768, cyc: 0.351668, id: 0.346339] time: 1:51:48.482865 
[Epoch 20/50] [Batch 200/516] [D loss: 0.005606, acc: 100%] [G loss: 8.907333, adv: 0.632064, cyc: 0.351203, id: 0.353998] time: 1:52:54.769574 
[Epoch 20/50] [Batch 300/516] [D loss: 0.008012, acc: 100%] [G loss: 9.026284, adv: 0.661268, cyc: 0.354065, id: 0.352771] time: 1:54:01.060090 
[Epoch 20/50] [Batch 400/516] [D loss: 0.007407, acc: 100%] [G loss: 8.809085, adv: 0.647746, cyc: 0.345718, id: 0.338903] time: 1:55:07.346641 
[Epoch 20/50] [Batch 500/516] [D loss: 0.005417, acc: 100%] [G loss: 8.945354, adv: 0.621302, cyc: 0.354028, id: 0.353732] time: 1:56:13.632331 
[Epoch 21/50] [Batch 0/516] [D loss: 0.006420, acc: 100%] [G loss: 8.962943, adv: 0.632858, cyc: 0.353826, id: 0.345275] time: 1:56:26.589841 
[Epoch 21/50] [Batch 100/516] [D loss: 0.006948, acc: 100%] [G loss: 8.893734, adv: 0.625470, cyc: 0.351508, id: 0.346289] time: 1:57:32.880272 
[Epoch 21/50] [Batch 200/516] [D loss: 0.005139, acc: 100%] [G loss: 8.888999, adv: 0.627818, cyc: 0.350892, id: 0.350025] time: 1:58:39.167274 
[Epoch 21/50] [Batch 300/516] [D loss: 0.007050, acc: 100%] [G loss: 8.974402, adv: 0.647133, cyc: 0.352966, id: 0.352992] time: 1:59:45.448673 
[Epoch 21/50] [Batch 400/516] [D loss: 0.006314, acc: 100%] [G loss: 8.845080, adv: 0.628006, cyc: 0.349379, id: 0.343136] time: 2:00:51.727268 
[Epoch 21/50] [Batch 500/516] [D loss: 0.004994, acc: 100%] [G loss: 8.948562, adv: 0.634317, cyc: 0.352988, id: 0.351025] time: 2:01:58.014668 
[Epoch 22/50] [Batch 0/516] [D loss: 0.005871, acc: 100%] [G loss: 8.902091, adv: 0.626635, cyc: 0.351598, id: 0.341867] time: 2:02:08.619129 
[Epoch 22/50] [Batch 100/516] [D loss: 0.006389, acc: 100%] [G loss: 8.835006, adv: 0.630384, cyc: 0.348249, id: 0.343099] time: 2:03:14.901854 
[Epoch 22/50] [Batch 200/516] [D loss: 0.004754, acc: 100%] [G loss: 8.807076, adv: 0.604333, cyc: 0.349189, id: 0.350173] time: 2:04:21.175250 
[Epoch 22/50] [Batch 300/516] [D loss: 0.006133, acc: 100%] [G loss: 8.951884, adv: 0.621976, cyc: 0.354336, id: 0.353064] time: 2:05:27.453252 
[Epoch 22/50] [Batch 400/516] [D loss: 0.005837, acc: 100%] [G loss: 8.723071, adv: 0.635887, cyc: 0.342685, id: 0.339336] time: 2:06:33.727484 
[Epoch 22/50] [Batch 500/516] [D loss: 0.004596, acc: 100%] [G loss: 8.900092, adv: 0.609840, cyc: 0.353122, id: 0.351333] time: 2:07:40.000634 
[Epoch 23/50] [Batch 0/516] [D loss: 0.005507, acc: 100%] [G loss: 8.854173, adv: 0.619000, cyc: 0.349955, id: 0.343290] time: 2:07:50.604327 
[Epoch 23/50] [Batch 100/516] [D loss: 0.005707, acc: 100%] [G loss: 8.839449, adv: 0.619424, cyc: 0.349567, id: 0.343959] time: 2:08:56.873231 
[Epoch 23/50] [Batch 200/516] [D loss: 0.004489, acc: 100%] [G loss: 8.787080, adv: 0.596293, cyc: 0.349095, id: 0.348845] time: 2:10:03.146644 
[Epoch 23/50] [Batch 300/516] [D loss: 0.005661, acc: 100%] [G loss: 8.901065, adv: 0.618175, cyc: 0.352350, id: 0.349878] time: 2:11:09.422961 
[Epoch 23/50] [Batch 400/516] [D loss: 0.005361, acc: 100%] [G loss: 8.726838, adv: 0.622082, cyc: 0.344259, id: 0.338715] time: 2:12:15.695834 
[Epoch 23/50] [Batch 500/516] [D loss: 0.004246, acc: 100%] [G loss: 8.821158, adv: 0.610717, cyc: 0.349325, id: 0.346739] time: 2:13:21.969467 
[Epoch 24/50] [Batch 0/516] [D loss: 0.004954, acc: 100%] [G loss: 8.778284, adv: 0.608575, cyc: 0.347550, id: 0.335843] time: 2:13:32.571753 
[Epoch 24/50] [Batch 100/516] [D loss: 0.005421, acc: 100%] [G loss: 8.755953, adv: 0.623170, cyc: 0.345318, id: 0.338331] time: 2:14:38.839398 
[Epoch 24/50] [Batch 200/516] [D loss: 0.004075, acc: 100%] [G loss: 8.711762, adv: 0.602560, cyc: 0.345136, id: 0.340586] time: 2:15:45.106266 
[Epoch 24/50] [Batch 300/516] [D loss: 0.005705, acc: 100%] [G loss: 8.883536, adv: 0.628944, cyc: 0.350736, id: 0.343257] time: 2:16:51.373112 
[Epoch 24/50] [Batch 400/516] [D loss: 0.005260, acc: 100%] [G loss: 8.568345, adv: 0.619413, cyc: 0.336961, id: 0.334294] time: 2:17:57.644589 
[Epoch 24/50] [Batch 500/516] [D loss: 0.003913, acc: 100%] [G loss: 8.812856, adv: 0.612797, cyc: 0.348720, id: 0.346216] time: 2:19:03.910716 
[Epoch 25/50] [Batch 0/516] [D loss: 0.004785, acc: 100%] [G loss: 8.777845, adv: 0.600263, cyc: 0.348193, id: 0.340005] time: 2:19:14.514639 
[Epoch 25/50] [Batch 100/516] [D loss: 0.004816, acc: 100%] [G loss: 8.726591, adv: 0.605125, cyc: 0.345588, id: 0.339609] time: 2:20:20.777065 
[Epoch 25/50] [Batch 200/516] [D loss: 0.003898, acc: 100%] [G loss: 8.694729, adv: 0.588032, cyc: 0.345533, id: 0.345365] time: 2:21:27.045653 
[Epoch 25/50] [Batch 300/516] [D loss: 0.004803, acc: 100%] [G loss: 8.765529, adv: 0.602337, cyc: 0.347384, id: 0.346483] time: 2:22:33.312040 
[Epoch 25/50] [Batch 400/516] [D loss: 0.004630, acc: 100%] [G loss: 8.743383, adv: 0.611042, cyc: 0.346164, id: 0.340017] time: 2:23:39.572695 
[Epoch 25/50] [Batch 500/516] [D loss: 0.003633, acc: 100%] [G loss: 8.739889, adv: 0.596301, cyc: 0.346737, id: 0.346781] time: 2:24:45.837692 
[Epoch 26/50] [Batch 0/516] [D loss: 0.004341, acc: 100%] [G loss: 8.743443, adv: 0.606114, cyc: 0.346085, id: 0.335249] time: 2:24:58.363831 
[Epoch 26/50] [Batch 100/516] [D loss: 0.004646, acc: 100%] [G loss: 8.659311, adv: 0.614630, cyc: 0.341338, id: 0.338110] time: 2:26:04.625963 
[Epoch 26/50] [Batch 200/516] [D loss: 0.003516, acc: 100%] [G loss: 8.666371, adv: 0.596761, cyc: 0.343468, id: 0.340022] time: 2:27:10.894351 
[Epoch 26/50] [Batch 300/516] [D loss: 0.004621, acc: 100%] [G loss: 8.761793, adv: 0.606307, cyc: 0.346986, id: 0.343195] time: 2:28:17.151734 
[Epoch 26/50] [Batch 400/516] [D loss: 0.004581, acc: 100%] [G loss: 8.512980, adv: 0.615154, cyc: 0.334915, id: 0.328737] time: 2:29:23.409745 
[Epoch 26/50] [Batch 500/516] [D loss: 0.003426, acc: 100%] [G loss: 8.699987, adv: 0.604308, cyc: 0.344192, id: 0.342481] time: 2:30:29.660003 
[Epoch 27/50] [Batch 0/516] [D loss: 0.004097, acc: 100%] [G loss: 8.691636, adv: 0.601546, cyc: 0.344102, id: 0.332631] time: 2:30:40.260881 
[Epoch 27/50] [Batch 100/516] [D loss: 0.004326, acc: 100%] [G loss: 8.645647, adv: 0.606873, cyc: 0.341598, id: 0.334560] time: 2:31:46.531991 
[Epoch 27/50] [Batch 200/516] [D loss: 0.003297, acc: 100%] [G loss: 8.607482, adv: 0.588258, cyc: 0.341478, id: 0.339341] time: 2:32:52.794119 
[Epoch 27/50] [Batch 300/516] [D loss: 0.004424, acc: 100%] [G loss: 8.716559, adv: 0.608606, cyc: 0.344409, id: 0.342938] time: 2:33:59.048415 
[Epoch 27/50] [Batch 400/516] [D loss: 0.004377, acc: 100%] [G loss: 8.465633, adv: 0.611387, cyc: 0.332942, id: 0.327907] time: 2:35:05.301028 
[Epoch 27/50] [Batch 500/516] [D loss: 0.003261, acc: 100%] [G loss: 8.652779, adv: 0.598386, cyc: 0.342435, id: 0.341796] time: 2:36:11.552080 
[Epoch 28/50] [Batch 0/516] [D loss: 0.003884, acc: 100%] [G loss: 8.653637, adv: 0.595486, cyc: 0.342921, id: 0.332864] time: 2:36:22.152072 
[Epoch 28/50] [Batch 100/516] [D loss: 0.004028, acc: 100%] [G loss: 8.611337, adv: 0.599692, cyc: 0.340725, id: 0.333577] time: 2:37:28.398838 
[Epoch 28/50] [Batch 200/516] [D loss: 0.003102, acc: 100%] [G loss: 8.568200, adv: 0.574482, cyc: 0.340876, id: 0.338870] time: 2:38:34.652561 
[Epoch 28/50] [Batch 300/516] [D loss: 0.004015, acc: 100%] [G loss: 8.641979, adv: 0.596183, cyc: 0.341992, id: 0.343731] time: 2:39:40.903576 
[Epoch 28/50] [Batch 400/516] [D loss: 0.003872, acc: 100%] [G loss: 8.467181, adv: 0.602556, cyc: 0.333785, id: 0.329118] time: 2:40:47.149204 
[Epoch 28/50] [Batch 500/516] [D loss: 0.003028, acc: 100%] [G loss: 8.654645, adv: 0.589980, cyc: 0.343165, id: 0.345211] time: 2:41:53.402989 
[Epoch 29/50] [Batch 0/516] [D loss: 0.003772, acc: 100%] [G loss: 8.632641, adv: 0.605065, cyc: 0.340916, id: 0.332911] time: 2:42:04.002290 
[Epoch 29/50] [Batch 100/516] [D loss: 0.003752, acc: 100%] [G loss: 8.580988, adv: 0.602702, cyc: 0.338844, id: 0.333535] time: 2:43:10.241733 
[Epoch 29/50] [Batch 200/516] [D loss: 0.002977, acc: 100%] [G loss: 8.542620, adv: 0.573901, cyc: 0.339716, id: 0.338482] time: 2:44:16.486374 
[Epoch 29/50] [Batch 300/516] [D loss: 0.004106, acc: 100%] [G loss: 8.692305, adv: 0.610054, cyc: 0.343197, id: 0.341681] time: 2:45:22.729708 
[Epoch 29/50] [Batch 400/516] [D loss: 0.003948, acc: 100%] [G loss: 8.409030, adv: 0.611236, cyc: 0.330127, id: 0.327022] time: 2:46:28.979222 
[Epoch 29/50] [Batch 500/516] [D loss: 0.002899, acc: 100%] [G loss: 8.710023, adv: 0.589357, cyc: 0.345895, id: 0.346754] time: 2:47:35.219800 
[Epoch 30/50] [Batch 0/516] [D loss: 0.003693, acc: 100%] [G loss: 8.619440, adv: 0.595624, cyc: 0.341016, id: 0.336227] time: 2:47:45.819972 
[Epoch 30/50] [Batch 100/516] [D loss: 0.003364, acc: 100%] [G loss: 8.564528, adv: 0.608266, cyc: 0.337533, id: 0.334752] time: 2:48:52.060341 
[Epoch 30/50] [Batch 200/516] [D loss: 0.002843, acc: 100%] [G loss: 8.490728, adv: 0.577410, cyc: 0.336768, id: 0.340176] time: 2:49:58.305924 
[Epoch 30/50] [Batch 300/516] [D loss: 0.003667, acc: 100%] [G loss: 8.607843, adv: 0.606290, cyc: 0.339405, id: 0.341117] time: 2:51:04.544873 
[Epoch 30/50] [Batch 400/516] [D loss: 0.003888, acc: 100%] [G loss: 8.416368, adv: 0.608789, cyc: 0.330805, id: 0.326822] time: 2:52:10.787590 
[Epoch 30/50] [Batch 500/516] [D loss: 0.002828, acc: 100%] [G loss: 8.617239, adv: 0.593299, cyc: 0.341224, id: 0.342294] time: 2:53:17.024022 
[Epoch 31/50] [Batch 0/516] [D loss: 0.003400, acc: 100%] [G loss: 8.540982, adv: 0.589155, cyc: 0.338071, id: 0.330917] time: 2:53:30.147819 
[Epoch 31/50] [Batch 100/516] [D loss: 0.003533, acc: 100%] [G loss: 8.595483, adv: 0.613811, cyc: 0.338482, id: 0.334500] time: 2:54:36.393309 
[Epoch 31/50] [Batch 200/516] [D loss: 0.002737, acc: 100%] [G loss: 8.484727, adv: 0.580908, cyc: 0.336143, id: 0.338841] time: 2:55:42.629832 
[Epoch 31/50] [Batch 300/516] [D loss: 0.003562, acc: 100%] [G loss: 8.641092, adv: 0.608451, cyc: 0.340862, id: 0.341402] time: 2:56:48.865815 
[Epoch 31/50] [Batch 400/516] [D loss: 0.003447, acc: 100%] [G loss: 8.380185, adv: 0.617025, cyc: 0.328434, id: 0.324244] time: 2:57:55.102995 
[Epoch 31/50] [Batch 500/516] [D loss: 0.002611, acc: 100%] [G loss: 8.562914, adv: 0.600438, cyc: 0.337849, id: 0.340753] time: 2:59:01.334285 
[Epoch 32/50] [Batch 0/516] [D loss: 0.003248, acc: 100%] [G loss: 8.587424, adv: 0.612613, cyc: 0.338062, id: 0.330228] time: 2:59:11.930669 
[Epoch 32/50] [Batch 100/516] [D loss: 0.003016, acc: 100%] [G loss: 8.499407, adv: 0.593086, cyc: 0.335810, id: 0.334004] time: 3:00:18.164291 
[Epoch 32/50] [Batch 200/516] [D loss: 0.002564, acc: 100%] [G loss: 8.470822, adv: 0.586713, cyc: 0.334946, id: 0.338373] time: 3:01:24.409779 
[Epoch 32/50] [Batch 300/516] [D loss: 0.003245, acc: 100%] [G loss: 8.551179, adv: 0.603096, cyc: 0.337007, id: 0.340036] time: 3:02:30.648211 
[Epoch 32/50] [Batch 400/516] [D loss: 0.003473, acc: 100%] [G loss: 8.350266, adv: 0.616445, cyc: 0.327011, id: 0.322231] time: 3:03:36.893074 
[Epoch 32/50] [Batch 500/516] [D loss: 0.002455, acc: 100%] [G loss: 8.548132, adv: 0.599164, cyc: 0.337402, id: 0.338187] time: 3:04:43.125066 
[Epoch 33/50] [Batch 0/516] [D loss: 0.003174, acc: 100%] [G loss: 8.562669, adv: 0.612206, cyc: 0.336869, id: 0.328986] time: 3:04:53.723012 
[Epoch 33/50] [Batch 100/516] [D loss: 0.002961, acc: 100%] [G loss: 8.519476, adv: 0.615817, cyc: 0.334505, id: 0.333736] time: 3:05:59.962798 
[Epoch 33/50] [Batch 200/516] [D loss: 0.002477, acc: 100%] [G loss: 8.451293, adv: 0.586909, cyc: 0.333880, id: 0.340079] time: 3:07:06.196028 
[Epoch 33/50] [Batch 300/516] [D loss: 0.003060, acc: 100%] [G loss: 8.553601, adv: 0.608649, cyc: 0.336587, id: 0.339909] time: 3:08:12.429312 
[Epoch 33/50] [Batch 400/516] [D loss: 0.003318, acc: 100%] [G loss: 8.342994, adv: 0.619428, cyc: 0.326280, id: 0.324952] time: 3:09:18.660739 
[Epoch 33/50] [Batch 500/516] [D loss: 0.002382, acc: 100%] [G loss: 8.603575, adv: 0.610511, cyc: 0.338657, id: 0.343640] time: 3:10:24.892428 
[Epoch 34/50] [Batch 0/516] [D loss: 0.003068, acc: 100%] [G loss: 8.524275, adv: 0.613652, cyc: 0.334712, id: 0.330651] time: 3:10:35.488446 
[Epoch 34/50] [Batch 100/516] [D loss: 0.002779, acc: 100%] [G loss: 8.481180, adv: 0.610524, cyc: 0.333255, id: 0.332103] time: 3:11:41.733378 
[Epoch 34/50] [Batch 200/516] [D loss: 0.002400, acc: 100%] [G loss: 8.451564, adv: 0.601332, cyc: 0.332537, id: 0.338219] time: 3:12:47.967010 
[Epoch 34/50] [Batch 300/516] [D loss: 0.002893, acc: 100%] [G loss: 8.519249, adv: 0.609793, cyc: 0.334627, id: 0.341938] time: 3:13:54.204027 
[Epoch 34/50] [Batch 400/516] [D loss: 0.002858, acc: 100%] [G loss: 8.378840, adv: 0.632135, cyc: 0.326550, id: 0.328852] time: 3:15:00.430916 
[Epoch 34/50] [Batch 500/516] [D loss: 0.002276, acc: 100%] [G loss: 8.517823, adv: 0.604773, cyc: 0.335292, id: 0.339502] time: 3:16:06.661568 
[Epoch 35/50] [Batch 0/516] [D loss: 0.002882, acc: 100%] [G loss: 8.493680, adv: 0.616571, cyc: 0.333268, id: 0.326545] time: 3:16:17.262414 
[Epoch 35/50] [Batch 100/516] [D loss: 0.002582, acc: 100%] [G loss: 8.432734, adv: 0.609074, cyc: 0.331170, id: 0.329427] time: 3:17:23.504873 
[Epoch 35/50] [Batch 200/516] [D loss: 0.002289, acc: 100%] [G loss: 8.423300, adv: 0.605752, cyc: 0.330938, id: 0.332585] time: 3:18:29.741267 
[Epoch 35/50] [Batch 300/516] [D loss: 0.002733, acc: 100%] [G loss: 8.525817, adv: 0.617907, cyc: 0.334447, id: 0.338103] time: 3:19:35.972730 
[Epoch 35/50] [Batch 400/516] [D loss: 0.002744, acc: 100%] [G loss: 8.321183, adv: 0.629577, cyc: 0.324104, id: 0.324301] time: 3:20:42.204103 
[Epoch 35/50] [Batch 500/516] [D loss: 0.002154, acc: 100%] [G loss: 8.523756, adv: 0.619343, cyc: 0.334108, id: 0.338504] time: 3:21:48.440624 
[Epoch 36/50] [Batch 0/516] [D loss: 0.002866, acc: 100%] [G loss: 8.539683, adv: 0.630695, cyc: 0.333933, id: 0.328274] time: 3:22:00.581114 
[Epoch 36/50] [Batch 100/516] [D loss: 0.002540, acc: 100%] [G loss: 8.434735, adv: 0.614214, cyc: 0.330816, id: 0.327640] time: 3:23:06.819484 
[Epoch 36/50] [Batch 200/516] [D loss: 0.002295, acc: 100%] [G loss: 8.410281, adv: 0.603174, cyc: 0.330577, id: 0.333560] time: 3:24:13.052005 
[Epoch 36/50] [Batch 300/516] [D loss: 0.002624, acc: 100%] [G loss: 8.508816, adv: 0.620638, cyc: 0.333154, id: 0.339288] time: 3:25:19.287681 
[Epoch 36/50] [Batch 400/516] [D loss: 0.002645, acc: 100%] [G loss: 8.307995, adv: 0.624562, cyc: 0.324142, id: 0.320837] time: 3:26:25.524308 
[Epoch 36/50] [Batch 500/516] [D loss: 0.002073, acc: 100%] [G loss: 8.554762, adv: 0.626272, cyc: 0.334949, id: 0.338517] time: 3:27:31.765441 
[Epoch 37/50] [Batch 0/516] [D loss: 0.002891, acc: 100%] [G loss: 8.568295, adv: 0.637716, cyc: 0.334568, id: 0.328221] time: 3:27:42.359943 
[Epoch 37/50] [Batch 100/516] [D loss: 0.002230, acc: 100%] [G loss: 8.481458, adv: 0.626064, cyc: 0.331698, id: 0.331952] time: 3:28:48.584817 
[Epoch 37/50] [Batch 200/516] [D loss: 0.002168, acc: 100%] [G loss: 8.403737, adv: 0.609256, cyc: 0.329515, id: 0.335993] time: 3:29:54.814776 
[Epoch 37/50] [Batch 300/516] [D loss: 0.002603, acc: 100%] [G loss: 8.500614, adv: 0.626963, cyc: 0.332388, id: 0.335563] time: 3:31:01.040895 
[Epoch 37/50] [Batch 400/516] [D loss: 0.002719, acc: 100%] [G loss: 8.276111, adv: 0.636339, cyc: 0.321703, id: 0.315839] time: 3:32:07.274079 
[Epoch 37/50] [Batch 500/516] [D loss: 0.002052, acc: 100%] [G loss: 8.466286, adv: 0.627581, cyc: 0.330696, id: 0.333850] time: 3:33:13.509639 
[Epoch 38/50] [Batch 0/516] [D loss: 0.002632, acc: 100%] [G loss: 8.474194, adv: 0.628613, cyc: 0.331176, id: 0.323403] time: 3:33:24.105145 
[Epoch 38/50] [Batch 100/516] [D loss: 0.002437, acc: 100%] [G loss: 8.402645, adv: 0.623558, cyc: 0.328440, id: 0.325283] time: 3:34:30.338107 
[Epoch 38/50] [Batch 200/516] [D loss: 0.002111, acc: 100%] [G loss: 8.357913, adv: 0.614320, cyc: 0.326946, id: 0.332003] time: 3:35:36.564777 
[Epoch 38/50] [Batch 300/516] [D loss: 0.002485, acc: 100%] [G loss: 8.488998, adv: 0.624381, cyc: 0.332070, id: 0.335735] time: 3:36:42.795143 
[Epoch 38/50] [Batch 400/516] [D loss: 0.002743, acc: 100%] [G loss: 8.253717, adv: 0.642024, cyc: 0.319887, id: 0.317345] time: 3:37:49.022251 
[Epoch 38/50] [Batch 500/516] [D loss: 0.001925, acc: 100%] [G loss: 8.476782, adv: 0.635599, cyc: 0.330548, id: 0.331722] time: 3:38:55.245244 
[Epoch 39/50] [Batch 0/516] [D loss: 0.002552, acc: 100%] [G loss: 8.480115, adv: 0.633761, cyc: 0.331006, id: 0.324087] time: 3:39:05.842165 
[Epoch 39/50] [Batch 100/516] [D loss: 0.002222, acc: 100%] [G loss: 8.378348, adv: 0.622160, cyc: 0.327242, id: 0.327218] time: 3:40:12.066996 
[Epoch 39/50] [Batch 200/516] [D loss: 0.002070, acc: 100%] [G loss: 8.379313, adv: 0.618877, cyc: 0.327566, id: 0.331492] time: 3:41:18.297539 
[Epoch 39/50] [Batch 300/516] [D loss: 0.002417, acc: 100%] [G loss: 8.488239, adv: 0.633270, cyc: 0.331283, id: 0.333754] time: 3:42:24.528772 
[Epoch 39/50] [Batch 400/516] [D loss: 0.002316, acc: 100%] [G loss: 8.340755, adv: 0.639661, cyc: 0.324298, id: 0.319616] time: 3:43:30.757904 
[Epoch 39/50] [Batch 500/516] [D loss: 0.001870, acc: 100%] [G loss: 8.463976, adv: 0.619459, cyc: 0.331402, id: 0.333473] time: 3:44:36.982920 
[Epoch 40/50] [Batch 0/516] [D loss: 0.002500, acc: 100%] [G loss: 8.435720, adv: 0.640487, cyc: 0.328053, id: 0.322782] time: 3:44:47.579501 
[Epoch 40/50] [Batch 100/516] [D loss: 0.002292, acc: 100%] [G loss: 8.399492, adv: 0.629765, cyc: 0.327645, id: 0.325764] time: 3:45:53.807343 
[Epoch 40/50] [Batch 200/516] [D loss: 0.002002, acc: 100%] [G loss: 8.372170, adv: 0.614184, cyc: 0.327759, id: 0.330754] time: 3:47:00.041463 
[Epoch 40/50] [Batch 300/516] [D loss: 0.002247, acc: 100%] [G loss: 8.452042, adv: 0.618214, cyc: 0.330566, id: 0.339776] time: 3:48:06.276130 
[Epoch 40/50] [Batch 400/516] [D loss: 0.002202, acc: 100%] [G loss: 8.236999, adv: 0.637826, cyc: 0.319438, id: 0.317291] time: 3:49:12.504371 
[Epoch 40/50] [Batch 500/516] [D loss: 0.001853, acc: 100%] [G loss: 8.450112, adv: 0.632921, cyc: 0.329480, id: 0.332371] time: 3:50:18.733095 
[Epoch 41/50] [Batch 0/516] [D loss: 0.002393, acc: 100%] [G loss: 8.421753, adv: 0.633457, cyc: 0.328192, id: 0.320895] time: 3:50:30.685442 
[Epoch 41/50] [Batch 100/516] [D loss: 0.002246, acc: 100%] [G loss: 8.359444, adv: 0.625682, cyc: 0.326037, id: 0.325647] time: 3:51:36.918750 
[Epoch 41/50] [Batch 200/516] [D loss: 0.001984, acc: 100%] [G loss: 8.305875, adv: 0.618770, cyc: 0.324239, id: 0.325708] time: 3:52:43.155684 
[Epoch 41/50] [Batch 300/516] [D loss: 0.002196, acc: 100%] [G loss: 8.449413, adv: 0.624242, cyc: 0.330189, id: 0.333505] time: 3:53:49.390891 
[Epoch 41/50] [Batch 400/516] [D loss: 0.002298, acc: 100%] [G loss: 8.193174, adv: 0.644812, cyc: 0.317023, id: 0.311780] time: 3:54:55.618124 
[Epoch 41/50] [Batch 500/516] [D loss: 0.001765, acc: 100%] [G loss: 8.398817, adv: 0.624744, cyc: 0.327825, id: 0.330172] time: 3:56:01.846320 
[Epoch 42/50] [Batch 0/516] [D loss: 0.002317, acc: 100%] [G loss: 8.447181, adv: 0.643211, cyc: 0.328480, id: 0.322760] time: 3:56:12.442582 
[Epoch 42/50] [Batch 100/516] [D loss: 0.002094, acc: 100%] [G loss: 8.340447, adv: 0.621337, cyc: 0.325539, id: 0.325811] time: 3:57:18.670731 
[Epoch 42/50] [Batch 200/516] [D loss: 0.001880, acc: 100%] [G loss: 8.304405, adv: 0.626574, cyc: 0.323360, id: 0.327106] time: 3:58:24.900947 
[Epoch 42/50] [Batch 300/516] [D loss: 0.002138, acc: 100%] [G loss: 8.435545, adv: 0.626238, cyc: 0.329417, id: 0.332056] time: 3:59:31.129958 
[Epoch 42/50] [Batch 400/516] [D loss: 0.002400, acc: 100%] [G loss: 8.170306, adv: 0.643994, cyc: 0.315844, id: 0.314614] time: 4:00:37.358637 
[Epoch 42/50] [Batch 500/516] [D loss: 0.001791, acc: 100%] [G loss: 8.404951, adv: 0.633537, cyc: 0.327418, id: 0.328455] time: 4:01:43.594988 
[Epoch 43/50] [Batch 0/516] [D loss: 0.002294, acc: 100%] [G loss: 8.408687, adv: 0.645984, cyc: 0.326236, id: 0.322707] time: 4:01:54.192423 
[Epoch 43/50] [Batch 100/516] [D loss: 0.002097, acc: 100%] [G loss: 8.298682, adv: 0.618183, cyc: 0.323927, id: 0.322157] time: 4:03:00.425542 
[Epoch 43/50] [Batch 200/516] [D loss: 0.001891, acc: 100%] [G loss: 8.314874, adv: 0.632585, cyc: 0.323173, id: 0.328120] time: 4:04:06.654333 
[Epoch 43/50] [Batch 300/516] [D loss: 0.002143, acc: 100%] [G loss: 8.420006, adv: 0.633769, cyc: 0.327841, id: 0.334194] time: 4:05:12.875690 
[Epoch 43/50] [Batch 400/516] [D loss: 0.002034, acc: 100%] [G loss: 8.192761, adv: 0.634840, cyc: 0.317760, id: 0.313905] time: 4:06:19.100061 
[Epoch 43/50] [Batch 500/516] [D loss: 0.001717, acc: 100%] [G loss: 8.365191, adv: 0.626437, cyc: 0.326188, id: 0.327758] time: 4:07:25.335787 
[Epoch 44/50] [Batch 0/516] [D loss: 0.002215, acc: 100%] [G loss: 8.379122, adv: 0.645182, cyc: 0.325025, id: 0.319887] time: 4:07:35.929935 
[Epoch 44/50] [Batch 100/516] [D loss: 0.002086, acc: 100%] [G loss: 8.331991, adv: 0.631062, cyc: 0.324263, id: 0.323602] time: 4:08:42.156519 
[Epoch 44/50] [Batch 200/516] [D loss: 0.001775, acc: 100%] [G loss: 8.281538, adv: 0.622002, cyc: 0.322551, id: 0.326701] time: 4:09:48.383010 
[Epoch 44/50] [Batch 300/516] [D loss: 0.002073, acc: 100%] [G loss: 8.365336, adv: 0.621010, cyc: 0.326452, id: 0.332033] time: 4:10:54.610055 
[Epoch 44/50] [Batch 400/516] [D loss: 0.002288, acc: 100%] [G loss: 8.159312, adv: 0.642294, cyc: 0.315572, id: 0.311214] time: 4:12:00.847944 
[Epoch 44/50] [Batch 500/516] [D loss: 0.001717, acc: 100%] [G loss: 8.371369, adv: 0.631665, cyc: 0.325903, id: 0.328336] time: 4:13:07.078921 
[Epoch 45/50] [Batch 0/516] [D loss: 0.002217, acc: 100%] [G loss: 8.367950, adv: 0.640848, cyc: 0.324767, id: 0.321540] time: 4:13:17.674452 
[Epoch 45/50] [Batch 100/516] [D loss: 0.002182, acc: 100%] [G loss: 8.292987, adv: 0.635721, cyc: 0.322145, id: 0.320105] time: 4:14:23.902923 
[Epoch 45/50] [Batch 200/516] [D loss: 0.001707, acc: 100%] [G loss: 8.265881, adv: 0.619762, cyc: 0.321994, id: 0.328649] time: 4:15:30.132399 
[Epoch 45/50] [Batch 300/516] [D loss: 0.001965, acc: 100%] [G loss: 8.373251, adv: 0.621174, cyc: 0.326791, id: 0.332196] time: 4:16:36.363888 
[Epoch 45/50] [Batch 400/516] [D loss: 0.002329, acc: 100%] [G loss: 8.139633, adv: 0.647965, cyc: 0.314010, id: 0.312852] time: 4:17:42.599345 
[Epoch 45/50] [Batch 500/516] [D loss: 0.001598, acc: 100%] [G loss: 8.333375, adv: 0.627889, cyc: 0.324430, id: 0.326681] time: 4:18:48.825430 
[Epoch 46/50] [Batch 0/516] [D loss: 0.002140, acc: 100%] [G loss: 8.358030, adv: 0.643962, cyc: 0.324133, id: 0.318854] time: 4:19:01.547256 
[Epoch 46/50] [Batch 100/516] [D loss: 0.001928, acc: 100%] [G loss: 8.264733, adv: 0.635584, cyc: 0.320796, id: 0.318835] time: 4:20:07.774664 
[Epoch 46/50] [Batch 200/516] [D loss: 0.001652, acc: 100%] [G loss: 8.255688, adv: 0.621590, cyc: 0.321277, id: 0.327636] time: 4:21:14.011031 
[Epoch 46/50] [Batch 300/516] [D loss: 0.001951, acc: 100%] [G loss: 8.364908, adv: 0.630533, cyc: 0.325406, id: 0.333436] time: 4:22:20.247397 
[Epoch 46/50] [Batch 400/516] [D loss: 0.001976, acc: 100%] [G loss: 8.125545, adv: 0.632505, cyc: 0.314727, id: 0.310727] time: 4:23:26.482626 
[Epoch 46/50] [Batch 500/516] [D loss: 0.001623, acc: 100%] [G loss: 8.362174, adv: 0.641774, cyc: 0.324479, id: 0.329199] time: 4:24:32.720735 
[Epoch 47/50] [Batch 0/516] [D loss: 0.002115, acc: 100%] [G loss: 8.359318, adv: 0.644993, cyc: 0.324118, id: 0.318032] time: 4:24:43.322608 
[Epoch 47/50] [Batch 100/516] [D loss: 0.001924, acc: 100%] [G loss: 8.286404, adv: 0.642198, cyc: 0.321032, id: 0.322855] time: 4:25:49.556937 
[Epoch 47/50] [Batch 200/516] [D loss: 0.001606, acc: 100%] [G loss: 8.255957, adv: 0.624985, cyc: 0.320896, id: 0.327534] time: 4:26:55.799205 
[Epoch 47/50] [Batch 300/516] [D loss: 0.001967, acc: 100%] [G loss: 8.373905, adv: 0.641828, cyc: 0.324901, id: 0.330231] time: 4:28:02.032908 
[Epoch 47/50] [Batch 400/516] [D loss: 0.002532, acc: 100%] [G loss: 8.093745, adv: 0.653126, cyc: 0.311426, id: 0.307528] time: 4:29:08.266149 
[Epoch 47/50] [Batch 500/516] [D loss: 0.001523, acc: 100%] [G loss: 8.296350, adv: 0.631868, cyc: 0.322326, id: 0.325073] time: 4:30:14.494027 
[Epoch 48/50] [Batch 0/516] [D loss: 0.002028, acc: 100%] [G loss: 8.374857, adv: 0.644782, cyc: 0.324604, id: 0.325403] time: 4:30:25.091533 
[Epoch 48/50] [Batch 100/516] [D loss: 0.001851, acc: 100%] [G loss: 8.237404, adv: 0.644843, cyc: 0.318404, id: 0.319512] time: 4:31:31.328305 
[Epoch 48/50] [Batch 200/516] [D loss: 0.001641, acc: 100%] [G loss: 8.244727, adv: 0.634853, cyc: 0.319582, id: 0.324912] time: 4:32:37.562656 
[Epoch 48/50] [Batch 300/516] [D loss: 0.001940, acc: 100%] [G loss: 8.351815, adv: 0.648839, cyc: 0.323257, id: 0.328131] time: 4:33:43.792855 
[Epoch 48/50] [Batch 400/516] [D loss: 0.002203, acc: 100%] [G loss: 8.087580, adv: 0.650012, cyc: 0.311524, id: 0.304715] time: 4:34:50.026190 
[Epoch 48/50] [Batch 500/516] [D loss: 0.001511, acc: 100%] [G loss: 8.311215, adv: 0.655510, cyc: 0.320698, id: 0.322047] time: 4:35:56.254309 
[Epoch 49/50] [Batch 0/516] [D loss: 0.002018, acc: 100%] [G loss: 8.332786, adv: 0.654404, cyc: 0.321817, id: 0.316923] time: 4:36:06.850330 
[Epoch 49/50] [Batch 100/516] [D loss: 0.001575, acc: 100%] [G loss: 8.227016, adv: 0.630863, cyc: 0.319171, id: 0.321698] time: 4:37:13.079741 
[Epoch 49/50] [Batch 200/516] [D loss: 0.001644, acc: 100%] [G loss: 8.237707, adv: 0.638258, cyc: 0.318768, id: 0.327745] time: 4:38:19.309004 
[Epoch 49/50] [Batch 300/516] [D loss: 0.001778, acc: 100%] [G loss: 8.334180, adv: 0.628574, cyc: 0.323913, id: 0.330329] time: 4:39:25.536284 
[Epoch 49/50] [Batch 400/516] [D loss: 0.001650, acc: 100%] [G loss: 8.145721, adv: 0.644823, cyc: 0.314327, id: 0.311986] time: 4:40:31.766215 
[Epoch 49/50] [Batch 500/516] [D loss: 0.001466, acc: 100%] [G loss: 8.295580, adv: 0.640572, cyc: 0.321197, id: 0.327997] time: 4:41:38.000580 
[Epoch 50/50] [Batch 0/516] [D loss: 0.001968, acc: 100%] [G loss: 8.321337, adv: 0.645686, cyc: 0.322365, id: 0.316239] time: 4:41:48.597030 
[Epoch 50/50] [Batch 100/516] [D loss: 0.001826, acc: 100%] [G loss: 8.203861, adv: 0.632151, cyc: 0.318006, id: 0.320648] time: 4:42:54.814950 
[Epoch 50/50] [Batch 200/516] [D loss: 0.001523, acc: 100%] [G loss: 8.257097, adv: 0.639867, cyc: 0.319345, id: 0.330083] time: 4:44:01.035717 
[Epoch 50/50] [Batch 300/516] [D loss: 0.001749, acc: 100%] [G loss: 8.314230, adv: 0.648707, cyc: 0.321596, id: 0.321655] time: 4:45:07.256585 
[Epoch 50/50] [Batch 400/516] [D loss: 0.002634, acc: 100%] [G loss: 8.107888, adv: 0.664571, cyc: 0.311182, id: 0.302172] time: 4:46:13.484591 
[Epoch 50/50] [Batch 500/516] [D loss: 0.001441, acc: 100%] [G loss: 8.353864, adv: 0.641018, cyc: 0.323641, id: 0.335701] time: 4:47:19.712694 
Train Finished.
