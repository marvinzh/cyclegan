_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_6 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_7 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_A_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 1, 600, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 600, 64)        256       
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 1, 600, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1, 600, 128)       24704     
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 1, 600, 128)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 76800)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               39322112  
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
D_B_Out (Dense)              (None, 1)                 513       
=================================================================
Total params: 79,220,482
Trainable params: 39,610,241
Non-trainable params: 39,610,241
_________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
ivec_b (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
ivec_a (InputLayer)             (None, 1, 600, 1)    0                                            
__________________________________________________________________________________________________
model_4 (Model)                 (None, 1, 600, 1)    653345      ivec_b[0][0]                     
                                                                 model_3[1][0]                    
                                                                 ivec_a[0][0]                     
__________________________________________________________________________________________________
model_3 (Model)                 (None, 1, 600, 1)    653345      ivec_a[0][0]                     
                                                                 model_4[1][0]                    
                                                                 ivec_b[0][0]                     
__________________________________________________________________________________________________
model_2 (Model)                 (None, 1)            39610241    model_4[1][0]                    
__________________________________________________________________________________________________
model_1 (Model)                 (None, 1)            39610241    model_3[1][0]                    
==================================================================================================
Total params: 80,527,172
Trainable params: 1,306,690
Non-trainable params: 79,220,482
__________________________________________________________________________________________________
Start CycleGAN training.
[Epoch 1/50] [Batch 0/516] [D loss: 127.323593, acc:   0%] [G loss: 19.681978, adv: -0.320302, cyc: 0.924864, id: 0.951974] time: 0:01:58.899033 
[Epoch 1/50] [Batch 100/516] [D loss: 0.004141, acc:   0%] [G loss: 9.533850, adv: -0.002602, cyc: 0.441556, id: 0.391019] time: 0:03:46.230692 
[Epoch 1/50] [Batch 200/516] [D loss: 0.222194, acc:   0%] [G loss: 7.265241, adv: -0.542262, cyc: 0.385753, id: 0.346288] time: 0:05:33.136050 
[Epoch 1/50] [Batch 300/516] [D loss: 0.025628, acc:   0%] [G loss: 7.677273, adv: 0.045229, cyc: 0.350189, id: 0.318796] time: 0:07:19.736086 
[Epoch 1/50] [Batch 400/516] [D loss: 0.016540, acc:   0%] [G loss: 7.230982, adv: 0.005354, cyc: 0.333115, id: 0.316334] time: 0:09:06.594934 
[Epoch 1/50] [Batch 500/516] [D loss: 1.181120, acc:   0%] [G loss: 6.850575, adv: -0.026188, cyc: 0.317859, id: 0.316222] time: 0:10:53.360489 
[Epoch 2/50] [Batch 0/516] [D loss: 0.001595, acc:   0%] [G loss: 6.749576, adv: 0.001222, cyc: 0.310677, id: 0.304496] time: 0:11:10.444649 
[Epoch 2/50] [Batch 100/516] [D loss: 0.001431, acc:   0%] [G loss: 6.542769, adv: -0.002615, cyc: 0.301468, id: 0.293789] time: 0:12:57.196012 
[Epoch 2/50] [Batch 200/516] [D loss: 0.278698, acc:  25%] [G loss: 6.539786, adv: 0.011794, cyc: 0.300108, id: 0.287307] time: 0:14:43.827698 
[Epoch 2/50] [Batch 300/516] [D loss: 0.001872, acc:   0%] [G loss: 6.425680, adv: -0.003784, cyc: 0.296427, id: 0.281308] time: 0:16:30.426666 
[Epoch 2/50] [Batch 400/516] [D loss: 0.006355, acc:   0%] [G loss: 6.172437, adv: 0.010734, cyc: 0.283022, id: 0.279179] time: 0:18:17.136916 
[Epoch 2/50] [Batch 500/516] [D loss: 0.001273, acc:   0%] [G loss: 6.050976, adv: -0.002761, cyc: 0.278341, id: 0.288384] time: 0:20:03.668788 
[Epoch 3/50] [Batch 0/516] [D loss: 0.027116, acc:   0%] [G loss: 6.174621, adv: -0.005257, cyc: 0.284708, id: 0.286793] time: 0:20:20.778415 
[Epoch 3/50] [Batch 100/516] [D loss: 0.002170, acc:   0%] [G loss: 5.891150, adv: -0.002485, cyc: 0.270784, id: 0.277638] time: 0:22:07.398879 
[Epoch 3/50] [Batch 200/516] [D loss: 0.006770, acc:   0%] [G loss: 5.886567, adv: 0.001133, cyc: 0.270257, id: 0.270516] time: 0:23:54.073317 
[Epoch 3/50] [Batch 300/516] [D loss: 0.013647, acc:   0%] [G loss: 5.927982, adv: 0.020823, cyc: 0.270630, id: 0.266102] time: 0:25:40.707958 
[Epoch 3/50] [Batch 400/516] [D loss: 0.001512, acc:   0%] [G loss: 5.779075, adv: -0.002099, cyc: 0.266190, id: 0.261299] time: 0:27:27.422485 
[Epoch 3/50] [Batch 500/516] [D loss: 0.003326, acc:   0%] [G loss: 5.729282, adv: -0.001060, cyc: 0.262935, id: 0.280166] time: 0:29:14.124014 
[Epoch 4/50] [Batch 0/516] [D loss: 0.373653, acc:   2%] [G loss: 5.648616, adv: -0.000767, cyc: 0.259512, id: 0.268793] time: 0:29:31.167800 
[Epoch 4/50] [Batch 100/516] [D loss: 0.043497, acc:   0%] [G loss: 5.460295, adv: -0.084193, cyc: 0.258417, id: 0.265896] time: 0:31:17.984110 
[Epoch 4/50] [Batch 200/516] [D loss: 0.002445, acc:   0%] [G loss: 5.666200, adv: -0.002405, cyc: 0.260195, id: 0.265375] time: 0:33:05.086442 
[Epoch 4/50] [Batch 300/516] [D loss: 0.001977, acc:   0%] [G loss: 5.589075, adv: -0.000148, cyc: 0.256773, id: 0.254827] time: 0:34:51.783779 
[Epoch 4/50] [Batch 400/516] [D loss: 0.295731, acc:  25%] [G loss: 5.588020, adv: -0.007148, cyc: 0.257747, id: 0.254514] time: 0:36:38.498740 
[Epoch 4/50] [Batch 500/516] [D loss: 0.004417, acc:   0%] [G loss: 5.489722, adv: 0.007703, cyc: 0.250942, id: 0.268880] time: 0:38:25.202477 
[Epoch 5/50] [Batch 0/516] [D loss: 0.002089, acc:   0%] [G loss: 5.440026, adv: -0.000239, cyc: 0.249998, id: 0.257048] time: 0:38:42.221433 
[Epoch 5/50] [Batch 100/516] [D loss: 0.001425, acc:   0%] [G loss: 5.519150, adv: -0.002419, cyc: 0.253733, id: 0.259186] time: 0:40:28.978626 
[Epoch 5/50] [Batch 200/516] [D loss: 0.001291, acc:   0%] [G loss: 5.455647, adv: -0.002927, cyc: 0.250848, id: 0.252417] time: 0:42:15.771503 
[Epoch 5/50] [Batch 300/516] [D loss: 0.001853, acc:   0%] [G loss: 5.343297, adv: -0.002384, cyc: 0.245361, id: 0.245840] time: 0:44:02.413695 
[Epoch 5/50] [Batch 400/516] [D loss: 0.002438, acc:   0%] [G loss: 5.357754, adv: -0.000392, cyc: 0.246337, id: 0.245646] time: 0:45:49.349602 
[Epoch 5/50] [Batch 500/516] [D loss: 0.001345, acc:   0%] [G loss: 5.340732, adv: -0.002023, cyc: 0.245277, id: 0.259629] time: 0:47:35.887258 
[Epoch 6/50] [Batch 0/516] [D loss: 0.004056, acc:   0%] [G loss: 5.297895, adv: 0.002241, cyc: 0.243172, id: 0.250252] time: 0:47:56.760537 
[Epoch 6/50] [Batch 100/516] [D loss: 0.002470, acc:   0%] [G loss: 5.260351, adv: -0.006732, cyc: 0.241937, id: 0.249004] time: 0:49:43.485745 
[Epoch 6/50] [Batch 200/516] [D loss: 0.001340, acc:   0%] [G loss: 5.255323, adv: -0.002316, cyc: 0.241112, id: 0.246501] time: 0:51:30.147164 
[Epoch 6/50] [Batch 300/516] [D loss: 0.474191, acc:  50%] [G loss: 5.429878, adv: 0.057061, cyc: 0.244017, id: 0.242081] time: 0:53:16.837658 
[Epoch 6/50] [Batch 400/516] [D loss: 0.059736, acc:   0%] [G loss: 5.300644, adv: 0.026129, cyc: 0.241239, id: 0.240673] time: 0:55:03.652153 
[Epoch 6/50] [Batch 500/516] [D loss: 0.004039, acc:   0%] [G loss: 5.249372, adv: 0.004020, cyc: 0.240347, id: 0.255387] time: 0:56:50.326121 
[Epoch 7/50] [Batch 0/516] [D loss: 0.003442, acc:   0%] [G loss: 5.168457, adv: -0.000902, cyc: 0.236756, id: 0.252816] time: 0:57:07.396326 
[Epoch 7/50] [Batch 100/516] [D loss: 0.494717, acc:   0%] [G loss: 5.244283, adv: 0.026897, cyc: 0.238624, id: 0.237986] time: 0:58:54.154658 
[Epoch 7/50] [Batch 200/516] [D loss: 0.001443, acc:   0%] [G loss: 5.226355, adv: -0.001979, cyc: 0.240293, id: 0.238729] time: 1:00:40.969957 
[Epoch 7/50] [Batch 300/516] [D loss: 0.001376, acc:   0%] [G loss: 5.109429, adv: 0.001933, cyc: 0.234589, id: 0.232265] time: 1:02:27.568832 
[Epoch 7/50] [Batch 400/516] [D loss: 0.110817, acc:  25%] [G loss: 5.055600, adv: -0.023543, cyc: 0.234633, id: 0.233062] time: 1:04:14.421356 
[Epoch 7/50] [Batch 500/516] [D loss: 0.003145, acc:   0%] [G loss: 5.109403, adv: -0.012365, cyc: 0.235356, id: 0.250883] time: 1:06:01.097969 
[Epoch 8/50] [Batch 0/516] [D loss: 0.002719, acc:   0%] [G loss: 5.082685, adv: 0.000987, cyc: 0.233748, id: 0.235491] time: 1:06:18.171148 
[Epoch 8/50] [Batch 100/516] [D loss: 0.294432, acc:  25%] [G loss: 5.043749, adv: -0.004423, cyc: 0.231565, id: 0.240940] time: 1:08:04.741305 
[Epoch 8/50] [Batch 200/516] [D loss: 0.015068, acc:   0%] [G loss: 5.117983, adv: -0.002014, cyc: 0.235678, id: 0.230448] time: 1:09:51.348634 
[Epoch 8/50] [Batch 300/516] [D loss: 0.001336, acc:   0%] [G loss: 5.048619, adv: -0.001878, cyc: 0.232107, id: 0.228648] time: 1:11:37.782132 
[Epoch 8/50] [Batch 400/516] [D loss: 0.085540, acc:   0%] [G loss: 5.207145, adv: 0.078264, cyc: 0.232302, id: 0.229284] time: 1:13:24.395730 
[Epoch 8/50] [Batch 500/516] [D loss: 0.001984, acc:   0%] [G loss: 5.153917, adv: -0.000098, cyc: 0.236930, id: 0.243532] time: 1:15:11.120131 
[Epoch 9/50] [Batch 0/516] [D loss: 0.025495, acc:   0%] [G loss: 5.762429, adv: 0.354610, cyc: 0.231511, id: 0.242913] time: 1:15:28.120532 
[Epoch 9/50] [Batch 100/516] [D loss: 0.001926, acc:   0%] [G loss: 5.060956, adv: -0.000362, cyc: 0.231623, id: 0.246469] time: 1:17:14.506735 
[Epoch 9/50] [Batch 200/516] [D loss: 0.002249, acc:   0%] [G loss: 5.108181, adv: -0.001175, cyc: 0.234575, id: 0.234183] time: 1:19:01.021114 
[Epoch 9/50] [Batch 300/516] [D loss: 0.001855, acc:   0%] [G loss: 4.952110, adv: -0.002770, cyc: 0.227836, id: 0.223490] time: 1:20:47.436903 
[Epoch 9/50] [Batch 400/516] [D loss: 0.038628, acc:   0%] [G loss: 4.985530, adv: -0.001753, cyc: 0.228458, id: 0.238531] time: 1:22:34.051311 
[Epoch 9/50] [Batch 500/516] [D loss: 0.001474, acc:   0%] [G loss: 5.042585, adv: -0.003528, cyc: 0.231966, id: 0.241066] time: 1:24:20.705304 
[Epoch 10/50] [Batch 0/516] [D loss: 0.001445, acc:   0%] [G loss: 4.982865, adv: -0.002614, cyc: 0.229302, id: 0.231898] time: 1:24:37.821312 
[Epoch 10/50] [Batch 100/516] [D loss: 0.002359, acc:   0%] [G loss: 4.903729, adv: -0.000099, cyc: 0.225049, id: 0.230515] time: 1:26:24.687042 
[Epoch 10/50] [Batch 200/516] [D loss: 0.003965, acc:   0%] [G loss: 5.034308, adv: 0.022382, cyc: 0.229098, id: 0.229632] time: 1:28:11.331811 
[Epoch 10/50] [Batch 300/516] [D loss: 0.001357, acc:   0%] [G loss: 4.867406, adv: -0.002992, cyc: 0.223681, id: 0.222603] time: 1:29:57.889832 
[Epoch 10/50] [Batch 400/516] [D loss: 0.018062, acc:   0%] [G loss: 4.897187, adv: -0.037922, cyc: 0.228739, id: 0.225598] time: 1:31:44.529037 
[Epoch 10/50] [Batch 500/516] [D loss: 0.001206, acc:   0%] [G loss: 4.899634, adv: -0.002753, cyc: 0.225228, id: 0.236221] time: 1:33:31.281490 
[Epoch 11/50] [Batch 0/516] [D loss: 0.014387, acc:   0%] [G loss: 5.045533, adv: 0.065722, cyc: 0.225462, id: 0.234264] time: 1:33:49.538926 
[Epoch 11/50] [Batch 100/516] [D loss: 0.001250, acc:   0%] [G loss: 4.861926, adv: -0.002491, cyc: 0.222964, id: 0.232358] time: 1:35:36.037514 
[Epoch 11/50] [Batch 200/516] [D loss: 0.009178, acc:   0%] [G loss: 4.924621, adv: -0.001585, cyc: 0.226043, id: 0.227770] time: 1:37:22.583899 
[Epoch 11/50] [Batch 300/516] [D loss: 0.001912, acc:   0%] [G loss: 4.872443, adv: 0.000170, cyc: 0.223176, id: 0.227325] time: 1:39:09.228572 
[Epoch 11/50] [Batch 400/516] [D loss: 0.001824, acc:   0%] [G loss: 4.890309, adv: -0.006702, cyc: 0.225076, id: 0.228504] time: 1:40:55.843164 
[Epoch 11/50] [Batch 500/516] [D loss: 0.002741, acc:   0%] [G loss: 4.965081, adv: 0.000788, cyc: 0.228197, id: 0.234753] time: 1:42:42.508152 
[Epoch 12/50] [Batch 0/516] [D loss: 0.003674, acc:   0%] [G loss: 4.843560, adv: 0.002172, cyc: 0.221975, id: 0.231660] time: 1:42:59.557871 
[Epoch 12/50] [Batch 100/516] [D loss: 0.003943, acc:   0%] [G loss: 4.914780, adv: 0.000664, cyc: 0.225764, id: 0.227633] time: 1:44:46.119875 
[Epoch 12/50] [Batch 200/516] [D loss: 0.001206, acc:   0%] [G loss: 4.861229, adv: -0.002411, cyc: 0.223496, id: 0.223300] time: 1:46:32.656644 
[Epoch 12/50] [Batch 300/516] [D loss: 0.002433, acc:   0%] [G loss: 4.788234, adv: -0.002715, cyc: 0.220108, id: 0.217790] time: 1:48:19.403385 
[Epoch 12/50] [Batch 400/516] [D loss: 0.107410, acc:   0%] [G loss: 4.828318, adv: -0.013985, cyc: 0.223221, id: 0.222777] time: 1:50:06.128653 
[Epoch 12/50] [Batch 500/516] [D loss: 0.001342, acc:   0%] [G loss: 4.859109, adv: -0.002032, cyc: 0.223140, id: 0.234864] time: 1:51:52.790214 
[Epoch 13/50] [Batch 0/516] [D loss: 0.001235, acc:   0%] [G loss: 4.813893, adv: -0.002261, cyc: 0.220995, id: 0.229675] time: 1:52:09.806319 
[Epoch 13/50] [Batch 100/516] [D loss: 0.001621, acc:   0%] [G loss: 4.787671, adv: -0.004215, cyc: 0.220190, id: 0.224673] time: 1:53:56.512638 
[Epoch 13/50] [Batch 200/516] [D loss: 0.002575, acc:   0%] [G loss: 4.895417, adv: -0.000372, cyc: 0.224388, id: 0.228295] time: 1:55:43.123690 
[Epoch 13/50] [Batch 300/516] [D loss: 0.007167, acc:   0%] [G loss: 4.792405, adv: 0.001181, cyc: 0.219932, id: 0.217885] time: 1:57:29.757649 
[Epoch 13/50] [Batch 400/516] [D loss: 0.001863, acc:   0%] [G loss: 4.885365, adv: -0.000813, cyc: 0.224870, id: 0.221238] time: 1:59:16.379378 
[Epoch 13/50] [Batch 500/516] [D loss: 0.003245, acc:   0%] [G loss: 4.959210, adv: 0.002168, cyc: 0.227824, id: 0.232221] time: 2:01:03.268458 
[Epoch 14/50] [Batch 0/516] [D loss: 0.003093, acc:   0%] [G loss: 4.738645, adv: -0.000419, cyc: 0.217621, id: 0.224522] time: 2:01:20.300932 
[Epoch 14/50] [Batch 100/516] [D loss: 0.041979, acc:   0%] [G loss: 4.830791, adv: -0.001740, cyc: 0.221427, id: 0.231607] time: 2:03:06.882425 
[Epoch 14/50] [Batch 200/516] [D loss: 0.009791, acc:   0%] [G loss: 4.848100, adv: 0.013357, cyc: 0.221139, id: 0.223296] time: 2:04:53.476495 
[Epoch 14/50] [Batch 300/516] [D loss: 0.001209, acc:   0%] [G loss: 4.779245, adv: -0.002964, cyc: 0.219514, id: 0.219438] time: 2:06:40.067659 
[Epoch 14/50] [Batch 400/516] [D loss: 0.000306, acc:   0%] [G loss: 6.160590, adv: 0.652856, cyc: 0.222244, id: 0.232405] time: 2:08:26.707611 
[Epoch 14/50] [Batch 500/516] [D loss: 0.429347, acc:   0%] [G loss: 4.875729, adv: 0.010256, cyc: 0.222611, id: 0.235591] time: 2:10:13.293620 
[Epoch 15/50] [Batch 0/516] [D loss: 0.002221, acc:   0%] [G loss: 4.739457, adv: -0.003316, cyc: 0.217993, id: 0.223421] time: 2:10:30.312363 
[Epoch 15/50] [Batch 100/516] [D loss: 0.009020, acc:   0%] [G loss: 4.802269, adv: -0.000885, cyc: 0.220786, id: 0.221755] time: 2:12:17.029664 
[Epoch 15/50] [Batch 200/516] [D loss: 0.003171, acc:   0%] [G loss: 4.814794, adv: 0.002117, cyc: 0.220695, id: 0.222054] time: 2:14:03.625104 
[Epoch 15/50] [Batch 300/516] [D loss: 0.002427, acc:   0%] [G loss: 4.703404, adv: -0.001128, cyc: 0.215986, id: 0.214792] time: 2:15:50.377294 
[Epoch 15/50] [Batch 400/516] [D loss: 0.495617, acc:   0%] [G loss: 5.732912, adv: 0.461481, cyc: 0.220532, id: 0.226916] time: 2:17:36.952026 
[Epoch 15/50] [Batch 500/516] [D loss: 0.027725, acc:   0%] [G loss: 4.706595, adv: -0.045798, cyc: 0.220039, id: 0.232883] time: 2:19:23.691654 
[Epoch 16/50] [Batch 0/516] [D loss: 0.002537, acc:   0%] [G loss: 4.725694, adv: -0.003618, cyc: 0.217329, id: 0.223301] time: 2:19:41.920510 
[Epoch 16/50] [Batch 100/516] [D loss: 0.004308, acc:   0%] [G loss: 4.774509, adv: -0.005836, cyc: 0.219977, id: 0.221633] time: 2:21:28.493546 
[Epoch 16/50] [Batch 200/516] [D loss: 0.001575, acc:   0%] [G loss: 4.801736, adv: -0.003076, cyc: 0.220807, id: 0.219739] time: 2:23:14.985678 
[Epoch 16/50] [Batch 300/516] [D loss: 0.004262, acc:   0%] [G loss: 4.793970, adv: 0.007854, cyc: 0.219227, id: 0.219562] time: 2:25:01.868943 
[Epoch 16/50] [Batch 400/516] [D loss: 0.005627, acc:   0%] [G loss: 4.697559, adv: -0.003941, cyc: 0.215799, id: 0.220568] time: 2:26:48.471876 
[Epoch 16/50] [Batch 500/516] [D loss: 0.001363, acc:   0%] [G loss: 4.789751, adv: -0.002806, cyc: 0.220032, id: 0.231305] time: 2:28:35.138243 
[Epoch 17/50] [Batch 0/516] [D loss: 0.002104, acc:   0%] [G loss: 4.782989, adv: -0.002081, cyc: 0.219286, id: 0.231412] time: 2:28:52.210663 
[Epoch 17/50] [Batch 100/516] [D loss: 0.001601, acc:   0%] [G loss: 4.715933, adv: -0.001533, cyc: 0.216155, id: 0.226405] time: 2:30:38.914633 
[Epoch 17/50] [Batch 200/516] [D loss: 0.003987, acc:   0%] [G loss: 4.762062, adv: 0.001557, cyc: 0.218164, id: 0.220979] time: 2:32:25.516508 
[Epoch 17/50] [Batch 300/516] [D loss: 0.028243, acc:   0%] [G loss: 4.695536, adv: -0.002312, cyc: 0.215742, id: 0.214401] time: 2:34:12.385245 
[Epoch 17/50] [Batch 400/516] [D loss: 0.002093, acc:   0%] [G loss: 4.732284, adv: -0.003389, cyc: 0.217764, id: 0.217921] time: 2:35:59.069615 
[Epoch 17/50] [Batch 500/516] [D loss: 0.098744, acc:   0%] [G loss: 4.805512, adv: 0.025469, cyc: 0.217562, id: 0.237023] time: 2:37:45.544141 
[Epoch 18/50] [Batch 0/516] [D loss: 0.034105, acc:   0%] [G loss: 4.755649, adv: 0.011490, cyc: 0.217403, id: 0.222796] time: 2:38:02.560478 
[Epoch 18/50] [Batch 100/516] [D loss: 0.016771, acc:   0%] [G loss: 5.860147, adv: 0.563066, cyc: 0.217001, id: 0.225502] time: 2:39:49.098583 
[Epoch 18/50] [Batch 200/516] [D loss: 0.001551, acc:   0%] [G loss: 4.765562, adv: -0.002524, cyc: 0.218669, id: 0.223285] time: 2:41:35.744617 
[Epoch 18/50] [Batch 300/516] [D loss: 0.001318, acc:   0%] [G loss: 4.695990, adv: -0.002171, cyc: 0.215827, id: 0.213112] time: 2:43:22.626372 
[Epoch 18/50] [Batch 400/516] [D loss: 0.004503, acc:   0%] [G loss: 4.861225, adv: 0.007886, cyc: 0.222639, id: 0.220752] time: 2:45:09.331609 
[Epoch 18/50] [Batch 500/516] [D loss: 0.004168, acc:   0%] [G loss: 4.814169, adv: -0.002325, cyc: 0.221156, id: 0.231312] time: 2:46:56.066794 
[Epoch 19/50] [Batch 0/516] [D loss: 0.015638, acc:   0%] [G loss: 4.762111, adv: 0.017190, cyc: 0.217060, id: 0.223326] time: 2:47:13.152006 
[Epoch 19/50] [Batch 100/516] [D loss: 0.009180, acc:   0%] [G loss: 4.694781, adv: 0.001806, cyc: 0.214843, id: 0.225240] time: 2:48:59.820783 
[Epoch 19/50] [Batch 200/516] [D loss: 0.003844, acc:   0%] [G loss: 4.709544, adv: -0.000350, cyc: 0.215764, id: 0.221364] time: 2:50:46.274718 
[Epoch 19/50] [Batch 300/516] [D loss: 0.130811, acc:  24%] [G loss: 5.451195, adv: 0.404802, cyc: 0.212910, id: 0.213172] time: 2:52:32.920565 
[Epoch 19/50] [Batch 400/516] [D loss: 0.001935, acc:   0%] [G loss: 4.763725, adv: -0.003276, cyc: 0.218777, id: 0.222818] time: 2:54:19.484429 
[Epoch 19/50] [Batch 500/516] [D loss: 0.001893, acc:   0%] [G loss: 4.747943, adv: -0.002339, cyc: 0.218238, id: 0.227566] time: 2:56:06.195784 
[Epoch 20/50] [Batch 0/516] [D loss: 0.098174, acc:   0%] [G loss: 4.799946, adv: 0.041168, cyc: 0.215950, id: 0.229536] time: 2:56:23.205266 
[Epoch 20/50] [Batch 100/516] [D loss: 0.544105, acc:   0%] [G loss: 4.725079, adv: 0.000921, cyc: 0.216351, id: 0.226929] time: 2:58:09.792427 
[Epoch 20/50] [Batch 200/516] [D loss: 0.002197, acc:   0%] [G loss: 4.774850, adv: -0.011442, cyc: 0.220285, id: 0.219229] time: 2:59:56.445107 
[Epoch 20/50] [Batch 300/516] [D loss: -0.055701, acc:   0%] [G loss: 9.156838, adv: 2.246832, cyc: 0.213659, id: 0.216818] time: 3:01:43.019073 
[Epoch 20/50] [Batch 400/516] [D loss: 0.001200, acc:   0%] [G loss: 4.763687, adv: -0.002359, cyc: 0.218720, id: 0.223539] time: 3:03:29.596607 
[Epoch 20/50] [Batch 500/516] [D loss: 0.001998, acc:   0%] [G loss: 4.719405, adv: -0.003362, cyc: 0.216539, id: 0.231138] time: 3:05:16.433839 
[Epoch 21/50] [Batch 0/516] [D loss: 0.002626, acc:   0%] [G loss: 4.670830, adv: -0.004318, cyc: 0.214923, id: 0.220237] time: 3:05:34.648855 
[Epoch 21/50] [Batch 100/516] [D loss: 0.034596, acc:   0%] [G loss: 4.699963, adv: 0.007596, cyc: 0.214992, id: 0.220570] time: 3:07:21.043486 
[Epoch 21/50] [Batch 200/516] [D loss: 0.018951, acc:   0%] [G loss: 4.682629, adv: -0.004533, cyc: 0.214867, id: 0.221199] time: 3:09:07.743523 
[Epoch 21/50] [Batch 300/516] [D loss: 0.001689, acc:   0%] [G loss: 4.624827, adv: -0.003793, cyc: 0.212551, id: 0.212519] time: 3:10:54.481535 
[Epoch 21/50] [Batch 400/516] [D loss: 0.002697, acc:   0%] [G loss: 4.696251, adv: -0.000986, cyc: 0.215634, id: 0.217334] time: 3:12:41.303496 
[Epoch 21/50] [Batch 500/516] [D loss: 0.437856, acc:   0%] [G loss: 7.223067, adv: 1.258264, cyc: 0.215798, id: 0.228165] time: 3:14:27.972166 
[Epoch 22/50] [Batch 0/516] [D loss: 0.006165, acc:   0%] [G loss: 4.690472, adv: 0.015342, cyc: 0.213795, id: 0.221098] time: 3:14:45.161283 
[Epoch 22/50] [Batch 100/516] [D loss: 0.001259, acc:   0%] [G loss: 4.687589, adv: -0.002095, cyc: 0.215541, id: 0.217344] time: 3:16:31.692584 
[Epoch 22/50] [Batch 200/516] [D loss: 0.001272, acc:   0%] [G loss: 4.675963, adv: -0.002415, cyc: 0.214500, id: 0.218319] time: 3:18:18.421014 
[Epoch 22/50] [Batch 300/516] [D loss: 0.001393, acc:   0%] [G loss: 4.599594, adv: -0.003278, cyc: 0.211287, id: 0.211813] time: 3:20:05.097116 
[Epoch 22/50] [Batch 400/516] [D loss: 0.002547, acc:   0%] [G loss: 4.716426, adv: -0.001471, cyc: 0.216147, id: 0.225091] time: 3:21:51.560528 
[Epoch 22/50] [Batch 500/516] [D loss: 0.001610, acc:   0%] [G loss: 4.706714, adv: -0.000606, cyc: 0.215725, id: 0.230187] time: 3:23:38.167149 
[Epoch 23/50] [Batch 0/516] [D loss: 0.002481, acc:   0%] [G loss: 4.680967, adv: -0.003344, cyc: 0.215036, id: 0.222410] time: 3:23:55.276905 
[Epoch 23/50] [Batch 100/516] [D loss: 1.891973, acc:   0%] [G loss: 4.680100, adv: 0.007106, cyc: 0.213682, id: 0.226390] time: 3:25:42.140198 
[Epoch 23/50] [Batch 200/516] [D loss: 0.003268, acc:   0%] [G loss: 4.751578, adv: 0.002342, cyc: 0.217651, id: 0.220182] time: 3:27:28.731095 
[Epoch 23/50] [Batch 300/516] [D loss: 0.104123, acc:   0%] [G loss: 4.644778, adv: -0.009396, cyc: 0.214025, id: 0.212952] time: 3:29:15.183347 
[Epoch 23/50] [Batch 400/516] [D loss: 0.002400, acc:   0%] [G loss: 4.664423, adv: -0.003220, cyc: 0.214139, id: 0.219574] time: 3:31:01.851996 
[Epoch 23/50] [Batch 500/516] [D loss: 0.001894, acc:   0%] [G loss: 4.668651, adv: -0.003708, cyc: 0.214587, id: 0.225583] time: 3:32:48.428834 
[Epoch 24/50] [Batch 0/516] [D loss: 0.001623, acc:   0%] [G loss: 4.632365, adv: -0.002105, cyc: 0.212647, id: 0.221040] time: 3:33:05.489763 
[Epoch 24/50] [Batch 100/516] [D loss: 0.001265, acc:   0%] [G loss: 4.600714, adv: -0.001824, cyc: 0.211223, id: 0.216904] time: 3:34:52.019111 
[Epoch 24/50] [Batch 200/516] [D loss: 0.003770, acc:   0%] [G loss: 4.667958, adv: -0.001256, cyc: 0.214010, id: 0.218960] time: 3:36:38.803791 
[Epoch 24/50] [Batch 300/516] [D loss: 0.001839, acc:   0%] [G loss: 4.640702, adv: -0.000913, cyc: 0.212531, id: 0.217397] time: 3:38:25.606173 
[Epoch 24/50] [Batch 400/516] [D loss: 0.002622, acc:   0%] [G loss: 4.629399, adv: -0.000093, cyc: 0.212200, id: 0.218278] time: 3:40:12.328195 
[Epoch 24/50] [Batch 500/516] [D loss: 0.057606, acc:   0%] [G loss: 4.661442, adv: -0.002145, cyc: 0.214055, id: 0.224635] time: 3:41:58.843600 
[Epoch 25/50] [Batch 0/516] [D loss: 0.001577, acc:   0%] [G loss: 4.626291, adv: -0.003253, cyc: 0.212299, id: 0.223207] time: 3:42:15.856270 
[Epoch 25/50] [Batch 100/516] [D loss: 0.018153, acc:   0%] [G loss: 4.663353, adv: 0.006143, cyc: 0.213533, id: 0.217176] time: 3:44:02.469186 
[Epoch 25/50] [Batch 200/516] [D loss: 0.023424, acc:   0%] [G loss: 4.660663, adv: -0.006905, cyc: 0.214408, id: 0.216215] time: 3:45:49.091575 
[Epoch 25/50] [Batch 300/516] [D loss: 0.029854, acc:   0%] [G loss: 4.666363, adv: -0.005003, cyc: 0.214736, id: 0.211893] time: 3:47:35.836541 
[Epoch 25/50] [Batch 400/516] [D loss: 0.001722, acc:   0%] [G loss: 4.663019, adv: -0.001943, cyc: 0.213612, id: 0.223242] time: 3:49:22.374376 
[Epoch 25/50] [Batch 500/516] [D loss: 0.025823, acc:   0%] [G loss: 4.684457, adv: -0.005601, cyc: 0.215463, id: 0.225775] time: 3:51:09.063664 
[Epoch 26/50] [Batch 0/516] [D loss: 0.001207, acc:   0%] [G loss: 4.614970, adv: -0.002966, cyc: 0.212152, id: 0.217731] time: 3:51:27.237875 
[Epoch 26/50] [Batch 100/516] [D loss: 0.002387, acc:   0%] [G loss: 4.623286, adv: -0.002648, cyc: 0.212171, id: 0.219295] time: 3:53:14.140460 
[Epoch 26/50] [Batch 200/516] [D loss: 0.064345, acc:   0%] [G loss: 4.702214, adv: 0.014978, cyc: 0.214475, id: 0.214553] time: 3:55:01.001434 
[Epoch 26/50] [Batch 300/516] [D loss: 0.001639, acc:   0%] [G loss: 4.646892, adv: 0.019902, cyc: 0.211400, id: 0.210836] time: 3:56:47.679933 
[Epoch 26/50] [Batch 400/516] [D loss: 0.014279, acc:   0%] [G loss: 4.634127, adv: -0.006095, cyc: 0.212758, id: 0.221488] time: 3:58:34.579910 
[Epoch 26/50] [Batch 500/516] [D loss: 0.623256, acc:   0%] [G loss: 4.672944, adv: 0.013252, cyc: 0.213083, id: 0.224915] time: 4:00:21.630728 
[Epoch 27/50] [Batch 0/516] [D loss: 0.004913, acc:   0%] [G loss: 4.616756, adv: 0.000462, cyc: 0.211711, id: 0.220116] time: 4:00:38.665950 
[Epoch 27/50] [Batch 100/516] [D loss: 0.003326, acc:   0%] [G loss: 4.596670, adv: -0.004272, cyc: 0.211226, id: 0.217176] time: 4:02:25.723790 
[Epoch 27/50] [Batch 200/516] [D loss: 0.003522, acc:   0%] [G loss: 4.711415, adv: -0.000363, cyc: 0.216146, id: 0.217078] time: 4:04:12.783696 
[Epoch 27/50] [Batch 300/516] [D loss: 0.109937, acc:   0%] [G loss: 4.644380, adv: 0.004326, cyc: 0.212631, id: 0.212838] time: 4:05:59.607430 
[Epoch 27/50] [Batch 400/516] [D loss: 0.004059, acc:   0%] [G loss: 4.651433, adv: 0.028019, cyc: 0.210752, id: 0.215274] time: 4:07:46.444318 
[Epoch 27/50] [Batch 500/516] [D loss: 0.004121, acc:   0%] [G loss: 4.694919, adv: -0.002106, cyc: 0.215331, id: 0.229133] time: 4:09:33.400941 
[Epoch 28/50] [Batch 0/516] [D loss: 0.006826, acc:   0%] [G loss: 4.641932, adv: 0.005918, cyc: 0.212286, id: 0.221158] time: 4:09:50.524614 
[Epoch 28/50] [Batch 100/516] [D loss: 0.569046, acc:   0%] [G loss: 4.637518, adv: 0.018803, cyc: 0.210879, id: 0.217839] time: 4:11:37.214307 
[Epoch 28/50] [Batch 200/516] [D loss: 0.009951, acc:   0%] [G loss: 4.700679, adv: 0.009611, cyc: 0.214527, id: 0.219462] time: 4:13:23.838678 
[Epoch 28/50] [Batch 300/516] [D loss: 0.064270, acc:   0%] [G loss: 4.560212, adv: -0.017977, cyc: 0.210801, id: 0.211021] time: 4:15:10.420476 
[Epoch 28/50] [Batch 400/516] [D loss: 0.001125, acc:   0%] [G loss: 4.662509, adv: -0.002760, cyc: 0.213788, id: 0.222449] time: 4:16:57.019609 
[Epoch 28/50] [Batch 500/516] [D loss: 0.011595, acc:   0%] [G loss: 4.692840, adv: 0.009414, cyc: 0.214316, id: 0.226369] time: 4:18:44.037304 
[Epoch 29/50] [Batch 0/516] [D loss: 0.015763, acc:   0%] [G loss: 4.607361, adv: -0.002405, cyc: 0.211691, id: 0.218211] time: 4:19:01.112835 
[Epoch 29/50] [Batch 100/516] [D loss: 1.656161, acc:   0%] [G loss: 4.560851, adv: -0.006767, cyc: 0.209780, id: 0.216103] time: 4:20:47.751120 
[Epoch 29/50] [Batch 200/516] [D loss: 0.029168, acc:   0%] [G loss: 4.629063, adv: -0.036782, cyc: 0.215820, id: 0.215957] time: 4:22:34.437666 
[Epoch 29/50] [Batch 300/516] [D loss: 0.001360, acc:   0%] [G loss: 4.602841, adv: -0.001557, cyc: 0.211419, id: 0.209842] time: 4:24:21.089837 
[Epoch 29/50] [Batch 400/516] [D loss: 0.005566, acc:   0%] [G loss: 4.682724, adv: 0.011827, cyc: 0.213306, id: 0.222455] time: 4:26:07.747078 
[Epoch 29/50] [Batch 500/516] [D loss: 0.050591, acc:   0%] [G loss: 4.962164, adv: 0.131168, cyc: 0.215281, id: 0.231491] time: 4:27:54.417669 
[Epoch 30/50] [Batch 0/516] [D loss: 0.087097, acc:  25%] [G loss: 4.257921, adv: -0.182247, cyc: 0.211920, id: 0.220453] time: 4:28:11.472752 
[Epoch 30/50] [Batch 100/516] [D loss: 0.008832, acc:   0%] [G loss: 4.584277, adv: -0.015949, cyc: 0.211721, id: 0.217408] time: 4:29:58.175603 
[Epoch 30/50] [Batch 200/516] [D loss: 0.001422, acc:   0%] [G loss: 4.667581, adv: -0.002665, cyc: 0.214047, id: 0.218480] time: 4:31:45.229498 
[Epoch 30/50] [Batch 300/516] [D loss: 0.281009, acc:  25%] [G loss: 4.693449, adv: 0.053039, cyc: 0.210367, id: 0.210451] time: 4:33:31.703467 
[Epoch 30/50] [Batch 400/516] [D loss: 13.466504, acc:   0%] [G loss: 7.224334, adv: 1.290265, cyc: 0.213153, id: 0.214528] time: 4:35:18.302390 
[Epoch 30/50] [Batch 500/516] [D loss: 0.012047, acc:   0%] [G loss: 4.633421, adv: 0.002176, cyc: 0.212274, id: 0.224481] time: 4:37:05.470860 
[Epoch 31/50] [Batch 0/516] [D loss: 2.749117, acc:   0%] [G loss: 5.116608, adv: 0.247887, cyc: 0.211875, id: 0.221498] time: 4:37:24.096643 
[Epoch 31/50] [Batch 100/516] [D loss: 0.043418, acc:   0%] [G loss: 4.619390, adv: 0.005790, cyc: 0.211287, id: 0.217667] time: 4:39:12.803389 
[Epoch 31/50] [Batch 200/516] [D loss: 0.002321, acc:   0%] [G loss: 4.681009, adv: -0.001786, cyc: 0.215200, id: 0.213521] time: 4:41:01.526050 
[Epoch 31/50] [Batch 300/516] [D loss: 0.001532, acc:   0%] [G loss: 4.612986, adv: -0.003279, cyc: 0.211724, id: 0.213660] time: 4:42:50.239708 
[Epoch 31/50] [Batch 400/516] [D loss: 0.002021, acc:   0%] [G loss: 4.558797, adv: -0.002753, cyc: 0.208966, id: 0.217788] time: 4:44:38.666330 
[Epoch 31/50] [Batch 500/516] [D loss: 0.001502, acc:   0%] [G loss: 4.625885, adv: -0.003840, cyc: 0.212230, id: 0.227664] time: 4:46:27.315993 
[Epoch 32/50] [Batch 0/516] [D loss: 0.024983, acc:   0%] [G loss: 5.401667, adv: 0.408382, cyc: 0.210351, id: 0.217796] time: 4:46:44.667730 
[Epoch 32/50] [Batch 100/516] [D loss: 0.056400, acc:   0%] [G loss: 4.682384, adv: 0.041480, cyc: 0.210951, id: 0.216965] time: 4:48:33.315341 
[Epoch 32/50] [Batch 200/516] [D loss: 0.001622, acc:   0%] [G loss: 4.639929, adv: -0.002106, cyc: 0.212837, id: 0.216516] time: 4:50:21.612628 
[Epoch 32/50] [Batch 300/516] [D loss: 0.004673, acc:   0%] [G loss: 4.585723, adv: 0.003087, cyc: 0.209809, id: 0.213338] time: 4:52:10.335722 
[Epoch 32/50] [Batch 400/516] [D loss: 0.496649, acc:   0%] [G loss: 4.655312, adv: 0.012501, cyc: 0.212040, id: 0.221233] time: 4:53:59.104031 
[Epoch 32/50] [Batch 500/516] [D loss: 0.002046, acc:   0%] [G loss: 4.669565, adv: 0.009995, cyc: 0.213024, id: 0.227861] time: 4:55:47.977832 
[Epoch 33/50] [Batch 0/516] [D loss: 0.004296, acc:   0%] [G loss: 4.599937, adv: 0.006497, cyc: 0.210259, id: 0.220328] time: 4:56:05.459169 
[Epoch 33/50] [Batch 100/516] [D loss: 0.002914, acc:   0%] [G loss: 4.596036, adv: -0.002463, cyc: 0.211029, id: 0.216509] time: 4:57:54.184083 
[Epoch 33/50] [Batch 200/516] [D loss: 0.004210, acc:   0%] [G loss: 4.592177, adv: -0.005289, cyc: 0.210901, id: 0.215496] time: 4:59:43.058043 
[Epoch 33/50] [Batch 300/516] [D loss: 0.001232, acc:   0%] [G loss: 4.540544, adv: -0.002625, cyc: 0.208379, id: 0.209669] time: 5:01:31.768758 
[Epoch 33/50] [Batch 400/516] [D loss: 0.019685, acc:   0%] [G loss: 4.583557, adv: -0.003509, cyc: 0.210172, id: 0.218297] time: 5:03:20.316278 
[Epoch 33/50] [Batch 500/516] [D loss: 0.001647, acc:   0%] [G loss: 4.591230, adv: -0.002922, cyc: 0.210724, id: 0.223338] time: 5:05:08.802361 
[Epoch 34/50] [Batch 0/516] [D loss: 0.112997, acc:   0%] [G loss: 4.675351, adv: 0.067443, cyc: 0.208077, id: 0.218767] time: 5:05:26.250846 
[Epoch 34/50] [Batch 100/516] [D loss: 0.001270, acc:   0%] [G loss: 4.556189, adv: -0.001925, cyc: 0.208900, id: 0.217953] time: 5:07:14.951033 
[Epoch 34/50] [Batch 200/516] [D loss: 0.001991, acc:   0%] [G loss: 4.678412, adv: -0.003147, cyc: 0.214663, id: 0.220168] time: 5:09:03.592786 
[Epoch 34/50] [Batch 300/516] [D loss: 0.101057, acc:   0%] [G loss: 4.571123, adv: 0.001363, cyc: 0.209325, id: 0.211917] time: 5:10:52.324158 
[Epoch 34/50] [Batch 400/516] [D loss: 0.003299, acc:   0%] [G loss: 4.592306, adv: 0.000313, cyc: 0.210648, id: 0.214601] time: 5:12:40.693097 
[Epoch 34/50] [Batch 500/516] [D loss: 0.006243, acc:   0%] [G loss: 4.648438, adv: -0.009460, cyc: 0.214218, id: 0.223886] time: 5:14:29.075627 
[Epoch 35/50] [Batch 0/516] [D loss: 0.004049, acc:   0%] [G loss: 4.554336, adv: -0.005074, cyc: 0.209189, id: 0.219954] time: 5:14:46.443214 
[Epoch 35/50] [Batch 100/516] [D loss: 0.254594, acc:  25%] [G loss: 4.470237, adv: -0.030696, cyc: 0.207769, id: 0.214546] time: 5:16:35.595069 
[Epoch 35/50] [Batch 200/516] [D loss: 0.001838, acc:   0%] [G loss: 4.592473, adv: -0.003829, cyc: 0.210547, id: 0.217321] time: 5:18:24.287271 
[Epoch 35/50] [Batch 300/516] [D loss: 0.011677, acc:   0%] [G loss: 4.591813, adv: 0.003527, cyc: 0.210327, id: 0.209536] time: 5:20:12.959972 
[Epoch 35/50] [Batch 400/516] [D loss: 0.056878, acc:   0%] [G loss: 4.595150, adv: -0.003591, cyc: 0.211122, id: 0.214148] time: 5:22:01.555957 
[Epoch 35/50] [Batch 500/516] [D loss: 0.021343, acc:   0%] [G loss: 4.648866, adv: 0.021727, cyc: 0.211023, id: 0.225465] time: 5:23:49.163528 
[Epoch 36/50] [Batch 0/516] [D loss: 0.028938, acc:   0%] [G loss: 4.530761, adv: -0.001463, cyc: 0.207730, id: 0.218625] time: 5:24:08.045592 
[Epoch 36/50] [Batch 100/516] [D loss: 0.001936, acc:   0%] [G loss: 4.583828, adv: -0.001269, cyc: 0.210050, id: 0.219036] time: 5:25:57.013226 
[Epoch 36/50] [Batch 200/516] [D loss: 0.002243, acc:   0%] [G loss: 4.590141, adv: -0.003800, cyc: 0.210522, id: 0.216219] time: 5:27:45.699778 
[Epoch 36/50] [Batch 300/516] [D loss: 0.004838, acc:   0%] [G loss: 4.541029, adv: 0.000856, cyc: 0.207816, id: 0.212296] time: 5:29:34.342451 
[Epoch 36/50] [Batch 400/516] [D loss: 0.001898, acc:   0%] [G loss: 4.562682, adv: -0.004715, cyc: 0.209584, id: 0.215361] time: 5:31:22.779912 
[Epoch 36/50] [Batch 500/516] [D loss: 0.405611, acc:   0%] [G loss: 4.812677, adv: 0.110088, cyc: 0.210447, id: 0.224156] time: 5:33:11.611528 
[Epoch 37/50] [Batch 0/516] [D loss: 0.003111, acc:   0%] [G loss: 4.602975, adv: -0.001917, cyc: 0.211346, id: 0.219055] time: 5:33:29.058318 
[Epoch 37/50] [Batch 100/516] [D loss: 0.001334, acc:   0%] [G loss: 4.528085, adv: -0.001687, cyc: 0.207451, id: 0.217868] time: 5:35:17.439676 
[Epoch 37/50] [Batch 200/516] [D loss: 0.005200, acc:   0%] [G loss: 4.562219, adv: 0.000246, cyc: 0.208867, id: 0.214595] time: 5:37:06.102472 
[Epoch 37/50] [Batch 300/516] [D loss: 0.002181, acc:   0%] [G loss: 4.552804, adv: -0.003992, cyc: 0.209080, id: 0.210017] time: 5:38:54.950147 
[Epoch 37/50] [Batch 400/516] [D loss: 0.001494, acc:   0%] [G loss: 4.575043, adv: -0.002128, cyc: 0.209859, id: 0.215288] time: 5:40:43.625505 
[Epoch 37/50] [Batch 500/516] [D loss: 0.007749, acc:   0%] [G loss: 4.654038, adv: -0.005832, cyc: 0.214037, id: 0.224549] time: 5:42:32.271523 
[Epoch 38/50] [Batch 0/516] [D loss: 0.001389, acc:   0%] [G loss: 4.584806, adv: -0.002142, cyc: 0.210598, id: 0.217716] time: 5:42:49.595522 
[Epoch 38/50] [Batch 100/516] [D loss: 0.086557, acc:   0%] [G loss: 4.530350, adv: 0.002855, cyc: 0.207010, id: 0.218914] time: 5:44:38.429269 
[Epoch 38/50] [Batch 200/516] [D loss: 0.001804, acc:   0%] [G loss: 4.630559, adv: -0.002686, cyc: 0.212349, id: 0.217783] time: 5:46:27.215599 
[Epoch 38/50] [Batch 300/516] [D loss: 0.001276, acc:   0%] [G loss: 4.572724, adv: -0.002748, cyc: 0.209672, id: 0.212485] time: 5:48:15.647999 
[Epoch 38/50] [Batch 400/516] [D loss: 0.026411, acc:   0%] [G loss: 4.561923, adv: 0.004798, cyc: 0.208648, id: 0.213931] time: 5:50:04.229854 
[Epoch 38/50] [Batch 500/516] [D loss: 0.001194, acc:   0%] [G loss: 4.646473, adv: -0.002594, cyc: 0.212921, id: 0.230219] time: 5:51:52.463840 
[Epoch 39/50] [Batch 0/516] [D loss: 0.008679, acc:   0%] [G loss: 4.596960, adv: -0.005784, cyc: 0.211159, id: 0.221700] time: 5:52:09.813524 
[Epoch 39/50] [Batch 100/516] [D loss: 0.011378, acc:   0%] [G loss: 4.516762, adv: -0.004399, cyc: 0.207423, id: 0.215235] time: 5:53:58.322926 
[Epoch 39/50] [Batch 200/516] [D loss: 0.002984, acc:   0%] [G loss: 4.660881, adv: 0.002120, cyc: 0.213437, id: 0.217183] time: 5:55:46.545736 
[Epoch 39/50] [Batch 300/516] [D loss: 0.001650, acc:   0%] [G loss: 4.554508, adv: -0.003250, cyc: 0.209043, id: 0.210553] time: 5:57:34.557962 
[Epoch 39/50] [Batch 400/516] [D loss: 0.001791, acc:   0%] [G loss: 4.611806, adv: 0.009640, cyc: 0.210805, id: 0.212715] time: 5:59:22.951560 
[Epoch 39/50] [Batch 500/516] [D loss: -0.000493, acc:   0%] [G loss: 5.568128, adv: 0.477022, cyc: 0.211611, id: 0.223704] time: 6:01:11.336323 
[Epoch 40/50] [Batch 0/516] [D loss: 0.001745, acc:   0%] [G loss: 4.582569, adv: -0.000893, cyc: 0.210056, id: 0.220964] time: 6:01:28.699607 
[Epoch 40/50] [Batch 100/516] [D loss: 0.023327, acc:   0%] [G loss: 4.522544, adv: -0.002047, cyc: 0.207321, id: 0.217071] time: 6:03:17.196947 
[Epoch 40/50] [Batch 200/516] [D loss: 0.023066, acc:   0%] [G loss: 4.609839, adv: -0.003620, cyc: 0.211233, id: 0.218983] time: 6:05:05.691608 
[Epoch 40/50] [Batch 300/516] [D loss: 0.188988, acc:  25%] [G loss: 8.066904, adv: 1.781180, cyc: 0.206374, id: 0.209215] time: 6:06:54.303863 
[Epoch 40/50] [Batch 400/516] [D loss: 0.002683, acc:   0%] [G loss: 4.557692, adv: -0.002057, cyc: 0.208787, id: 0.218663] time: 6:08:42.711708 
[Epoch 40/50] [Batch 500/516] [D loss: 1.948070, acc:   0%] [G loss: 4.430414, adv: -0.098557, cyc: 0.212334, id: 0.222132] time: 6:10:31.307666 
[Epoch 41/50] [Batch 0/516] [D loss: 0.002065, acc:   0%] [G loss: 4.541298, adv: -0.001386, cyc: 0.208144, id: 0.219854] time: 6:10:50.020244 
[Epoch 41/50] [Batch 100/516] [D loss: 0.001245, acc:   0%] [G loss: 4.535954, adv: -0.002472, cyc: 0.208254, id: 0.214568] time: 6:12:38.400779 
[Epoch 41/50] [Batch 200/516] [D loss: 0.220053, acc:  25%] [G loss: 4.604563, adv: 0.010761, cyc: 0.209773, id: 0.217514] time: 6:14:26.593610 
[Epoch 41/50] [Batch 300/516] [D loss: 0.002496, acc:   0%] [G loss: 4.540036, adv: 0.003693, cyc: 0.207543, id: 0.212610] time: 6:16:14.828545 
[Epoch 41/50] [Batch 400/516] [D loss: 0.305573, acc:  25%] [G loss: 4.631623, adv: 0.045067, cyc: 0.207794, id: 0.219051] time: 6:18:03.326151 
[Epoch 41/50] [Batch 500/516] [D loss: 0.001387, acc:   0%] [G loss: 4.589445, adv: -0.003331, cyc: 0.210731, id: 0.222841] time: 6:19:51.811592 
[Epoch 42/50] [Batch 0/516] [D loss: 0.004590, acc:   0%] [G loss: 4.481521, adv: -0.008235, cyc: 0.205805, id: 0.221328] time: 6:20:09.219331 
[Epoch 42/50] [Batch 100/516] [D loss: 0.004207, acc:   0%] [G loss: 4.516795, adv: -0.002942, cyc: 0.207081, id: 0.217941] time: 6:21:57.944541 
[Epoch 42/50] [Batch 200/516] [D loss: 0.046441, acc:   0%] [G loss: 4.611486, adv: 0.013761, cyc: 0.210133, id: 0.213209] time: 6:23:45.152598 
[Epoch 42/50] [Batch 300/516] [D loss: 0.322555, acc:  25%] [G loss: 4.672896, adv: 0.071029, cyc: 0.207646, id: 0.209775] time: 6:25:32.329803 
[Epoch 42/50] [Batch 400/516] [D loss: 0.002224, acc:   0%] [G loss: 4.558659, adv: -0.001625, cyc: 0.208694, id: 0.220434] time: 6:27:19.569055 
[Epoch 42/50] [Batch 500/516] [D loss: 0.004896, acc:   0%] [G loss: 4.588437, adv: -0.001737, cyc: 0.210375, id: 0.224646] time: 6:29:06.946990 
[Epoch 43/50] [Batch 0/516] [D loss: 0.010111, acc:   0%] [G loss: 4.497043, adv: -0.030892, cyc: 0.209149, id: 0.216775] time: 6:29:24.125926 
[Epoch 43/50] [Batch 100/516] [D loss: 0.001467, acc:   0%] [G loss: 4.506266, adv: -0.002589, cyc: 0.206531, id: 0.217275] time: 6:31:11.459690 
[Epoch 43/50] [Batch 200/516] [D loss: 0.807428, acc:   0%] [G loss: 4.618032, adv: 0.017415, cyc: 0.210249, id: 0.211954] time: 6:32:58.695977 
[Epoch 43/50] [Batch 300/516] [D loss: 0.001376, acc:   0%] [G loss: 4.536161, adv: -0.001607, cyc: 0.207847, id: 0.212458] time: 6:34:45.944914 
[Epoch 43/50] [Batch 400/516] [D loss: 0.001759, acc:   0%] [G loss: 4.532901, adv: -0.002143, cyc: 0.207836, id: 0.214870] time: 6:36:33.240229 
[Epoch 43/50] [Batch 500/516] [D loss: 0.001527, acc:   0%] [G loss: 4.556101, adv: -0.001624, cyc: 0.208447, id: 0.228692] time: 6:38:20.760911 
[Epoch 44/50] [Batch 0/516] [D loss: 0.007802, acc:   0%] [G loss: 4.542978, adv: 0.005180, cyc: 0.207699, id: 0.218395] time: 6:38:38.038132 
[Epoch 44/50] [Batch 100/516] [D loss: 0.001959, acc:   0%] [G loss: 4.529117, adv: -0.001716, cyc: 0.207760, id: 0.214863] time: 6:40:25.139954 
[Epoch 44/50] [Batch 200/516] [D loss: 0.001372, acc:   0%] [G loss: 4.534188, adv: -0.002623, cyc: 0.207989, id: 0.212006] time: 6:42:12.499791 
[Epoch 44/50] [Batch 300/516] [D loss: 0.002555, acc:   0%] [G loss: 4.504741, adv: -0.003506, cyc: 0.206516, id: 0.211746] time: 6:43:59.944350 
[Epoch 44/50] [Batch 400/516] [D loss: 0.047302, acc:   0%] [G loss: 4.498818, adv: -0.013096, cyc: 0.207393, id: 0.213441] time: 6:45:47.171826 
[Epoch 44/50] [Batch 500/516] [D loss: -0.000036, acc:   0%] [G loss: 4.776093, adv: 0.073583, cyc: 0.212202, id: 0.224459] time: 6:47:34.380007 
[Epoch 45/50] [Batch 0/516] [D loss: 0.026122, acc:   0%] [G loss: 4.522050, adv: 0.001636, cyc: 0.207078, id: 0.217538] time: 6:47:51.548507 
[Epoch 45/50] [Batch 100/516] [D loss: 0.001506, acc:   0%] [G loss: 4.478998, adv: -0.002321, cyc: 0.205313, id: 0.215495] time: 6:49:38.745439 
[Epoch 45/50] [Batch 200/516] [D loss: 0.009724, acc:   0%] [G loss: 4.586510, adv: -0.008107, cyc: 0.211043, id: 0.213198] time: 6:51:25.905156 
[Epoch 45/50] [Batch 300/516] [D loss: 0.008477, acc:   0%] [G loss: 4.509855, adv: -0.003235, cyc: 0.206570, id: 0.214500] time: 6:53:13.115389 
[Epoch 45/50] [Batch 400/516] [D loss: 0.265022, acc:  25%] [G loss: 5.747837, adv: 0.615469, cyc: 0.206955, id: 0.213702] time: 6:55:00.221614 
[Epoch 45/50] [Batch 500/516] [D loss: 0.001576, acc:   0%] [G loss: 4.583349, adv: -0.002606, cyc: 0.210095, id: 0.226887] time: 6:56:47.707750 
[Epoch 46/50] [Batch 0/516] [D loss: 0.031262, acc:   0%] [G loss: 4.498070, adv: -0.015215, cyc: 0.207631, id: 0.216693] time: 6:57:06.011688 
[Epoch 46/50] [Batch 100/516] [D loss: 0.059679, acc:   0%] [G loss: 4.694423, adv: 0.084698, cyc: 0.207323, id: 0.215960] time: 6:58:53.248435 
[Epoch 46/50] [Batch 200/516] [D loss: 0.001298, acc:   0%] [G loss: 4.572362, adv: -0.002743, cyc: 0.209426, id: 0.218788] time: 7:00:40.452509 
[Epoch 46/50] [Batch 300/516] [D loss: 0.029629, acc:   0%] [G loss: 4.548184, adv: -0.003835, cyc: 0.208776, id: 0.210861] time: 7:02:27.834752 
[Epoch 46/50] [Batch 400/516] [D loss: 0.004884, acc:   0%] [G loss: 4.526481, adv: -0.005392, cyc: 0.207663, id: 0.216873] time: 7:04:15.190151 
[Epoch 46/50] [Batch 500/516] [D loss: 0.001846, acc:   0%] [G loss: 4.552189, adv: -0.002254, cyc: 0.208466, id: 0.227492] time: 7:06:02.378201 
[Epoch 47/50] [Batch 0/516] [D loss: 1.285735, acc:   0%] [G loss: 5.651433, adv: 0.574832, cyc: 0.206260, id: 0.216939] time: 7:06:19.562774 
[Epoch 47/50] [Batch 100/516] [D loss: 0.001656, acc:   0%] [G loss: 4.502997, adv: -0.001992, cyc: 0.206299, id: 0.217253] time: 7:08:07.002412 
[Epoch 47/50] [Batch 200/516] [D loss: 0.005138, acc:   0%] [G loss: 6.488060, adv: 0.983534, cyc: 0.206821, id: 0.215883] time: 7:09:54.345991 
[Epoch 47/50] [Batch 300/516] [D loss: 0.001165, acc:   0%] [G loss: 4.520804, adv: -0.002561, cyc: 0.207459, id: 0.209053] time: 7:11:41.579002 
[Epoch 47/50] [Batch 400/516] [D loss: 0.001818, acc:   0%] [G loss: 4.514675, adv: -0.003566, cyc: 0.207031, id: 0.215586] time: 7:13:28.915459 
[Epoch 47/50] [Batch 500/516] [D loss: 0.128953, acc:   0%] [G loss: 4.750787, adv: 0.058220, cyc: 0.212462, id: 0.224388] time: 7:15:16.264218 
[Epoch 48/50] [Batch 0/516] [D loss: 0.001453, acc:   0%] [G loss: 4.505278, adv: -0.001495, cyc: 0.206587, id: 0.216789] time: 7:15:33.377826 
[Epoch 48/50] [Batch 100/516] [D loss: 0.007616, acc:   0%] [G loss: 4.512343, adv: -0.001430, cyc: 0.206621, id: 0.218949] time: 7:17:20.604866 
[Epoch 48/50] [Batch 200/516] [D loss: 0.001828, acc:   0%] [G loss: 4.575301, adv: -0.001483, cyc: 0.209457, id: 0.217736] time: 7:19:07.868314 
[Epoch 48/50] [Batch 300/516] [D loss: 0.125513, acc:  25%] [G loss: 5.425286, adv: 0.446415, cyc: 0.207601, id: 0.210775] time: 7:20:54.471087 
[Epoch 48/50] [Batch 400/516] [D loss: 0.001972, acc:   0%] [G loss: 4.517795, adv: -0.003221, cyc: 0.207432, id: 0.211578] time: 7:22:41.125732 
[Epoch 48/50] [Batch 500/516] [D loss: 0.001247, acc:   0%] [G loss: 4.553973, adv: -0.003133, cyc: 0.208898, id: 0.224010] time: 7:24:27.591715 
[Epoch 49/50] [Batch 0/516] [D loss: 0.159519, acc:  25%] [G loss: 4.542855, adv: -0.004863, cyc: 0.208732, id: 0.216953] time: 7:24:44.696908 
[Epoch 49/50] [Batch 100/516] [D loss: 0.001496, acc:   0%] [G loss: 4.570014, adv: -0.001780, cyc: 0.209542, id: 0.218331] time: 7:26:31.408361 
[Epoch 49/50] [Batch 200/516] [D loss: 0.002331, acc:   0%] [G loss: 4.563925, adv: 0.001240, cyc: 0.208857, id: 0.215261] time: 7:28:18.017510 
[Epoch 49/50] [Batch 300/516] [D loss: 0.001463, acc:   0%] [G loss: 4.505547, adv: -0.003102, cyc: 0.206617, id: 0.210756] time: 7:30:04.610200 
[Epoch 49/50] [Batch 400/516] [D loss: 0.001507, acc:   0%] [G loss: 4.492759, adv: -0.002760, cyc: 0.206081, id: 0.212734] time: 7:31:51.463512 
[Epoch 49/50] [Batch 500/516] [D loss: 0.001628, acc:   0%] [G loss: 4.581820, adv: -0.002722, cyc: 0.210140, id: 0.224121] time: 7:33:38.177263 
[Epoch 50/50] [Batch 0/516] [D loss: 0.001769, acc:   0%] [G loss: 4.542921, adv: -0.000423, cyc: 0.208393, id: 0.216704] time: 7:33:55.272310 
[Epoch 50/50] [Batch 100/516] [D loss: 0.002363, acc:   0%] [G loss: 4.504331, adv: -0.003202, cyc: 0.206648, id: 0.215128] time: 7:35:42.165458 
[Epoch 50/50] [Batch 200/516] [D loss: 0.001780, acc:   0%] [G loss: 4.539130, adv: -0.000412, cyc: 0.208036, id: 0.212594] time: 7:37:28.836151 
[Epoch 50/50] [Batch 300/516] [D loss: 0.001556, acc:   0%] [G loss: 4.526503, adv: -0.002249, cyc: 0.207735, id: 0.209120] time: 7:39:15.522282 
[Epoch 50/50] [Batch 400/516] [D loss: 0.001623, acc:   0%] [G loss: 4.516721, adv: -0.003299, cyc: 0.207067, id: 0.216223] time: 7:41:02.238667 
[Epoch 50/50] [Batch 500/516] [D loss: 0.008818, acc:   0%] [G loss: 4.567428, adv: -0.018979, cyc: 0.211120, id: 0.224056] time: 7:42:48.899994 
Train Finished.
